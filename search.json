[
  {
    "objectID": "mindmap/OS/process_api.html",
    "href": "mindmap/OS/process_api.html",
    "title": "Process",
    "section": "",
    "text": "A running program.\nEach process has a unique name known as process ID."
  },
  {
    "objectID": "mindmap/OS/process_api.html#definition",
    "href": "mindmap/OS/process_api.html#definition",
    "title": "Process",
    "section": "",
    "text": "A running program.\nEach process has a unique name known as process ID."
  },
  {
    "objectID": "mindmap/OS/process_api.html#states",
    "href": "mindmap/OS/process_api.html#states",
    "title": "Process",
    "section": "States",
    "text": "States\n\nRunning: It is running.\nReady: It is ready to run, but the OS decides to not run it.\nBlocked: It is performing I/O."
  },
  {
    "objectID": "mindmap/OS/process_api.html#apis-provided-by-os",
    "href": "mindmap/OS/process_api.html#apis-provided-by-os",
    "title": "Process",
    "section": "APIs provided by OS",
    "text": "APIs provided by OS\n\nfork(): Create a new process. The caller is the parent, the created one is the child.\nwait(): Wait for the child process to complete execution.\nexec(): Replace the current program with a new program yet using the same process.\n…"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Minh Dang",
    "section": "",
    "text": "I’m Minh, a full-time Software Engineer and a part-time ultra trail runner. Here, I love to share my knowledge and experiences spanning Software Engineering and Ultra Trail Running."
  },
  {
    "objectID": "posts/2025-01-05_XV6.html",
    "href": "posts/2025-01-05_XV6.html",
    "title": "XV6 Series: MIT Lab3 2024",
    "section": "",
    "text": "Since xv6 is running on Sv39 RISC-V, only the bottom 39 bits of 64-bit virtual address are used; the top 25 bits are not used. Within 39 bits, there are 27 bits are used for Page Table Entry (PTE) index; the other 12 bits are used for the offset.\n\n\nEach PTE contains a 44-bit physical page number (PPN) and 10-bit flags.\n\nGiven the PTE value, we can calculate the Physical Page Number (PPN) by the following:\n#define PTE2PA(pte) (((pte) &gt;&gt; 10) &lt;&lt; 12)\n\nRight shift 10 bits to remove the flags\nLeft shift 12 bits to align with the physical address where the bottom 12 bits are used for offset.\n\nGiven the PTE value, we can get the PTE Flags by the following:\n#define PTE_FLAGS(pte) ((pte) & 0x3FF)\n\nBy using bit-wise AND with 0x3FF (001111111111), we can zero all the bits in the PTE except for the first 10 bits, representing the FLAGS.\n\nA typical PTE in RISC-V has the following format:\n\n\n\nBit Position\nName\nDescription\n\n\n\n\n0\nV\nIndicates if the PTE is valid.\n\n\n1\nR\nPage is readable.\n\n\n2\nW\nPage is writable.\n\n\n3\nX\nPage is executable.\n\n\n4\nU\nAccessible in user mode.\n\n\n5\nG\nShared across all address spaces.\n\n\n6\nA\nSet by hardware on the first access.\n\n\n7\nD\nSet by hardware on the first write.\n\n\n8-9\n\nReserved for future use.\n\n\n10-53\nPPN\nPhysical page number (mapping to memory).\n\n\n54-63\n\nReserved for future use.\n\n\n\n\n\n\nApproach:\n\nUsing the PTE format to decode the permission.\nUsing the order of virtual address to determine the page content since they are allocated in order.\n\n\n\n\n\n\n\n\n\nPTE entry\nContent\nPermission\n\n\n\n\nva 0x0 pte 0x21FCD85B pa 0x87F36000 perm 0x5B\ntext\n01011011 = AUXRV\n\n\nva 0x1000 pte 0x21FD1417 pa 0x87F45000 perm 0x17\ndata segment\n00010111 = UWRV\n\n\nva 0x2000 pte 0x21FD1007 pa 0x87F44000 perm 0x7\nguard page\n0111 = WRV\n\n\nva 0x3000 pte 0x21FD40D7 pa 0x87F50000 perm 0xD7\nstack\n11010111 = DAUWRV\n\n\nva 0x4000 pte 0x0 pa 0x0 perm 0x0\nunused\n\n\n\nva 0x5000 pte 0x0 pa 0x0 perm 0x0\nunused\n\n\n\nva 0x6000 pte 0x0 pa 0x0 perm 0x0\nunused\n\n\n\nva 0x7000 pte 0x0 pa 0x0 perm 0x0\nunused\n\n\n\nva 0x8000 pte 0x0 pa 0x0 perm 0x0\nunused\n\n\n\nva 0x9000 pte 0x0 pa 0x0 perm 0x0\nunused\n\n\n\nva 0xFFFF6000 pte 0x0 pa 0x0 perm 0x0\nunused\n\n\n\nva 0xFFFF7000 pte 0x0 pa 0x0 perm 0x0\nunused\n\n\n\nva 0xFFFF8000 pte 0x0 pa 0x0 perm 0x0\nunused\n\n\n\nva 0xFFFF9000 pte 0x0 pa 0x0 perm 0x0\nunused\n\n\n\nva 0xFFFFA000 pte 0x0 pa 0x0 perm 0x0\nunused\n\n\n\nva 0xFFFFB000 pte 0x0 pa 0x0 perm 0x0\nunused\n\n\n\nva 0xFFFFC000 pte 0x0 pa 0x0 perm 0x0\nunused\n\n\n\nva 0xFFFFD000 pte 0x0 pa 0x0 perm 0x0\nunused\n\n\n\nva 0xFFFFE000 pte 0x21FC90C7 pa 0x87F24000 perm 0xC7\ntrapframe\n11000111 = DAWRV\n\n\nva 0xFFFFF000 pte 0x2000184B pa 0x80006000 perm 0x4B\ntrampoline\n01001011 = AXRV"
  },
  {
    "objectID": "posts/2025-01-05_XV6.html#inspect-a-user-process-page-table",
    "href": "posts/2025-01-05_XV6.html#inspect-a-user-process-page-table",
    "title": "XV6 Series: MIT Lab3 2024",
    "section": "",
    "text": "Since xv6 is running on Sv39 RISC-V, only the bottom 39 bits of 64-bit virtual address are used; the top 25 bits are not used. Within 39 bits, there are 27 bits are used for Page Table Entry (PTE) index; the other 12 bits are used for the offset.\n\n\nEach PTE contains a 44-bit physical page number (PPN) and 10-bit flags.\n\nGiven the PTE value, we can calculate the Physical Page Number (PPN) by the following:\n#define PTE2PA(pte) (((pte) &gt;&gt; 10) &lt;&lt; 12)\n\nRight shift 10 bits to remove the flags\nLeft shift 12 bits to align with the physical address where the bottom 12 bits are used for offset.\n\nGiven the PTE value, we can get the PTE Flags by the following:\n#define PTE_FLAGS(pte) ((pte) & 0x3FF)\n\nBy using bit-wise AND with 0x3FF (001111111111), we can zero all the bits in the PTE except for the first 10 bits, representing the FLAGS.\n\nA typical PTE in RISC-V has the following format:\n\n\n\nBit Position\nName\nDescription\n\n\n\n\n0\nV\nIndicates if the PTE is valid.\n\n\n1\nR\nPage is readable.\n\n\n2\nW\nPage is writable.\n\n\n3\nX\nPage is executable.\n\n\n4\nU\nAccessible in user mode.\n\n\n5\nG\nShared across all address spaces.\n\n\n6\nA\nSet by hardware on the first access.\n\n\n7\nD\nSet by hardware on the first write.\n\n\n8-9\n\nReserved for future use.\n\n\n10-53\nPPN\nPhysical page number (mapping to memory).\n\n\n54-63\n\nReserved for future use.\n\n\n\n\n\n\nApproach:\n\nUsing the PTE format to decode the permission.\nUsing the order of virtual address to determine the page content since they are allocated in order.\n\n\n\n\n\n\n\n\n\nPTE entry\nContent\nPermission\n\n\n\n\nva 0x0 pte 0x21FCD85B pa 0x87F36000 perm 0x5B\ntext\n01011011 = AUXRV\n\n\nva 0x1000 pte 0x21FD1417 pa 0x87F45000 perm 0x17\ndata segment\n00010111 = UWRV\n\n\nva 0x2000 pte 0x21FD1007 pa 0x87F44000 perm 0x7\nguard page\n0111 = WRV\n\n\nva 0x3000 pte 0x21FD40D7 pa 0x87F50000 perm 0xD7\nstack\n11010111 = DAUWRV\n\n\nva 0x4000 pte 0x0 pa 0x0 perm 0x0\nunused\n\n\n\nva 0x5000 pte 0x0 pa 0x0 perm 0x0\nunused\n\n\n\nva 0x6000 pte 0x0 pa 0x0 perm 0x0\nunused\n\n\n\nva 0x7000 pte 0x0 pa 0x0 perm 0x0\nunused\n\n\n\nva 0x8000 pte 0x0 pa 0x0 perm 0x0\nunused\n\n\n\nva 0x9000 pte 0x0 pa 0x0 perm 0x0\nunused\n\n\n\nva 0xFFFF6000 pte 0x0 pa 0x0 perm 0x0\nunused\n\n\n\nva 0xFFFF7000 pte 0x0 pa 0x0 perm 0x0\nunused\n\n\n\nva 0xFFFF8000 pte 0x0 pa 0x0 perm 0x0\nunused\n\n\n\nva 0xFFFF9000 pte 0x0 pa 0x0 perm 0x0\nunused\n\n\n\nva 0xFFFFA000 pte 0x0 pa 0x0 perm 0x0\nunused\n\n\n\nva 0xFFFFB000 pte 0x0 pa 0x0 perm 0x0\nunused\n\n\n\nva 0xFFFFC000 pte 0x0 pa 0x0 perm 0x0\nunused\n\n\n\nva 0xFFFFD000 pte 0x0 pa 0x0 perm 0x0\nunused\n\n\n\nva 0xFFFFE000 pte 0x21FC90C7 pa 0x87F24000 perm 0xC7\ntrapframe\n11000111 = DAWRV\n\n\nva 0xFFFFF000 pte 0x2000184B pa 0x80006000 perm 0x4B\ntrampoline\n01001011 = AXRV"
  },
  {
    "objectID": "posts/2025-01-05_XV6.html#speed-up-system-calls",
    "href": "posts/2025-01-05_XV6.html#speed-up-system-calls",
    "title": "XV6 Series: MIT Lab3 2024",
    "section": "Speed up system calls",
    "text": "Speed up system calls\n\nGeneral knowledge:\n\nSystem calls usually require a context switch from user mode to kernel mode, which is expensive. To speed up the certain system calls, we use a technique called virtual dynamic shared object (vDSO). vDSO is a kernel mechanism for exporting a carefully selected set of kernel space routines to user space applications so that applications can call these kernel space routines in-process, without incurring the performance penalty of a mode switch from user mode to kernel mode that is inherent when calling these same kernel space routines by means of the system call interface.\n\nBesides, we should also understand how xv6 allocates pages to the process and how the virtual memory mapping to the physical memory.\nTBU: explain those concepts.\n\n\nSolution:\n\nugetpid() is declared in the file user/user.h, thus any user program can call it.\nAlso, the definition of ugetpid() is defined in the user/ulib.c file as follows:\n\nint\nugetpid(void)\n{\n  struct usyscall *u = (struct usyscall *)USYSCALL;\n  return u-&gt;pid;\n}\nFrom the definition, we can see that the pid is stored in the usyscall structure, which is defined in kernel/memlayout.h as follows:\nstruct usyscall {\n  int pid;  // Process ID\n};\nThe problem description suggests that: &gt; When each process is created, map one read-only page at USYSCALL. At the start of this page, store a struct usyscall\nThe USYSCALL is defined in the kernel/memlayout.h as follows:\n#define USYSCALL (TRAPFRAME - PGSIZE)\nThat means the struct usyscall is stored in the page right after the TRAPFRAME page.\nTo do that, we have to deep into the function where the memory is allocated for the process. In this case, it is the alloproc function defined in kernel/proc.c.\nstatic struct proc*\nallocproc(void) {\n  ...\n}\nThe allocproc uses the function kalloc to allocate 4096-byte page in physical memory to process’s component. For example, this is the line where a single page in physical memory is allocated for the process’s trapframe.\np-&gt;trapframe = (struct trapframe *)kalloc()\nAfter this line, the p-&gt;trapframe contains the memory of the page a.k.a. It plays as a pointer to the page in physical memory.\nThus, to allocate a page for the struct usyscall, we can use the following code:\nif((p-&gt;usyscall = (struct usyscall *)kalloc()) == 0){\n  freeproc(p) ;\n  release(&p-&gt;lock);\n  return 0;\n}\nWe also assign the process ID to the usyscall structure as follows:\np-&gt;usyscall-&gt;pid = p-&gt;pid;\nThen we map the physical address to virtual address of the process via the function proc_pagetable defined in the file kernel/proc.c.\n if(mappages(pagetable, USYSCALL, PGSIZE,\n              (uint64)(p-&gt;usyscall), PTE_R | PTE_U) &lt; 0) {\n      uvmunmap(pagetable, TRAMPOLINE, 1, 0);\n      uvmunmap(pagetable, TRAPFRAME, 1, 0);\n      uvmfree(pagetable, 0);\n      return 0;\n  }\nThe function mappages is used to create a pagetable entry for the given physical address.\nAfter the mapping is successful, the system can use the pagetable to convert the virtual address into physical address. That it’s. The rest of the code is to clean up the memory when freeing the process, which is defined in the freeproc function.\nstatic void\nfreeproc(struct proc *p)\n{\n  ...\n  if(p-&gt;usyscall)\n    kfree((void*)p-&gt;usyscall);\n  ...\n}"
  },
  {
    "objectID": "posts/2025-01-05_XV6.html#print-a-page-table",
    "href": "posts/2025-01-05_XV6.html#print-a-page-table",
    "title": "XV6 Series: MIT Lab3 2024",
    "section": "Print a page table",
    "text": "Print a page table\n\nGeneral knowledge:\n\nXv6 uses a three-level pagetable. For each level, there are 2^9 (512) entries. The first and second level entries contain the physical addresses for page-table pages in the lower level, while the lowest level entries contain the physical page number (PPN).\n\n\nThe pagetable entries are stored sequentially in the memory as follows:\n\n| Level2_Entry0 | Level1_Entry0 | Level0_Entry0 | ... | Level2_Entry1 | Level1_Entry0 | Level0_Entry0 | ...    \nThus, the gap between 2 PTE varies by level: - Level 2 entries: 512 * 512 * PGSIZE - Level 1 entries: 512 * PGSIZE - Level 0 entries: PGSIZE\n\nThe virtual address of the first pagetable entry is 0, which is set in the uvmfirst function.\n\nvoid\nuvmfirst(pagetable_t pagetable, uchar *src, uint sz)\n{\n  char *mem;\n\n  if(sz &gt;= PGSIZE)\n    panic(\"uvmfirst: more than a page\");\n  mem = kalloc();\n  memset(mem, 0, PGSIZE);\n  mappages(pagetable, 0, PGSIZE, (uint64)mem, PTE_W|PTE_R|PTE_X|PTE_U);\n  memmove(mem, src, sz);\n}\n\n\nSolution:\nvoid\nvmprint_helper(pagetable_t pagetable, uint64 level, uint64 va) {\n  uint64 sz = 0;\n  if (level == 2) sz = 512 * 512 * PGSIZE; \n  else if (level == 1) sz = 512 * PGSIZE;\n  else sz = PGSIZE;\n  for (int i = 0; i &lt; 512; i++, va += sz) {\n    pte_t pte = *(pagetable + i); // Dereference the pagetable pointer to get the pagetable entry content\n    if ((pte & PTE_V) == 0) continue;\n    for (int j = 0; j &lt; 3 - level; ++j) printf(\" ..\");\n    printf(\"%p: pte %p pa %p\\n\", (void *) va, (void *) pte, (void *) PTE2PA(pte));\n    if (PTE_LEAF(pte) == 0) // if it is not the leave\n        vmprint_helper((void *) PTE2PA(pte), level - 1, va);\n  }\n}"
  },
  {
    "objectID": "posts/2021-08-17-nlp_10_aivivn_product_review_sentiment_analysis.html",
    "href": "posts/2021-08-17-nlp_10_aivivn_product_review_sentiment_analysis.html",
    "title": "AIVIVN Product Review Sentiment Analysis [Pytorch Lightning Sample]",
    "section": "",
    "text": "from google.colab import drive\ndrive.mount('/content/drive')\n\nMounted at /content/drive\n\n\n\nInstall required packages\n\n%%capture\n!pip install pytorch-lightning\n!pip install torchmetrics\n!pip install pyvi \n!pip install torch-summary\n\n\n\nImport required packages\n\nimport re\nimport copy\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Optional, Tuple, Union\nfrom os.path import abspath\nimport torchmetrics\nimport pandas as pd\n\n\n\nHave a closer look at the dataset\nThe data contains user’s reviews following two categories: “positive” and “negative”. There are 27068 sentences in total. * Train: 16087 sentences * Test: 10981 sentences (public: 5454 sentences, private: 5527 sentences) * Labels: 0 (positive), 1 (negative)\nYou can download the dataset here.\n\ntrain_path = \"/content/drive/MyDrive/SLSOPS/dataset/Aivivn_vietnamese_dataset/train.crash\"\ntest_path = \"/content/drive/MyDrive/SLSOPS/dataset/Aivivn_vietnamese_dataset/test.crash\"\n\n\ndef split_array(arr, condition):\n    if len(arr) == 0:\n        return []\n    result = []\n    accumulated = [arr[0]]\n    for ele in arr[1:]:\n        if condition(ele):\n            result.append(copy.deepcopy(accumulated))\n            accumulated = [copy.deepcopy(ele)]\n        else:\n            accumulated.append(copy.deepcopy(ele))\n    result.append(copy.deepcopy(accumulated))\n    return result\n\n\ndef read_file(file_path, is_train=True):\n    file_path = abspath(file_path)\n    data_lines = list(\n        filter(lambda x: x != '', open(file_path).read().split('\\n')))\n    pattern = ('train' if is_train else 'test') + '_[0-9]{5}'\n    datas = split_array(data_lines, lambda x: bool(re.match(pattern, x)))\n    if is_train:\n        result_array = list(map(\n            lambda x: [x[0], ' '.join(x[1:-1]), int(x[-1])], datas))\n    else:\n        result_array = list(map(lambda x: [x[0], ' '.join(x[1:])], datas))\n    columns = ['name', 'text', 'label'] if is_train else ['name', 'text']\n    return pd.DataFrame(result_array, columns=columns)\n\n\ntrain_df = read_file(train_path)\ntest_df = read_file(test_path, is_train=False)\n\n\n# Having a look at the dataset 0: Postitive, 1: Negative\ntrain_df.head()\n\n\n\n\n\n\n\n\nname\ntext\nlabel\n\n\n\n\n0\ntrain_000000\n\"Dung dc sp tot cam on shop Đóng gói sản phẩm...\n0\n\n\n1\ntrain_000001\n\" Chất lượng sản phẩm tuyệt vời . Son mịn nhưn...\n0\n\n\n2\ntrain_000002\n\" Chất lượng sản phẩm tuyệt vời nhưng k có hộp...\n0\n\n\n3\ntrain_000003\n\":(( Mình hơi thất vọng 1 chút vì mình đã kỳ v...\n1\n\n\n4\ntrain_000004\n\"Lần trước mình mua áo gió màu hồng rất ok mà ...\n1\n\n\n\n\n\n\n\n\n# Having a look at the test set\ntest_df.head()\n\n\n\n\n\n\n\n\nname\ntext\n\n\n\n\n0\ntest_000000\n\"Chưa dùng thử nên chưa biết\"\n\n\n1\ntest_000001\n\" Không đáng tiềnVì ngay đợt sale nên mới mua ...\n\n\n2\ntest_000002\n\"Cám ơn shop. Đóng gói sản phẩm rất đẹp và chắ...\n\n\n3\ntest_000003\n\"Vải đẹp.phom oki luôn.quá ưng\"\n\n\n4\ntest_000004\n\"Chuẩn hàng đóng gói đẹp\"\n\n\n\n\n\n\n\n\n\nDefine dataset and dataloader classes\n\nfrom typing import List, Tuple\nimport torchtext\nfrom collections import Counter, OrderedDict\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torchtext.vocab import Vectors, Vocab\n\nclass Tokenizer():\n    def __init__(self, tokenizer: Any):\n        self.counter = Counter(['&lt;pad&gt;', '&lt;unk&gt;'])\n        self.tokenizer = tokenizer\n        self.vocab = None\n        self.update_vocab()\n    \n    def update_vocab(self):\n        # sorted_by_freq_tuples = sorted(self.counter.items()[2:], key=lambda x: x[1], reverse=True)\n        ordered_dict = OrderedDict(self.counter.items())\n        self.vocab = torchtext.vocab.vocab(ordered_dict, min_freq=1)\n\n    def fit_on_texts(self, texts: List[str]):\n        \"\"\"\n        Updates internal vocabulary based on a list of texts.\n        \"\"\"\n        for text in texts:\n            tokens = [t.text for t in self.tokenizer(text)] \n            self.counter.update(tokens)\n        self.update_vocab()\n    \n    def texts_to_sequences(self, texts: List[str], tensor: bool=True) -&gt; List[int]:\n        word2idx = self.vocab.get_stoi()\n        sequences = []\n        for text in texts:\n            seq = [word2idx.get(token.text, word2idx['&lt;unk&gt;']) for token in self.tokenizer(text)]\n            if tensor:\n                seq = torch.tensor(seq)\n            sequences.append(seq)\n        return sequences\n\ndef _load_data_from(data_path: Union[str, Path]):\n    df = read_file(data_path)\n    sents = list(df['text'].str.strip().str.lower())\n    sentiments = list(df['label'])\n    return sents, sentiments\n\ndef _save_to_csv(file_path: Union[str, Path], data):\n    sents, sentiments = data\n    df = pd.DataFrame({\n        \"text\": sents,\n        \"label\": sentiments,\n    })\n    df.to_csv(file_path, index=False)\n    return file_path\n\ndef _preprocess_data(data: Tuple[List[str], List[str]], tokenizer: Tokenizer):\n    sentences, sentiments = data\n    sequences = tokenizer.texts_to_sequences(sentences)\n    sentiment_tensor = torch.tensor(sentiments)\n    # pad sequences\n    sequences = pad_sequence(sequences, batch_first=True)\n    assert len(sequences) == len(sentiments)\n    all_data = []\n    for i in range(len(sentiments)):\n        sample = {\n            'sequence': sequences[i],\n            'sentiment': sentiment_tensor[i]\n        }\n        all_data.append(sample)\n    return all_data\n\ndef build_vocab(tokenizer, data):\n    sentences = data[0]\n    tokenizer.fit_on_texts(sentences)\n\n\nfrom gensim.models import KeyedVectors\nfrom gensim.test.utils import datapath\nimport numpy as np\n\ndef load_pretrained_word_embeddings(w2v_path: str):\n    return KeyedVectors.load_word2vec_format(datapath(w2v_path), binary=False)\n\ndef create_embedding_matrix(w2v_model, vocab: Vocab, path: Union[str, Path]):\n    if os.path.exists(path):\n        print(f'loading embedding matrix from {path}')\n        embedding_matrix = pickle.load(open(path, 'rb'))\n    else:\n        # Calculate vector for OOV token\n        OOV_vec = torch.from_numpy(np.mean(w2v_model.vectors, axis=0))\n        embedding_matrix = torch.zeros((len(vocab), w2v_model.vector_size), \n                                       dtype=torch.float)\n\n        # words that are not availabel in the pretrained word embeddings will be zeros\n        for word, index in vocab.get_stoi().items():\n            if word in w2v_model.vocab:\n                embedding_matrix[index] = torch.from_numpy(w2v_model[word])\n            else:\n                if word == \"&lt;pad&gt;\":\n                    continue\n                embedding_matrix[index] = OOV_vec\n\n        # save embedding matrix\n        pickle.dump(embedding_matrix, open(path, 'wb'))\n    return embedding_matrix\n\nNow we create the datamodule class for the dataset using Pytorch-Lightning Framework. You can read more here.\n\nimport torch\nfrom torch.utils.data import DataLoader, Dataset, random_split\nimport pytorch_lightning as pl\n\nclass AIVIVNDataset(Dataset):\n    def __init__(self, data):\n        self.data = data\n    def __len__(self):\n        return len(self.data)\n    def __getitem__(self, idx):\n        return self.data[idx]\n\nclass AIVIVN(pl.LightningDataModule):\n    \n    def __init__(self, tokenizer, opts: Dict[str, Any]):\n        super().__init__()\n        self.tokenizer = tokenizer\n        self.batch_size = opts['batch_size']\n        self.num_workers = opts['num_workers']\n        self.on_gpu = opts['on_gpu']\n        self.train_ds = None\n        self.val_ds = None\n\n        self.mapping = {\"negative\": 1, \"positive\": 0}\n        self.inverse_mapping = {v: k for k, v in enumerate(self.mapping)}\n    \n    def prepare_data(self, *args, **kwargs) -&gt; None:\n        self.train_path = '/content/drive/MyDrive/SLSOPS/dataset/Aivivn_vietnamese_dataset/train.crash'\n\n    def setup(self, stage: str = None) -&gt; None:\n        if stage == \"fit\" or stage is None:\n            # Load data from files\n            train_data = _load_data_from(self.train_path)\n            preprocessed_data = _preprocess_data(train_data, self.tokenizer)\n            dataset = AIVIVNDataset(preprocessed_data)\n            lengths = [int(len(dataset)*0.85), len(dataset) - int(len(dataset)*0.85)]\n            self.train_ds, self.val_ds = random_split(dataset, lengths)\n\n    def train_dataloader(self):\n        return DataLoader(\n            self.train_ds,\n            shuffle=True,\n            batch_size=self.batch_size,\n            num_workers=self.num_workers,\n            pin_memory=self.on_gpu\n        )\n    \n    def val_dataloader(self):\n        return DataLoader(\n            self.val_ds,\n            shuffle=False,\n            batch_size=self.batch_size,\n            num_workers=self.num_workers,\n            pin_memory=self.on_gpu,\n        )\n    \n    def __repr__(self):\n        basic = f\"AIVIVN Product Review Dataset\\nNum classes: {len(self.mapping)}\\nMapping: {self.mapping}\\n\"\n        if self.train_ds is None and self.val_ds is None:\n            return basic\n        batch = next(iter(self.train_dataloader()))\n        sequences, sentiments = batch['sequence'], batch['sentiment']\n        data = (\n            f\"Train/val sizes: {len(self.train_ds)}, {len(self.val_ds)}\\n\"\n            f\"Batch sequences stats: {(sequences.shape, sequences.dtype)}\\n\"\n            f\"Batch sentiments stats: {(sentiments.shape, sentiments.dtype)}\\n\"\n        )\n        return basic + data\n\n\n\nImplementation (TextCNN)\n\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass ConvPool(nn.Module):\n    def __init__(self, in_channels, out_channels, conv_kernel_sz, pool_kernel_sz):\n        super(ConvPool, self).__init__()\n        self.conv = nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=conv_kernel_sz)\n        self.pool = nn.MaxPool1d(pool_kernel_sz)\n\n    def forward(self, x):\n        out = self.conv(x)\n        out = F.relu(out)\n        out = self.pool(out)\n        return out\n\n\nclass TextCNN(pl.LightningModule):\n    def __init__(self, embeddings, num_classes=2, batch_first=True, lr=1e-3, dropout=0, l2reg=0.01):\n        super().__init__()\n        embedding_dim = embeddings.shape[1]\n        self.embedding = nn.Embedding.from_pretrained(embeddings)\n        kernel_sizes = [3,4,5]\n        self.filters = nn.ModuleList([ConvPool(embedding_dim, 128, conv_kernel_sz=conv_kernel_size, pool_kernel_sz=5) for conv_kernel_size in kernel_sizes])\n        self.conv_pool1 = ConvPool(128, 128, 5, 5)\n        self.conv_pool2 = ConvPool(128, 128, 5, 30)\n        self.flatten = nn.Flatten(start_dim=1)\n        self.linear1 = nn.Linear(256, 128)\n        self.linear2 = nn.Linear(128, num_classes)\n\n        self.lr = lr\n        self.l2reg = l2reg\n\n        self.train_acc = torchmetrics.Accuracy()\n        self.val_acc = torchmetrics.Accuracy()\n        self.val_f1 = torchmetrics.F1(num_classes=2, average='macro')\n        self.test_acc = torchmetrics.Accuracy()\n        self.test_f1 = torchmetrics.F1(num_classes=2, average='macro')\n    \n    def configure_optimizers(self):\n        optim = torch.optim.Adam(self.parameters(), lr=self.lr)\n        return optim\n\n    def forward(self, input):\n        sequences = input['sequence'] # BxS\n        embeds = self.embedding(sequences).permute(0, 2, 1) # BxSxH\n        out_1 = self.filters[0](embeds)\n        out_2 = self.filters[1](embeds)\n        out_3 = self.filters[2](embeds)\n        out = torch.cat((out_1, out_2, out_3), dim=2)\n        out = self.conv_pool1(out)\n        out = self.conv_pool2(out)\n        out = self.flatten(out)\n        out = self.linear1(out)\n        out = F.relu(out)\n        logit = self.linear2(out)\n        return logit\n    \n    def training_step(self, batch, batch_idx):\n        sentiments = batch['sentiment']\n        logits = self.forward(batch)\n        loss = F.cross_entropy(logits, sentiments)\n        scores = F.softmax(logits, dim=-1)\n        self.train_acc(scores, sentiments)\n        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n        self.log('train_acc', self.train_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        return loss\n    \n    def validation_step(self, batch, batch_idx):  # pylint: disable=unused-argument\n        sentiments = batch['sentiment']\n        logits = self.forward(batch)\n        scores = F.softmax(logits, dim=-1)\n        self.val_acc(scores, sentiments)\n        self.val_f1(scores, sentiments)\n        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n        self.log('val_acc', self.val_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        self.log('val_f1', self.val_f1, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n    \n    def test_step(self, batch, batch_idx):  # pylint: disable=unused-argument\n        sentiments = batch['sentiment']\n        logits = self.forward(batch)\n        scores = F.softmax(logits, dim=-1)\n        self.test_acc(scores, sentiments)\n        self.test_f1(scores, sentiments)\n        self.log('test_acc', self.test_acc, on_step=False, on_epoch=True, logger=True)\n        self.log('test_f1', self.test_f1, on_step=False, on_epoch=True, logger=True)\n    \n\nnn.ModuleList does not have a forward() method because it does not define any neural network, that is, there is no connection between each of the nn.Module’s that it stores. You may use it to store nn.Module’s, just like you use Python lists to store other types of objects (integers, strings, etc).\nThe advantage of using nn.ModuleList instead of using conventional Python lists to store nn.Module’s is that Pytorch is “aware” of the existence of the nn.Module’s inside an nn.ModuleList, which is not the case for Python lists. When using a Python list instead of a nn.ModuleList, the optimizer() will raise the error saying that the model has no parameters. This is because PyTorch does not see the parameters of the layers stored in a Python list. If you use a nn.ModuleList instead, you’ll get no error.\n\n\nTraining\n\n# Load pretrained w2v model\nw2v_path = \"/content/drive/MyDrive/SLSOPS/pretrained_w2v/word2vec_vi_words_100dims.txt\"\nw2v_model = load_pretrained_word_embeddings(w2v_path)\n\n\n# Load dataset\ntrain_path = '/content/drive/MyDrive/SLSOPS/dataset/Aivivn_vietnamese_dataset/train.crash'\ntrain_data = _load_data_from(train_path)\n\n\n# Create Tokenizer\nfrom spacy.lang.vi import Vietnamese\nnlp = Vietnamese()\ntokenizer = Tokenizer(nlp)\n\n# Build vocabulary\nbuild_vocab(tokenizer, [train_data[0]])\n\n\nimport os\nimport pickle\n\n# Create embedding matrix from pretrained w2v\nembedding_matrix = create_embedding_matrix(w2v_model, tokenizer.vocab, \"embedding_matrix.dat\")\n\n\noptions = {\n    \"on_gpu\": True,\n    \"batch_size\": 16,\n    \"num_workers\": 2\n}\n\n\n# Create DataModule\ndatamodule = AIVIVN(tokenizer, options)\n\n\nfrom pytorch_lightning.callbacks import ModelCheckpoint\ncheckpoint_callback = ModelCheckpoint(\n    monitor='val_acc', # save the model with the best validation accuracy\n    dirpath='checkpoints',\n    mode='max',\n)\n\n# Set hyper-parameters\nlr = 1e-3 \nnum_epochs = 20\nl2reg = 1e-5\ndropout = 0.0\n\ntrainer = pl.Trainer(gpus=1, max_epochs=num_epochs, callbacks=[checkpoint_callback], deterministic=True)\n# trainer = pl.Trainer(fast_dev_run=True, gpus=1) #Debug \n# trainer = pl.Trainer(overfit_batches=0.1, max_epochs=num_epochs, gpus=1) #Debug\nmodel = TextCNN(embedding_matrix, lr=lr, l2reg=l2reg, dropout=dropout)\ntrainer.fit(model, datamodule)\n\nGPU available: True, used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\n  | Name       | Type       | Params\n------------------------------------------\n0 | embedding  | Embedding  | 1.2 M \n1 | filters    | ModuleList | 153 K \n2 | conv_pool1 | ConvPool   | 82.0 K\n3 | conv_pool2 | ConvPool   | 82.0 K\n4 | flatten    | Flatten    | 0     \n5 | linear1    | Linear     | 32.9 K\n6 | linear2    | Linear     | 258   \n7 | train_acc  | Accuracy   | 0     \n8 | val_acc    | Accuracy   | 0     \n9 | val_f1     | F1         | 0     \n------------------------------------------\n351 K     Trainable params\n1.2 M     Non-trainable params\n1.6 M     Total params\n6.283     Total estimated model params size (MB)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSave model and tokenizer for inference\n\n# Load best model from training\nnew_model = TextCNN.load_from_checkpoint('/content/checkpoints/epoch=1-step=1709.ckpt', embeddings=embedding_matrix)\n\n\n# Test the loaded model with the validation set to double check\ntrainer.test(my_model, datamodule.val_dataloader())\n\n/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/datamodule.py:424: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n  f\"DataModule.{name} has already been called, so it will not be called again. \"\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\n\n\n\n\n--------------------------------------------------------------------------------\nDATALOADER:0 TEST RESULTS\n{'test_acc': 0.8881524205207825, 'test_f1': 0.8867566585540771}\n--------------------------------------------------------------------------------\n\n\n/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/datamodule.py:424: LightningDeprecationWarning: DataModule.teardown has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.teardown.\n  f\"DataModule.{name} has already been called, so it will not be called again. \"\n\n\n[{'test_acc': 0.8881524205207825, 'test_f1': 0.8867566585540771}]\n\n\n\n# Save tokenizer\nimport pickle\nwith open('tokenizer.pkl', 'wb') as outp:\n    pickle.dump(tokenizer, outp, pickle.HIGHEST_PROTOCOL)\n\n\n# Save entire model\ntorch.save(new_model, \"model\")\n\n\n\nInference\nTo do the inference, we have to do 2 steps: 1. Loading model and the tokenizer. 2. Define the preprocessing function to preprocess the input before feeding into the model. 3. (Optional) Convert the predictions to labels.\n\nimport torch.nn.functional as F\ninputs = [\":(( Mình hơi thất vọng 1 chút vì mình đã kỳ vọng cuốn sách khá nhiều hi vọng nó sẽ nói về việc học tập của cách sinh viên trường Harvard ra sao những nỗ lực của họ như thế nào 4h sáng? tại sao họ lại phải thức dậy vào thời khắc đấy? sau đó là cả một câu chuyện ra sao. Cái mình thực sự cần ở đây là câu chuyện ẩn dấu trong đó để tự bản thân mỗi người cảm nhận và đi sâu vào lòng người hơn. Còn cuốn sách này chỉ đơn thuần là cuốn sách dạy kĩ năng mà hầu như sách nào cũng đã có. BUồn...\", \"Chất lượng sản phẩm tuyệt vời nhưng k có hộp k có dây giày đen k có tất\"]\n# preprocess input\ndef _preprocess_data_for_inference(sentences: List[str], tokenizer: Tokenizer):\n    sequences = tokenizer.texts_to_sequences(sentences, tensor=True)\n    # pad sequences\n    sequences = torch.stack([F.pad(seq, (0, 557 - len(seq)), 'constant', 0) for seq in sequences])\n    return {\"sequence\": sequences}\ninput_data = _preprocess_data_for_inference(inputs, tokenizer)\nnew_model.eval()\npredictions = new_model(input_data)\n\n\ntorch.argmax(predictions, axis=-1)\n\ntensor([1, 0])\n\n\n\ntrain_df.iloc[3]['text']\n\n'\":(( Mình hơi thất vọng 1 chút vì mình đã kỳ vọng cuốn sách khá nhiều hi vọng nó sẽ nói về việc học tập của cách sinh viên trường Harvard ra sao những nỗ lực của họ như thế nào 4h sáng? tại sao họ lại phải thức dậy vào thời khắc đấy? sau đó là cả một câu chuyện ra sao. Cái mình thực sự cần ở đây là câu chuyện ẩn dấu trong đó để tự bản thân mỗi người cảm nhận và đi sâu vào lòng người hơn. Còn cuốn sách này chỉ đơn thuần là cuốn sách dạy kĩ năng mà hầu như sách nào cũng đã có. BUồn...\"'\n\n\n\n\nDebug\n\n# Random check the pretrain word embeddings\nA = embedding_matrix[tokenizer.vocab.get_stoi()['ăn_nằm']]\nB = w2v_model[\"ăn_nằm\"]\nnp.array_equal(A,B)\n\n\n\nLesson Learned\n\nMake sure to check the train datamodule when debugging the model.\nDon’t just copy the code from previous code. Make sure to read through it before using to mitigate hard-to-see bugs. In this post, the bug lies in the way we load the pretrained word embeddings."
  },
  {
    "objectID": "posts/2021-08-18-nlp_11_extract_aspects_from_sentence_using_denpendency_parsing_and_pos_tags.html",
    "href": "posts/2021-08-18-nlp_11_extract_aspects_from_sentence_using_denpendency_parsing_and_pos_tags.html",
    "title": "Extract aspects from sentence using denpendency parsing and POS tags",
    "section": "",
    "text": "from google.colab import drive\ndrive.mount('/content/drive')\n\nMounted at /content/drive"
  },
  {
    "objectID": "posts/2021-08-18-nlp_11_extract_aspects_from_sentence_using_denpendency_parsing_and_pos_tags.html#rules",
    "href": "posts/2021-08-18-nlp_11_extract_aspects_from_sentence_using_denpendency_parsing_and_pos_tags.html#rules",
    "title": "Extract aspects from sentence using denpendency parsing and POS tags",
    "section": "Rules",
    "text": "Rules\nWe check 2 cases: 1. The token POS is N (Noun) and the Dependency tag is not nsubj. 1. The token POS is N (Noun) and the Dependency tag is nsubj.\nNote: I come up with these rules by trying with many samples =)) No magic behind it.\n\naspects = []\ndoc = nlp(sentences[25])\nprint(doc)\nfor i, token in enumerate(doc):\n    # Case 1: \n    if token.tag_ == \"N\" and token.dep_ != \"nsubj\":\n        aspect = token.text\n        for child in token.children:\n            if child.dep_ == \"compound\":\n                if child in token.lefts:\n                    aspect = f\"{child.text} {aspect}\"\n                elif child in token.rights:\n                    aspect = f\"{aspect} {child.text}\"\n            elif child.dep_ == \"amod\":\n                opinion = child.text\n                for gchild in child.children:\n                    if gchild.dep_ == \"advmod\":\n                        if gchild in child.lefts:\n                            opinion = f\"{gchild.text} {opinion}\"\n                        elif gchild in child.rights:\n                            opinion = f\"{opinion} {gchild.text}\"\n                asp_obj = AsOp(aspect=aspect, opinion=opinion)\n                aspects.append(asp_obj)\n            elif child.dep_ == \"conj\":\n                asp_obj = None\n                if child.tag_ == \"N\":\n                    aspect = child.text\n                    opinion = \"\"\n                    for gchild in child.rights:\n                        if gchild.dep_ == \"xcomp\" and gchild.tag_ == \"A\":\n                            opinion = gchild.text\n                    if opinion:\n                        asp_obj = AsOp(aspect=aspect, opinion=opinion)\n                elif child.tag_ == \"A\":\n                    asp_obj = AsOp(aspect=aspect, opinion=child.text)\n                if asp_obj: \n                    aspects.append(asp_obj)\n            \n    # Case 2:\n    elif token.tag_ == \"N\" and token.dep_ == \"nsubj\":\n        opinion = \"\"\n        if token.head.tag_ == \"A\":\n            opinion = token.head.text\n            \n        for child in token.head.children:\n            if child.text == token.text:\n                continue\n            elif child.tag_ == \"A\" or child.tag_ == \"R\":\n                if opinion:\n                    if child in token.head.lefts: \n                        opinion = f\"{child.text} {opinion}\"\n                    else:\n                        opinion = f\"{opinion} {child.text}\"\n                else:\n                    opinion = child.text\n                    for gchild in child.children:\n                        if gchild.dep_ == \"advmod\":\n                            if gchild in child.lefts:\n                                opinion = f\"{gchild.text} {opinion}\"\n                            elif gchild in child.rights:\n                                opinion = f\"{opinion} {gchild.text}\"\n                asp_obj = AsOp(aspect=token.text, opinion=opinion)\n                aspects.append(asp_obj)\nprint(aspects)\n\nđến chán giờ cứ sử_dụng là bị cúp nguồn điện thì ai dám bật\n[]\n\n\n\nfrom dataclasses import dataclass\nfrom typing import Any\n@dataclass\nclass AsOp:\n    aspect: Any = None\n    opinion: Any = None\n\n\nfrom pyvi import ViTokenizer, ViPosTagger\nsentence = df['tokenized_spacy'][6]\n# print(sentence)\nsentences = list(df['tokenized_spacy'])[:100]\naspects = []\ncnt = 0\nfor sentence in sentences:\n    try:\n        doc = nlp(sentence)\n        for i, token in enumerate(doc):\n            if token.tag_ == \"N\" and token.dep_ != \"nsubj\":\n                aspect = token.text\n                for child in token.children:\n                    if child.dep_ == \"compound\":\n                        if child in token.lefts:\n                            aspect = f\"{child.text} {aspect}\"\n                        elif child in token.rights:\n                            aspect = f\"{aspect} {child.text}\"\n                    elif child.dep_ == \"amod\":\n                        opinion = child.text\n                        for gchild in child.children:\n                            if gchild.dep_ == \"advmod\":\n                                if gchild in child.lefts:\n                                    opinion = f\"{gchild.text} {opinion}\"\n                                elif gchild in child.rights:\n                                    opinion = f\"{opinion} {gchild.text}\"\n                        asp_obj = AsOp(aspect=aspect, opinion=opinion)\n                        aspects.append(asp_obj)\n                    elif child.dep_ == \"conj\":\n                        asp_obj = None\n                        if child.tag_ == \"N\":\n                            aspect = child.text\n                            opinion = \"\"\n                            for gchild in child.rights:\n                                if gchild.dep_ == \"xcomp\" and gchild.tag_ == \"A\":\n                                    opinion = gchild.text\n                            if opinion:\n                                asp_obj = AsOp(aspect=aspect, opinion=opinion)\n                        elif child.tag_ == \"A\":\n                            asp_obj = AsOp(aspect=aspect, opinion=child.text)\n                        if asp_obj: \n                            aspects.append(asp_obj)\n                    \n            elif token.tag_ == \"N\" and token.dep_ == \"nsubj\":\n                opinion = \"\"\n                if token.head.tag_ == \"A\":\n                    opinion = token.head.text\n                    \n                for child in token.head.children:\n                    if child.text == token.text:\n                        continue\n                    elif child.tag_ == \"A\" or child.tag_ == \"R\":\n                        if opinion:\n                            if child in token.head.lefts: \n                                opinion = f\"{child.text} {opinion}\"\n                            else:\n                                opinion = f\"{opinion} {child.text}\"\n                        else:\n                            opinion = child.text\n                            for gchild in child.children:\n                                if gchild.dep_ == \"advmod\":\n                                    if gchild in child.lefts:\n                                        opinion = f\"{gchild.text} {opinion}\"\n                                    elif gchild in child.rights:\n                                        opinion = f\"{opinion} {gchild.text}\"\n                        asp_obj = AsOp(aspect=token.text, opinion=opinion)\n                        aspects.append(asp_obj)\n    except:\n        print(sentence)\n        cnt += 1\n\n\naspects\n\n[AsOp(aspect='shipper', opinion='vào'),\n AsOp(aspect='nhân_viên', opinion='tốt'),\n AsOp(aspect='sản_phẩm', opinion='đẹp'),\n AsOp(aspect='giá', opinion='không tặng_vật_tư'),\n AsOp(aspect='giá', opinion='không tặng_vật_tư giống'),\n AsOp(aspect='giá', opinion='khoảng'),\n AsOp(aspect='giá', opinion='hơn khoảng'),\n AsOp(aspect='giá', opinion='hơn'),\n AsOp(aspect='tiền', opinion='hơn'),\n AsOp(aspect='tiền', opinion='không hơn'),\n AsOp(aspect='hàng', opinion='đúng'),\n AsOp(aspect='tiki giao_nhận', opinion='tốt'),\n AsOp(aspect='máy', opinion='tốt'),\n AsOp(aspect='máy', opinion='rất êm'),\n AsOp(aspect='hàng', opinion='nhanh'),\n AsOp(aspect='hàng', opinion='nhanh ổn'),\n AsOp(aspect='sản_phẩm', opinion='tạm'),\n AsOp(aspect='hàng', opinion='nhanh'),\n AsOp(aspect='máy_lạnh', opinion='chưa'),\n AsOp(aspect='máy_lạnh', opinion='chưa được'),\n AsOp(aspect='máy', opinion='chỉ'),\n AsOp(aspect='tiền', opinion='ồn_ào'),\n AsOp(aspect='âm_thanh', opinion='ồn_ào'),\n AsOp(aspect='hàng', opinion='mới'),\n AsOp(aspect='hàng', opinion='cũ'),\n AsOp(aspect='điện', opinion='cực_kỳ tốt'),\n AsOp(aspect='điện', opinion='cực_kỳ tốt liên_tục'),\n AsOp(aspect='sản_phẩm', opinion='cùng'),\n AsOp(aspect='thực_tế', opinion='gần'),\n AsOp(aspect='tiếng', opinion='to'),\n AsOp(aspect='tiếng', opinion='không êm'),\n AsOp(aspect='pin', opinion='không'),\n AsOp(aspect='đội_ngũ', opinion='rất'),\n AsOp(aspect='giá', opinion='thêm'),\n AsOp(aspect='người', opinion='xanh'),\n AsOp(aspect='tiki', opinion='rẻ'),\n AsOp(aspect='máy', opinion='đúng đúng'),\n AsOp(aspect='máy', opinion='khá to'),\n AsOp(aspect='máy', opinion='khá to êm'),\n AsOp(aspect='máy', opinion='khá to êm lại'),\n AsOp(aspect='khi', opinion='sẽ êm'),\n AsOp(aspect='máy', opinion='quá ồn'),\n AsOp(aspect='bạn', opinion='dễ_thương'),\n AsOp(aspect='bạn', opinion='dễ_thương lắm'),\n AsOp(aspect='hàng', opinion='nhanh'),\n AsOp(aspect='độ', opinion='nhiều'),\n AsOp(aspect='độ', opinion='bền'),\n AsOp(aspect='ngày', opinion='hợp_lý'),\n AsOp(aspect='đội', opinion='nhiều'),\n AsOp(aspect='điều', opinion='hòa'),\n AsOp(aspect='sản_phẩm', opinion='không'),\n AsOp(aspect='sản_phẩm', opinion='mới không'),\n AsOp(aspect='sản_phẩm', opinion='mới không ra'),\n AsOp(aspect='sản_phẩm', opinion='mới không ra rồi'),\n AsOp(aspect='điểm', opinion='vô_cùng'),\n AsOp(aspect='điều', opinion='hòa'),\n AsOp(aspect='điều', opinion='hòa'),\n AsOp(aspect='điều', opinion='cũ'),\n AsOp(aspect='phí', opinion='không'),\n AsOp(aspect='lần', opinion='cuối_cùng'),\n AsOp(aspect='chiều', opinion='dài'),\n AsOp(aspect='cái màng', opinion='lọc'),\n AsOp(aspect='biên_độ', opinion='nóng'),\n AsOp(aspect='biên_độ', opinion='lạnh'),\n AsOp(aspect='biên_độ', opinion='cao'),\n AsOp(aspect='tổng_chi_phí', opinion='hết'),\n AsOp(aspect='bao', opinion='gôm'),\n AsOp(aspect='lòng', opinion='thật buồn'),\n AsOp(aspect='giá', opinion='rẻ'),\n AsOp(aspect='giá', opinion='rât'),\n AsOp(aspect='giá', opinion='hợp_lý'),\n AsOp(aspect='7tr', opinion='tròn'),\n AsOp(aspect='cục', opinion='không'),\n AsOp(aspect='cục', opinion='không có'),\n AsOp(aspect='máy', opinion='hơi lạnh'),\n AsOp(aspect='cảm_giác', opinion='rất dễ_chịu'),\n AsOp(aspect='cục', opinion='lạnh'),\n AsOp(aspect='cục', opinion='nóng khoảng'),\n AsOp(aspect='cánh_quạt', opinion='không'),\n AsOp(aspect='cánh_quạt', opinion='không được'),\n AsOp(aspect='cục', opinion='nóng'),\n AsOp(aspect='máy_lạnh', opinion='rất tận_tình'),\n AsOp(aspect='máy_lạnh', opinion='rất tận_tình kém'),\n AsOp(aspect='nhân_viên', opinion='rất tận_tình'),\n AsOp(aspect='nhân_viên', opinion='rất tận_tình kém'),\n AsOp(aspect='dịch_vụ', opinion='rất kém'),\n AsOp(aspect='máy_lạnh', opinion='tạm ổn'),\n AsOp(aspect='máy_lạnh', opinion='tạm ổn êm'),\n AsOp(aspect='cục', opinion='nóng rất'),\n AsOp(aspect='dịch_vụ', opinion='khá ổn'),\n AsOp(aspect='máy', opinion='lạnh'),\n AsOp(aspect='mát', opinion='lạnh'),\n AsOp(aspect='sản_phẩm', opinion='mới'),\n AsOp(aspect='hàng', opinion='nhanh'),\n AsOp(aspect='máy', opinion='êm'),\n AsOp(aspect='máy', opinion='êm ít'),\n AsOp(aspect='máy', opinion='đẹp'),\n AsOp(aspect='máy', opinion='tốt'),\n AsOp(aspect='cục', opinion='dễ'),\n AsOp(aspect='thiết_kế', opinion='trang_nhã'),\n AsOp(aspect='cục', opinion='mạnh_mẽ'),\n AsOp(aspect='cục', opinion='cứng_cáp'),\n AsOp(aspect='tính_năng', opinion='nhiều'),\n AsOp(aspect='máy', opinion='không'),\n AsOp(aspect='tốc_độ gió', opinion='phù_hợp'),\n AsOp(aspect='kích_thước', opinion='khác'),\n AsOp(aspect='chức_năng', opinion='đầy_đủ')]"
  },
  {
    "objectID": "posts/2021-06-26-nlp_4_attention_based_lstm_for_aspect_level_sentiment_classification.html",
    "href": "posts/2021-06-26-nlp_4_attention_based_lstm_for_aspect_level_sentiment_classification.html",
    "title": "Attention based LSTM for Aspect level Sentiment Classification",
    "section": "",
    "text": "The full notebook is available here."
  },
  {
    "objectID": "posts/2021-06-26-nlp_4_attention_based_lstm_for_aspect_level_sentiment_classification.html#at-lstm",
    "href": "posts/2021-06-26-nlp_4_attention_based_lstm_for_aspect_level_sentiment_classification.html#at-lstm",
    "title": "Attention based LSTM for Aspect level Sentiment Classification",
    "section": "AT-LSTM",
    "text": "AT-LSTM\n\nLSTM with Aspect Embedding (AE-LSTM)\nAspect information is important when doing classificaiton on the sentence. We may get different polarities with different aspects. The author proposed to learn an embedding vector for each aspect.\n\n\nAttention-based LSTM (AT-LSTM)\nThe standard LSTM cannot detect which is the important part for aspect-level sentiment classification. The author proposed to design an attention mechanism capturing the key part of sentence in response to a given aspect.\n\nfrom IPython.display import Image\nImage(filename='/Users/minhdang/Desktop/AT-LSTM.png')\n\n\n\n\n\n\n\n\n\nclass AT_LSTM(pl.LightningModule):\n    def __init__(self, embeddings, hidden_size, aspect_hidden_size, num_layers=1, num_classes=3, batch_first=True, lr=1e-3, dropout=0, l2reg=0.01):\n        super().__init__()\n        embedding_dim = embeddings.shape[1]\n        self.embedding = nn.Embedding.from_pretrained(embeddings) # load pre-trained word embeddings\n        self.aspect_embedding = nn.Embedding(5, embedding_dim)\n        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first=batch_first, dropout=dropout)\n        self.linear_h = nn.Linear(hidden_size, hidden_size, bias=False)\n        self.linear_v = nn.Linear(aspect_hidden_size, aspect_hidden_size, bias=False)\n        self.linear_p = nn.Linear(hidden_size, hidden_size, bias=False)\n        self.linear_x = nn.Linear(hidden_size, hidden_size, bias=False)\n        self.linear = nn.Linear(hidden_size + aspect_hidden_size, 1)\n        self.linear_s = nn.Linear(hidden_size, num_classes)\n        self.batch_first = batch_first\n\n        self.lr = lr\n        self.l2reg = l2reg\n        # Define metrics \n        self.train_acc = torchmetrics.Accuracy() \n        self.val_acc = torchmetrics.Accuracy()\n        self.val_f1 = torchmetrics.F1(num_classes=3, average='macro')\n        self.test_acc = torchmetrics.Accuracy()\n        self.test_f1 = torchmetrics.F1(num_classes=3, average='macro')\n\n\n    def configure_optimizers(self):\n        optim = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.l2reg)\n        return optim\n\n    def forward(self, input):\n        sequences, seq_lens, aspect_seqs = input['sequence'], input['seq_len'], input['aspect']\n\n        # Covert sequence to embeddings\n        embeds = self.embedding(sequences)\n        # Get the max sequence length\n        max_seq_len = torch.max(seq_lens)\n        # Convert aspect to embeddings\n        aspect_embeds = self.aspect_embedding(aspect_seqs) \n\n        packed_embeds = pack_padded_sequence(embeds, seq_lens.cpu(), batch_first=self.batch_first, enforce_sorted=False)\n        H, (h, c) = self.lstm(packed_embeds) \n        padded_H, lens = pad_packed_sequence(H, batch_first=True) \n\n        Wh_H = self.linear_h(padded_H)\n        Wv_va = self.linear_v(aspect_embeds)\n        Wv_va = Wv_va.unsqueeze(1).repeat(1, max_seq_len, 1)\n        M = torch.tanh(torch.cat([Wh_H, Wv_va], dim=-1))\n        \n        # Calculate attention score\n        score = self.linear(M).squeeze()\n        att_mask = torch.arange(max_seq_len, device=self.device)[None,:] &lt; seq_lens[:, None]\n        # Create mask to zero out attention scores for padding tokens\n        score[~att_mask] = float('-inf')\n        \n        alpha = F.softmax(score, dim=-1).unsqueeze(2)\n        r = torch.matmul(padded_H.transpose(-2,-1), alpha).squeeze()\n        final_h = torch.tanh(self.linear_p(r) + self.linear_x(h[-1]))\n        out = self.linear_s(final_h)\n        return out\n    \n    def training_step(self, batch, batch_idx):\n        sentiments = batch['sentiment']\n        logits = self.forward(batch)\n        loss = F.cross_entropy(logits, sentiments)\n        scores = F.softmax(logits, dim=-1)\n        self.train_acc(scores, sentiments)\n        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n        self.log('train_acc', self.train_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        return loss\n    \n    def validation_step(self, batch, batch_idx):  # pylint: disable=unused-argument\n        sentiments = batch['sentiment']\n        logits = self.forward(batch)\n        loss = F.cross_entropy(logits, sentiments)\n        scores = F.softmax(logits, dim=-1)\n        self.val_acc(scores, sentiments)\n        self.val_f1(scores, sentiments)\n        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n        self.log('val_acc', self.val_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        self.log('val_f1', self.val_f1, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n\n    def test_step(self, batch, batch_idx):  # pylint: disable=unused-argument\n        sentiments = batch['sentiment']\n        logits = self.forward(batch)\n        scores = F.softmax(logits, dim=-1)\n        self.test_acc(scores, sentiments)\n        self.test_f1(scores, sentiments)\n        self.log('test_acc', self.test_acc, on_step=False, on_epoch=True, logger=True)\n        self.log('test_f1', self.test_f1, on_step=False, on_epoch=True, logger=True)"
  },
  {
    "objectID": "posts/2021-06-26-nlp_4_attention_based_lstm_for_aspect_level_sentiment_classification.html#atae-lstm",
    "href": "posts/2021-06-26-nlp_4_attention_based_lstm_for_aspect_level_sentiment_classification.html#atae-lstm",
    "title": "Attention based LSTM for Aspect level Sentiment Classification",
    "section": "ATAE-LSTM",
    "text": "ATAE-LSTM\nTo take advanatage of aspect information, we append the input aspect embedding into each word input vector. By doing that, the inter-dependence between words and the input aspect can be modeled.\n\nfrom IPython.display import Image\nImage(filename='/Users/minhdang/Desktop/ATAE-LSTM.png')\n\n\n\n\n\n\n\n\n\nclass ATAE_LSTM(pl.LightningModule):\n    def __init__(self, embeddings, hidden_size, aspect_hidden_size, num_layers=1, num_classes=3, batch_first=True, lr=1e-3, dropout=0, l2reg=0.01):\n        super().__init__()\n        embedding_dim = embeddings.shape[1]\n        self.embedding = nn.Embedding.from_pretrained(embeddings) # load pre-trained word embeddings\n        self.aspect_embedding = nn.Embedding(5, embedding_dim)\n        self.lstm = nn.LSTM(2*embedding_dim, hidden_size, num_layers, batch_first=batch_first, dropout=dropout)\n        self.linear_h = nn.Linear(hidden_size, hidden_size, bias=False)\n        self.linear_v = nn.Linear(aspect_hidden_size, aspect_hidden_size, bias=False)\n        self.linear_p = nn.Linear(hidden_size, hidden_size, bias=False)\n        self.linear_x = nn.Linear(hidden_size, hidden_size, bias=False)\n        self.linear = nn.Linear(hidden_size + aspect_hidden_size, 1)\n        self.linear_s = nn.Linear(hidden_size, num_classes)\n        self.batch_first = batch_first\n\n        self.lr = lr\n        self.l2reg = l2reg\n        # Define metrics \n        self.train_acc = torchmetrics.Accuracy() \n        self.val_acc = torchmetrics.Accuracy()\n        self.val_f1 = torchmetrics.F1(num_classes=3, average='macro')\n        self.test_acc = torchmetrics.Accuracy()\n        self.test_f1 = torchmetrics.F1(num_classes=3, average='macro')\n\n    def configure_optimizers(self):\n        optim = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.l2reg)\n        return optim\n\n    def forward(self, input):\n        sequences, seq_lens, aspect_seqs = input['sequence'], input['seq_len'], input['aspect']\n\n        # Covert sequence to embeddings\n        embeds = self.embedding(sequences)       \n        # Get the max sequence length\n        max_seq_len = torch.max(seq_lens)  \n        # Convert aspect to embeddings\n        aspect_embeds = self.aspect_embedding(aspect_seqs)\n        # Repeat the aspect vector across the dimension 1\n        aspect_embeds_repeat = aspect_embeds.unsqueeze(1).repeat(1,embeds.shape[1],1)\n        # Append the aspect vector to the input word vector\n        embeds = torch.cat([embeds, aspect_embeds_repeat], dim=-1)\n\n        packed_embeds = pack_padded_sequence(embeds, seq_lens.cpu(), batch_first=self.batch_first, enforce_sorted=False)\n        H, (h, c) = self.lstm(packed_embeds) \n        padded_H, lens = pad_packed_sequence(H, batch_first=True)\n\n        Wh_H = self.linear_h(padded_H)\n        Wv_va = self.linear_v(aspect_embeds) \n        Wv_va = Wv_va.unsqueeze(1).repeat(1, max_seq_len, 1)\n        M = torch.tanh(torch.cat([Wh_H, Wv_va], dim=-1))\n        \n        # Calculate attention score\n        score = self.linear(M).squeeze()    \n        # Create mask to zero out attention scores for padding tokens\n        att_mask = torch.arange(max_seq_len, device=self.device)[None,:] &lt; seq_lens[:, None]\n        score[~att_mask] = float('-inf')\n \n        alpha = F.softmax(score, dim=-1).unsqueeze(2)\n        r = torch.matmul(padded_H.transpose(-2,-1), alpha).squeeze()\n        final_h = torch.tanh(self.linear_p(r) + self.linear_x(h[-1]))\n        out = self.linear_s(final_h) \n        return out\n    \n    def training_step(self, batch, batch_idx):\n        sentiments = batch['sentiment']\n        logits = self.forward(batch)\n        loss = F.cross_entropy(logits, sentiments)\n        scores = F.softmax(logits, dim=-1)\n        self.train_acc(scores, sentiments)\n        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n        self.log('train_acc', self.train_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        return loss\n    \n    def validation_step(self, batch, batch_idx):  # pylint: disable=unused-argument\n        sentiments = batch['sentiment']\n        logits = self.forward(batch)\n        loss = F.cross_entropy(logits, sentiments)\n        scores = F.softmax(logits, dim=-1)\n        self.val_acc(scores, sentiments)\n        self.val_f1(scores, sentiments)\n        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n        self.log('val_acc', self.val_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        self.log('val_f1', self.val_f1, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n\n    def test_step(self, batch, batch_idx):  # pylint: disable=unused-argument\n        sentiments = batch['sentiment']\n        logits = self.forward(batch)\n        scores = F.softmax(logits, dim=-1)\n        self.test_acc(scores, sentiments)\n        self.test_f1(scores, sentiments)\n        self.log('test_acc', self.test_acc, on_step=False, on_epoch=True, logger=True)\n        self.log('test_f1', self.test_f1, on_step=False, on_epoch=True, logger=True)"
  },
  {
    "objectID": "posts/2021-06-26-nlp_4_attention_based_lstm_for_aspect_level_sentiment_classification.html#at-lstm-1",
    "href": "posts/2021-06-26-nlp_4_attention_based_lstm_for_aspect_level_sentiment_classification.html#at-lstm-1",
    "title": "Attention based LSTM for Aspect level Sentiment Classification",
    "section": "AT-LSTM",
    "text": "AT-LSTM\n\ncheckpoint_callback = ModelCheckpoint(\n    monitor='val_acc', # save the model with the best validation accuracy\n    dirpath='checkpoints',\n    mode='max',\n)\n\ntb_logger = pl_loggers.TensorBoardLogger('logs/') # create logger for tensorboard\n\n# Set hyper-parameters\nlr = 1e-3 \nhidden_size = 300\naspect_embedding_dim = 300\nnum_epochs = 30\nl2reg = 0.0 \n\ntrainer = pl.Trainer(gpus=1, max_epochs=num_epochs, logger=tb_logger, callbacks=[checkpoint_callback], deterministic=True)\n# trainer = pl.Trainer(fast_dev_run=True) #Debug \n# trainer = pl.Trainer(overfit_batches=0.025, max_epochs=num_epochs) #Debug\nmodel = AT_LSTM(embedding_matrix, hidden_size, aspect_embedding_dim, lr=lr, l2reg=l2reg)\ntrainer.fit(model, datamodule)\n\nGPU available: True, used: True\nTPU available: False, using: 0 TPU cores\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\n   | Name             | Type      | Params\n------------------------------------------------\n0  | embedding        | Embedding | 1.3 M \n1  | aspect_embedding | Embedding | 1.5 K \n2  | lstm             | LSTM      | 722 K \n3  | linear_h         | Linear    | 90.0 K\n4  | linear_v         | Linear    | 90.0 K\n5  | linear_p         | Linear    | 90.0 K\n6  | linear_x         | Linear    | 90.0 K\n7  | linear           | Linear    | 601   \n8  | linear_s         | Linear    | 903   \n9  | train_acc        | Accuracy  | 0     \n10 | val_acc          | Accuracy  | 0     \n11 | val_f1           | F1        | 0     \n12 | test_acc         | Accuracy  | 0     \n13 | test_f1          | F1        | 0     \n------------------------------------------------\n1.1 M     Trainable params\n1.3 M     Non-trainable params\n2.4 M     Total params\n9.708     Total estimated model params size (MB)\n\n\n\n\n\nGlobal seed set to 2401\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntrainer.test(ckpt_path=checkpoint_callback.best_model_path)\n\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\n\n\n\n\n\n--------------------------------------------------------------------------------\nDATALOADER:0 TEST RESULTS\n{'test_acc': 0.8150510191917419, 'test_f1': 0.6747192740440369}\n--------------------------------------------------------------------------------\n\n\n[{'test_acc': 0.8150510191917419, 'test_f1': 0.6747192740440369}]"
  },
  {
    "objectID": "posts/2021-06-26-nlp_4_attention_based_lstm_for_aspect_level_sentiment_classification.html#atae-lstm-1",
    "href": "posts/2021-06-26-nlp_4_attention_based_lstm_for_aspect_level_sentiment_classification.html#atae-lstm-1",
    "title": "Attention based LSTM for Aspect level Sentiment Classification",
    "section": "ATAE-LSTM",
    "text": "ATAE-LSTM\n\ncheckpoint_callback = ModelCheckpoint(\n    monitor='val_acc', # save the model with the best validation accuracy\n    dirpath='checkpoints',\n    mode='max',\n)\n\ntb_logger = pl_loggers.TensorBoardLogger('logs/') # create logger for tensorboard\n\n# Set hyper-parameters\nlr = 1e-3 \nhidden_size = 300\naspect_embedding_dim = 300\nnum_epochs = 30\nl2reg = 0.0 \n\ntrainer = pl.Trainer(gpus=1, max_epochs=num_epochs, logger=tb_logger, callbacks=[checkpoint_callback], deterministic=True)\n# trainer = pl.Trainer(fast_dev_run=True) #Debug \n# trainer = pl.Trainer(overfit_batches=0.025, max_epochs=num_epochs) #Debug\nmodel = ATAE_LSTM(embedding_matrix, hidden_size, aspect_embedding_dim, lr=lr, l2reg=l2reg)\ntrainer.fit(model, datamodule)\n\nGPU available: True, used: True\nTPU available: False, using: 0 TPU cores\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\n   | Name             | Type      | Params\n------------------------------------------------\n0  | embedding        | Embedding | 1.3 M \n1  | aspect_embedding | Embedding | 1.5 K \n2  | lstm             | LSTM      | 1.1 M \n3  | linear_h         | Linear    | 90.0 K\n4  | linear_v         | Linear    | 90.0 K\n5  | linear_p         | Linear    | 90.0 K\n6  | linear_x         | Linear    | 90.0 K\n7  | linear           | Linear    | 601   \n8  | linear_s         | Linear    | 903   \n9  | train_acc        | Accuracy  | 0     \n10 | val_acc          | Accuracy  | 0     \n11 | val_f1           | F1        | 0     \n12 | test_acc         | Accuracy  | 0     \n13 | test_f1          | F1        | 0     \n------------------------------------------------\n1.4 M     Trainable params\n1.3 M     Non-trainable params\n2.8 M     Total params\n11.148    Total estimated model params size (MB)\n\n\n\n\n\nGlobal seed set to 2401\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntrainer.test(ckpt_path=checkpoint_callback.best_model_path)\n\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\n\n\n\n\n\n--------------------------------------------------------------------------------\nDATALOADER:0 TEST RESULTS\n{'test_acc': 0.8227040767669678, 'test_f1': 0.6682634353637695}\n--------------------------------------------------------------------------------\n\n\n[{'test_acc': 0.8227040767669678, 'test_f1': 0.6682634353637695}]"
  },
  {
    "objectID": "posts/2021-08-30-nlp_12_job_recommendation_for_cs_it.html",
    "href": "posts/2021-08-30-nlp_12_job_recommendation_for_cs_it.html",
    "title": "Job recommendation system for CS/IT program.",
    "section": "",
    "text": "Taxonomy of recommender systems: A framework to classify and analyze a particular recommendation system.The system is described by the following dimensions:\n1. domain\n2. purpose\n3. context\n4. personalize level\n5. whose opinions\n6. privacy and trustworthiness\n7. interfaces\n8. algorithms\nDomain: Type of content recommended. The domain of Netflix is movies and TV series.\nPurpose: What is the purpose of the system, both for the end user and for the provider?\nContext: The environment which the consumer recieves a recommendation.\nPersonalization Levels: 1. None personalized 2. Semi/Segment personalized 3. Personalized recommendation is based on data about the current user than indicates how the user has interacted with the system previously.\nAlgorithms: Content-based filtering uses the metadata having on the items in the catalog. Depending on the specific algorithm, the system can calculate recommendations either by taking the items the user has liked and finding similar content, by comparing the items and user profiles, or if there’s no user involved, by finding similar content between items."
  },
  {
    "objectID": "posts/2021-08-30-nlp_12_job_recommendation_for_cs_it.html#step-1-remove-html-tags",
    "href": "posts/2021-08-30-nlp_12_job_recommendation_for_cs_it.html#step-1-remove-html-tags",
    "title": "Job recommendation system for CS/IT program.",
    "section": "Step 1: Remove HTML tags",
    "text": "Step 1: Remove HTML tags\n\nfrom bs4 import BeautifulSoup\n\n\ndef remove_html_tags(text):\n    soup = BeautifulSoup(text, 'html.parser')\n    stripped_text = soup.get_text()\n    return stripped_text\n\n\ndf['no_html'] = df['description'].apply(remove_html_tags)\n\n/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \"\"\"Entry point for launching an IPython kernel."
  },
  {
    "objectID": "posts/2021-08-30-nlp_12_job_recommendation_for_cs_it.html#step-2-add-space",
    "href": "posts/2021-08-30-nlp_12_job_recommendation_for_cs_it.html#step-2-add-space",
    "title": "Job recommendation system for CS/IT program.",
    "section": "Step 2: Add space",
    "text": "Step 2: Add space\n\n2.1 Normalize space rules\n\nimport re\ndef add_spaces(text):\n    # Space after punc. Only apply to !.,;:? \n    # Eg: Dislike.However =&gt; Dislike. However \n    text = re.compile(r\"([!.,;:?])([A-Z])\").sub(r\"\\1 \\2\", text)\n    # Space before open bracket\n    # Eg: Dislike(sth) =&gt; Dislike (sth)\n    text = re.sub(r\"([A-za-z])([\\(\\{\\[])\", r'\\1 \\2', text)\n    # Space after close bracket\n    # Eg: (such as)I like =&gt; (such as) I like\n    text = re.sub(r\"([\\)\\}\\]])([A-Za-z])\", r'\\1 \\2', text)\n    # Space between word and - or +\n    # Eg: I like it because-fast -pretty =&gt; I like it because - fast - pretty\n    # Eg: I like mac-book =&gt; keep the same\n    text = re.sub(r\"([A-Za-z])([-+])(\\s)\", r'\\1 \\2 ', text)\n    return text\n\n\ndf['add_space'] = df['no_html'].apply(add_spaces)\n\n/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \"\"\"Entry point for launching an IPython kernel.\n\n\n\ntemp_df = df[df.no_html != df.add_space][[\"no_html\", \"add_space\"]]\nprint(\"Impacted row\", len(temp_df))\ntemp_df.sample()\n\nImpacted row 2\n\n\n\n\n\n\n\n\n\nno_html\nadd_space\n\n\n\n\n53\nExperience in Agile. development methodologies. Integration of user-facing elements developed by a back-end developer with server- side logic\nExperience in Agile. development methodologies. Integration of user-facing elements developed by a back-end developer with server - side logic\n\n\n\n\n\n\n\n\n\n2.2 Add space and remove listing number\n\nimport string\ndef handle_listing_number(text):\n    \"\"\"\n    Only remove if it is listing numbers such as 1. 2. 3.\n    \"\"\"\n    listing = []\n    def remove_listing_number(match_obj):\n        listing_number = match_obj.group(0).strip()\n        result = \"\"\n        if match_obj.start() == 0 and listing_number[0] == \"1\":\n            return \"\"\n        for c in listing_number:\n            if c.isdigit():\n                # save to listing if it is digit\n                listing.append(int(c))\n                break\n            result += c\n        if not any(c in string.punctuation for c in result):\n            result += \".\"\n        return result + \" \"\n    \n    new_text = re.sub(r\"\\b([\\.\\;\\:\\!\\?\\D]*)([1-9])\\.\\s\", remove_listing_number, text.strip())\n    if len(listing) &gt; 1:\n        listing_copy = listing[:]\n        listing_copy.sort()\n        # if listing is sorted\n        if listing_copy == listing:\n            return new_text\n    return text\n\n\ndf[\"add_space2\"] = df['add_space'].apply(handle_listing_number) \n\n/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \"\"\"Entry point for launching an IPython kernel.\n\n\n\ntemp_df = df[df.add_space2 != df.add_space][[\"add_space\", \"add_space2\"]]\nprint(\"Impacted row\", len(temp_df))\ntemp_df\n\nImpacted row 0\n\n\n\n\n\n\n\n\n\nadd_space\nadd_space2"
  },
  {
    "objectID": "posts/2021-08-30-nlp_12_job_recommendation_for_cs_it.html#step-3-expand-contractions",
    "href": "posts/2021-08-30-nlp_12_job_recommendation_for_cs_it.html#step-3-expand-contractions",
    "title": "Job recommendation system for CS/IT program.",
    "section": "Step 3: Expand contractions",
    "text": "Step 3: Expand contractions\n\nfrom symspellpy import SymSpell, Verbosity, helpers\nimport contractions\ndef expand_contractions(text):\n    \"\"\"\n    expand shortened words, e.g. don't to do not\n    contractions library does not keep character case =&gt; need to transfer casing from origin text to fixed text\n    \"\"\"\n    expanded_text = helpers.transfer_casing_for_similar_text(text, contractions.fix(text))\n    # uppercase I\n    return re.sub(r\"\\bi\\b\", \"I\", expanded_text)\n\n\ndf[\"expand_contractions\"] = df[\"add_space2\"].apply(expand_contractions)\n\n/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \"\"\"Entry point for launching an IPython kernel."
  },
  {
    "objectID": "posts/2021-08-30-nlp_12_job_recommendation_for_cs_it.html#step-4-remove-redundant-elements",
    "href": "posts/2021-08-30-nlp_12_job_recommendation_for_cs_it.html#step-4-remove-redundant-elements",
    "title": "Job recommendation system for CS/IT program.",
    "section": "Step 4: Remove redundant elements",
    "text": "Step 4: Remove redundant elements\n\n# Remove and replace by empty space\ndef remove_redundant_elements(text):\n    # remove urls\n    text = re.sub(r\"http\\S+\", \" \", text)\n    # remove phone\n    text = re.sub(r\"[\\+]?[(]?[0-9]{3}[)]?[-\\s\\.]?[0-9]{3}[-\\s\\.]?[0-9]{4,6}\", \" \", text)\n    # remove email\n    text = re.sub(r\"[\\w.+-]+@[\\w-]+\\.[\\w.-]+\", \" \", text)\n    # remove newline\n    table = str.maketrans(\"\\n\\t\\r\", \"   \")\n    text = text.translate(table)\n    # remove redundant whitespaces\n    text = \" \".join(text.split())\n    return text\n\n\ndf[\"no_redundant\"] = df[\"expand_contractions\"].apply(remove_redundant_elements)\n\n/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \"\"\"Entry point for launching an IPython kernel."
  },
  {
    "objectID": "posts/2021-08-30-nlp_12_job_recommendation_for_cs_it.html#step-5-remove-emojies",
    "href": "posts/2021-08-30-nlp_12_job_recommendation_for_cs_it.html#step-5-remove-emojies",
    "title": "Job recommendation system for CS/IT program.",
    "section": "Step 5: Remove emojies",
    "text": "Step 5: Remove emojies\n\n%%capture\n!pip install emoji\n\n\nimport emoji\ndef remove_emoji(text):\n    return emoji.get_emoji_regexp().sub(r\" \", text)\n\n\ndf[\"no_emoji\"] = df[\"no_redundant\"].apply(remove_emoji)\n\n/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \"\"\"Entry point for launching an IPython kernel."
  },
  {
    "objectID": "posts/2021-08-30-nlp_12_job_recommendation_for_cs_it.html#step-6-removing-accented-characters",
    "href": "posts/2021-08-30-nlp_12_job_recommendation_for_cs_it.html#step-6-removing-accented-characters",
    "title": "Job recommendation system for CS/IT program.",
    "section": "Step 6: Removing accented characters",
    "text": "Step 6: Removing accented characters\n\nimport unidecode\ndef remove_accented_chars(text):\n    text = unidecode.unidecode(text)\n    return text\n\n\ndf[\"no_accented\"] = df[\"no_emoji\"].apply(remove_accented_chars)\n\n/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \"\"\"Entry point for launching an IPython kernel."
  },
  {
    "objectID": "posts/2021-08-30-nlp_12_job_recommendation_for_cs_it.html#step-7-collapse-duplicated-punctuation",
    "href": "posts/2021-08-30-nlp_12_job_recommendation_for_cs_it.html#step-7-collapse-duplicated-punctuation",
    "title": "Job recommendation system for CS/IT program.",
    "section": "Step 7: Collapse duplicated punctuation",
    "text": "Step 7: Collapse duplicated punctuation\n\nfrom itertools import groupby\ndef collapse_duplicated_punctuations(text):\n    \"\"\"\n    collapse duplicated punctations\n    because we added space to separate punc and word in step 3, no need to append \" \" after punc\n    \"\"\"\n    newtext = []\n    for k, g in groupby(text):\n        if k in string.punctuation:\n            newtext.append(k)\n        else:\n            newtext.extend(g)\n\n    return ''.join(newtext) \n\n\ndf[\"no_duplicated_punc\"] = df[\"no_accented\"].apply(collapse_duplicated_punctuations)\n\n/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \"\"\"Entry point for launching an IPython kernel."
  },
  {
    "objectID": "posts/2021-08-30-nlp_12_job_recommendation_for_cs_it.html#step-8-remove-consecutive-spaces",
    "href": "posts/2021-08-30-nlp_12_job_recommendation_for_cs_it.html#step-8-remove-consecutive-spaces",
    "title": "Job recommendation system for CS/IT program.",
    "section": "Step 8: Remove consecutive spaces",
    "text": "Step 8: Remove consecutive spaces\n\ndf[\"no_consecutive_spaces\"] = df.no_duplicated_punc.replace({\"\\s+\":\" \"},regex=True)\n\n/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \"\"\"Entry point for launching an IPython kernel.\n\n\n\n# remove redundant empty space \ndf[\"no_consecutive_spaces\"] = df.no_consecutive_spaces.str.strip()\n\n/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy"
  },
  {
    "objectID": "posts/2021-08-30-nlp_12_job_recommendation_for_cs_it.html#step-9-lower-case",
    "href": "posts/2021-08-30-nlp_12_job_recommendation_for_cs_it.html#step-9-lower-case",
    "title": "Job recommendation system for CS/IT program.",
    "section": "Step 9: Lower case",
    "text": "Step 9: Lower case\n\ndf['lower_case'] = df[\"no_consecutive_spaces\"].str.lower()\n\n/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \"\"\"Entry point for launching an IPython kernel.\n\n\n\ndf['lower_case'].iloc[0]\n\n'participate in all. development activities. write high-quality code to implement. features or fix bugs and implement unit test'"
  },
  {
    "objectID": "posts/2021-08-30-nlp_12_job_recommendation_for_cs_it.html#step-9-remove-stopwords",
    "href": "posts/2021-08-30-nlp_12_job_recommendation_for_cs_it.html#step-9-remove-stopwords",
    "title": "Job recommendation system for CS/IT program.",
    "section": "Step 9: Remove stopwords",
    "text": "Step 9: Remove stopwords\n\nimport spacy\nnlp = spacy.load('en_core_web_md')\n\n\ndef remove_stop_words(text):\n    doc = nlp(text)\n    no_stop_words = []\n    for token in doc:\n        if not token.is_stop:\n            no_stop_words.append(token.text)\n    return ' '.join(no_stop_words)\n\n\ndf['no_sw'] = df['lower_case'].apply(remove_stop_words)\n\n/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \"\"\"Entry point for launching an IPython kernel.\n\n\n\ndf['no_sw'][10]\n\n'chance work talented developers , following high standard . development practices ci / cd processes'"
  },
  {
    "objectID": "posts/2021-08-30-nlp_12_job_recommendation_for_cs_it.html#load-the-ner-model",
    "href": "posts/2021-08-30-nlp_12_job_recommendation_for_cs_it.html#load-the-ner-model",
    "title": "Job recommendation system for CS/IT program.",
    "section": "Load the NER model",
    "text": "Load the NER model\n\ncheckpoint = \"mrm8488/codebert-base-finetuned-stackoverflow-ner\"\n\n\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\nmodel = AutoModelForTokenClassification.from_pretrained(checkpoint)\n\n\nfrom transformers import pipeline\nclassifier = pipeline(\"token-classification\", model=model, tokenizer=tokenizer)"
  },
  {
    "objectID": "posts/2021-08-30-nlp_12_job_recommendation_for_cs_it.html#load-the-sentence-transformer",
    "href": "posts/2021-08-30-nlp_12_job_recommendation_for_cs_it.html#load-the-sentence-transformer",
    "title": "Job recommendation system for CS/IT program.",
    "section": "Load the sentence transformer",
    "text": "Load the sentence transformer\n\nfrom sentence_transformers import SentenceTransformer, util\nsent_model = SentenceTransformer('paraphrase-MiniLM-L12-v2')"
  },
  {
    "objectID": "posts/2021-08-30-nlp_12_job_recommendation_for_cs_it.html#define-helpers-functions",
    "href": "posts/2021-08-30-nlp_12_job_recommendation_for_cs_it.html#define-helpers-functions",
    "title": "Job recommendation system for CS/IT program.",
    "section": "Define helpers functions",
    "text": "Define helpers functions\n\nimport torch\nimport ast\nfrom collections import defaultdict\n\ndef add_space(ent):\n    ent['word'] = ent['word'].replace('Ġ', ' ')\n    return ent\n\ndef merge_B_I_entities(ents):\n    results = []\n    i = 0\n    N = len(ents)\n    while i &lt; N:\n        ent = ents[i]\n        ent = add_space(ent)\n        if i &lt; N - 1 and ent['entity'][:2] == 'B-':\n            i += 1\n            next_ent = ents[i]\n            while i &lt; N and next_ent['entity'][:2] == 'I-':\n                ent['word'] += add_space(next_ent)['word']\n                i += 1 \n                if i &lt; N:\n                    next_ent = ents[i]\n                else:\n                    break\n            i -= 1\n            ent['end'] = ents[i]['end']\n            ent['word'] = ent['word'].strip().lower()\n        results.append(ent)\n        i += 1\n    return results \n\ndef merge_entity(ent1, ent2):\n    if ent1['end'] == ent2['start']:\n        ent = {'start': ent1['start'], 'end': ent2['end'], 'entity': ent1['entity'], 'word': (ent1['word']+ent2['word']).strip().lower()}\n        return ent\n\ndef merge_similar_entities(ents):\n    results = []\n    hash_map = defaultdict(list)\n    for ent in ents:\n        hash_map[ent['entity']].append(ent)\n    for k, v in hash_map.items():\n        new_ents = []\n        merge_ent = v[0]\n        i = 0\n        while i &lt; len(v) - 1:\n            temp = merge_entity(merge_ent, v[i + 1])\n            if temp:\n                merge_ent = temp\n            else:\n                new_ents.append(merge_ent)\n                merge_ent = v[i + 1]\n            i+=1\n        merge_ent['word'] = merge_ent['word'].strip().lower()\n        new_ents.append(merge_ent)\n        results += new_ents \n    words = [ent['word'] for ent in results]\n    return results\n\ndef extract_skills(desc):\n    ents = classifier(desc)\n    results = merge_B_I_entities(ents)\n    results = merge_similar_entities(results)\n    skills = set()\n    for ent in results:\n        skills.add(ent['word'])\n    return list(skills)\n\ndef get_skills_from_course_titles(course_titles):\n    course_skills = set()\n    for skills in course_df[course_df['title'].isin(course_titles)]['skills']:\n        course_skills.update(ast.literal_eval(skills))\n    return course_skills\n\ndef show_results(results):\n    for res in results:\n        print(res)"
  },
  {
    "objectID": "posts/2021-08-30-nlp_12_job_recommendation_for_cs_it.html#define-recommender-class",
    "href": "posts/2021-08-30-nlp_12_job_recommendation_for_cs_it.html#define-recommender-class",
    "title": "Job recommendation system for CS/IT program.",
    "section": "Define Recommender class",
    "text": "Define Recommender class\n\nfrom collections import defaultdict\nfrom dataclasses import dataclass\nfrom typing import List\nimport ast\nimport torch\ndef get_skills_from_course_titles(course_titles):\n    course_skills = set()\n    for skills in course_df[course_df['title'].isin(course_titles)]['skills']:\n        course_skills.update(ast.literal_eval(skills))\n    return course_skills\n\nclass Recommender:\n    def __init__(self, ner_classifier, sent_model, course_df, setup=True):\n        self.classifier = ner_classifier\n        self.sent_model = sent_model\n        self.course_info = course_df\n        if setup:\n            self._setup(course_df)\n\n    def _setup(self, course_df):\n        self.course_info = course_df.copy(deep=True)\n        self.course_info['skills'] = self.course_info['extract_skills'].apply(self.extract_skills)\n\n    def extract_skills(self, desc):\n        ents = self.classifier(desc)\n        results = Recommender.merge_B_I_entities(ents)\n        results = Recommender.merge_similar_entities(results)\n        skills = set()\n        for ent in results:\n            skills.add(ent['word'])\n        return list(skills) \n\n    def recommend(self, course_titles, job_info, topk: int = None) -&gt; List[Job]:\n        c_embed = self.sent_model.encode(list(self.course_info[self.course_info['title'].isin(course_titles)]['no_sw']), convert_to_tensor=True)\n        c_avg_embed = torch.mean(c_embed, axis=0)\n        job_descs = list(job_info['no_sw'])\n        job_embeds = self.sent_model.encode(job_descs, convert_to_tensor=True)\n\n        results = Recommender.compare_embeds(c_avg_embed, job_embeds, job_info)\n        skill_list = [set(res[2]) for res in results]\n        my_skills = Recommender.get_skills_from_course_titles(course_titles)\n        scores = []\n\n        # calculate similar skills scores\n        for skills in skill_list:\n            mutual = my_skills.intersection(skills)\n            if len(my_skills) != 0:\n                scores.append(len(mutual)/len(my_skills))\n            else:\n                scores.append(0)\n\n        for i, res in enumerate(results):\n            final_score = res[-1] * 0.6 + 0.4 * scores[i]\n            res[-1] = final_score\n\n        results.sort(key=lambda x: x[-1], reverse=True)\n        if topk:\n            results = results[:topk]\n        return results\n\n    @staticmethod\n    def get_skills_from_course_titles(course_titles):\n        course_skills = set()\n        for skills in course_df[course_df['title'].isin(course_titles)]['skills']:\n            course_skills.update(ast.literal_eval(skills))\n        return course_skills\n\n    @staticmethod\n    def add_space(ent):\n        ent['word'] = ent['word'].replace('Ġ', ' ')\n        return ent\n\n    @staticmethod\n    def merge_B_I_entities(ents):\n        results = []\n        i = 0\n        N = len(ents)\n        while i &lt; N:\n            ent = ents[i]\n            ent = add_space(ent)\n            if i &lt; N - 1 and ent['entity'][:2] == 'B-':\n                i += 1\n                next_ent = ents[i]\n                while i &lt; N and next_ent['entity'][:2] == 'I-':\n                    ent['word'] += add_space(next_ent)['word']\n                    i += 1 \n                    if i &lt; N:\n                        next_ent = ents[i]\n                    else:\n                        break\n                i -= 1\n                ent['end'] = ents[i]['end']\n                ent['word'] = ent['word'].strip().lower()\n            results.append(ent)\n            i += 1\n        return results \n\n    @staticmethod\n    def merge_entity(ent1, ent2):\n        if ent1['end'] == ent2['start']:\n            ent = {'start': ent1['start'], 'end': ent2['end'], 'entity': ent1['entity'], 'word': (ent1['word']+ent2['word']).strip().lower()}\n            return ent\n\n    @staticmethod\n    def merge_similar_entities(ents):\n        results = []\n        hash_map = defaultdict(list)\n        for ent in ents:\n            hash_map[ent['entity']].append(ent)\n        for k, v in hash_map.items():\n            new_ents = []\n            merge_ent = v[0]\n            i = 0\n            while i &lt; len(v) - 1:\n                temp = Recommender.merge_entity(merge_ent, v[i + 1])\n                if temp:\n                    merge_ent = temp\n                else:\n                    new_ents.append(merge_ent)\n                    merge_ent = v[i + 1]\n                i+=1\n            merge_ent['word'] = merge_ent['word'].strip().lower()\n            new_ents.append(merge_ent)\n            results += new_ents \n        words = [ent['word'] for ent in results]\n        return results\n\n    @staticmethod\n    def compare_embeds(c_embed: List, job_embeds: List[List], job_info):\n        results = []\n        for i, job_embed in enumerate(job_embeds):\n            score = util.pytorch_cos_sim(c_embed, job_embed)\n            results.append([job_info.index[i], job_info['title'].iloc[i], job_info['skills'].iloc[i], score.item()])\n        results.sort(key=lambda x: x[-1], reverse=True)\n        return results\n\n    @staticmethod  \n    def post_process(self, outputs):\n        return outputs"
  },
  {
    "objectID": "posts/2021-08-15-nlp_9_content_based_recommendation_system_for_movies_[baby_version].html",
    "href": "posts/2021-08-15-nlp_9_content_based_recommendation_system_for_movies_[baby_version].html",
    "title": "Content based recommendation system for movies [Baby Version]",
    "section": "",
    "text": "from google.colab import drive\ndrive.mount('/content/drive')\n\nDrive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n\n\n\nOverview about recommendation system and its application\nRecommendation system is popular nowadays. They are used to predict the “rating” or “preference” that users would give to an item. Those information can be used to provide users useful suggestions. For example, Amazon uses it to suggest products to customes, while Nexflix uses it to recommend videos based on user’s favor.\n\n\nMain types of recommendation system\nGenerally, there are three types of recommendation system: 1. Simple recommenders: provide recommendation based on items’ popularity or ratings. For example, the movies in IDMB top 250. 2. Content-based recommenders: suggest items based on other item properties. The system assumes that if a person likes a particular item, he or she will also like an item which is similar to it. For example, Netflix suggests new movies based on the user’s history. 3. Collaborative filtering engines: predict the rating or preference that a user would give an item based on past ratings and preferences of other users.\nIn this post, we will build a content-based recommendation system for movies using the MovieLens Dataset. Since the dataset is large (26 miliion ratings and 750,000 tag applications), we only use a subset of it for fast development.\n\n\nLoad dataset\nYou can download the dataset here.\n\nimport pandas as pd\nmetadata = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/dataset/archive/movies_metadata.csv\", low_memory=False)\nmetadata.head(3)\n\n\n\n\n\n\n\n\nadult\nbelongs_to_collection\nbudget\ngenres\nhomepage\nid\nimdb_id\noriginal_language\noriginal_title\noverview\npopularity\nposter_path\nproduction_companies\nproduction_countries\nrelease_date\nrevenue\nruntime\nspoken_languages\nstatus\ntagline\ntitle\nvideo\nvote_average\nvote_count\n\n\n\n\n0\nFalse\n{'id': 10194, 'name': 'Toy Story Collection', ...\n30000000\n[{'id': 16, 'name': 'Animation'}, {'id': 35, '...\nhttp://toystory.disney.com/toy-story\n862\ntt0114709\nen\nToy Story\nLed by Woody, Andy's toys live happily in his ...\n21.946943\n/rhIRbceoE9lR4veEXuwCC2wARtG.jpg\n[{'name': 'Pixar Animation Studios', 'id': 3}]\n[{'iso_3166_1': 'US', 'name': 'United States o...\n1995-10-30\n373554033.0\n81.0\n[{'iso_639_1': 'en', 'name': 'English'}]\nReleased\nNaN\nToy Story\nFalse\n7.7\n5415.0\n\n\n1\nFalse\nNaN\n65000000\n[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...\nNaN\n8844\ntt0113497\nen\nJumanji\nWhen siblings Judy and Peter discover an encha...\n17.015539\n/vzmL6fP7aPKNKPRTFnZmiUfciyV.jpg\n[{'name': 'TriStar Pictures', 'id': 559}, {'na...\n[{'iso_3166_1': 'US', 'name': 'United States o...\n1995-12-15\n262797249.0\n104.0\n[{'iso_639_1': 'en', 'name': 'English'}, {'iso...\nReleased\nRoll the dice and unleash the excitement!\nJumanji\nFalse\n6.9\n2413.0\n\n\n2\nFalse\n{'id': 119050, 'name': 'Grumpy Old Men Collect...\n0\n[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...\nNaN\n15602\ntt0113228\nen\nGrumpier Old Men\nA family wedding reignites the ancient feud be...\n11.7129\n/6ksm1sjKMFLbO7UY2i6G1ju9SML.jpg\n[{'name': 'Warner Bros.', 'id': 6194}, {'name'...\n[{'iso_3166_1': 'US', 'name': 'United States o...\n1995-12-22\n0.0\n101.0\n[{'iso_639_1': 'en', 'name': 'English'}]\nReleased\nStill Yelling. Still Fighting. Still Ready for...\nGrumpier Old Men\nFalse\n6.5\n92.0\n\n\n\n\n\n\n\nOur recommendation system will be based on the similarity between the movie overviews. Specifically, we will compute the pairwise cosine similarity scores for all movies and suggest the movies based on this score.\nFirst of all, we have to transform the raw text to vector form sincewe cannot compute the similarity score directly from the raw text. In this post, we will compute the Term Frequency-Inverse Document Frequency (TF-IDF) vectors for each document.\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Create a TF-IDF object and remove all english stop words in the document \n# before producing vector representation\ntfidf = TfidfVectorizer(stop_words='english')\n\n\nmetadata['overview'] = metadata['overview'].fillna('')\n\ntfidf_matrix = tfidf.fit_transform(metadata['overview'])\n\n\ntfidf_matrix.shape\n\n(45466, 75827)\n\n\nFrom the shape of the matrix we can see that the vector has length of 75827 and we have 45466 movie overview in total.\n\ntfidf.get_feature_names()[5000:5010]\n\n['avails',\n 'avaks',\n 'avalanche',\n 'avalanches',\n 'avallone',\n 'avalon',\n 'avant',\n 'avanthika',\n 'avanti',\n 'avaracious']\n\n\nAfter generating vector for each movie overview, we can start computing the similarity score between them. There are many ways to do that besides cosine similarity, such as the manhantatan, euclidean, the Pearson, etc. There is no right or wrong answer to which score is the best. Different scores will work well in different situations. It is always encouraged to experiment with different metrics and choose the best.\n\nfrom sklearn.metrics.pairwise import linear_kernel\n\ncosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n\n\ncosine_sim.shape\n\n(45466, 45466)\n\n\n\ncosine_sim[1]\n\narray([0.01504121, 1.        , 0.04681953, ..., 0.        , 0.02198641,\n       0.00929411])\n\n\n\nindices = pd.Series(metadata.index, index=metadata['title']).drop_duplicates()\n\n\ndef get_recommendations(title, cosine_sim=cosine_sim):\n    idx = indices[title]\n    sim_scores = list(enumerate(cosine_sim[idx]))\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n    sim_scores = sim_scores[1:11]\n    movie_indices = [i[0] for i in sim_scores]\n    return metadata['title'].iloc[movie_indices]\n\n\nget_recommendations('The Dark Knight Rises')\n\n45464             Satan Triumphant\n45463                     Betrayal\n45462          Century of Birthing\n45461                       Subdue\n45460                   Robin Hood\n45459              Caged Heat 3000\n45458          The Burkittsville 7\n45457    Shadow of the Blair Witch\n45456             House of Horrors\n45455    St. Michael Had a Rooster\nName: title, dtype: object\n\n\n\nget_recommendations('The Godfather')\n\n1178               The Godfather: Part II\n44030    The Godfather Trilogy: 1972-1990\n1914              The Godfather: Part III\n23126                          Blood Ties\n11297                    Household Saints\n34717                   Start Liquidation\n10821                            Election\n38030            A Mother Should Be Loved\n17729                   Short Sharp Shock\n26293                  Beck 28 - Familjen\nName: title, dtype: object\n\n\n\n\nDiscussion\nHere we will discuss a bit the motivation behind TF-IDF\nTerm frequency Give a set of English text documents, we want to rank them by which document is more relevant to the query, for example, “the excellent student”. Firstly, we can simply filter out the documents that do not contain all 3 words - “the”, “excellent” and “student”. However, there are still many documents left. To further distinguish them, we might count the frequency of those 3 words in each document and rank them by corresponding frequencies. That frequency is called the term frequency. Since the length of the document may vary significantly, we often normalize the frequency of each word by the length of the document.\nInverse document frequency Some terms are more common than the other. For example, the term “the” is more popular than the word “excellent”. Term frequency tends to incorrectly emphasize documents which happen to use the word “the” more frequently, without giving enough weight to more meaningful terms such as “excellent” and “student”. Yet, the term “the” is not a good key word to distinguish the relevant and non-relevant documents. The inverse document frequency is used to diminished the weight of terms that occur very frequently in the document set and increases the weight of terms that occur rarely."
  },
  {
    "objectID": "posts/2021-06-18-nlp_1_effective_lstms_for_target_dependent_sentiment_classification [part 1].html",
    "href": "posts/2021-06-18-nlp_1_effective_lstms_for_target_dependent_sentiment_classification [part 1].html",
    "title": "Effective LSTMs for Target Dependent Sentiment Classification [Part 1]",
    "section": "",
    "text": "from IPython.display import Image\nImage(filename='images/paper_image.png')\nTarget-Dependent Sentiment Classification is one of the text classification problems in the field of sentiment analysis. Given a sentence and a target to the model, it has to output the sentiment polarity (e.g positive, negative, neutral) of the sentence towards that target. For example, we have a sentence “I bout a new camera. The pucture quality is amazing but the battery life is too short”. If we input the target picture quality, we expect the sentiment to be “positive”. On the other hand, if we input the target battery life, we expect the sentiment to be “negative”.\nThe author argues that the Target-Dependent sentiment classification is challenging since it is hard to effectively model the sentiment relatedness of a target word with its context words in a sentence. Doing feature engineerings are clumsy, so they propose a neural network approach with 2 models Target-Dependent LSTM (TD-LSTM) and Target-Connection LSTM(TC-LSTM).\nIn this post, I will implement those models and compare it with the plain LSTM model, just like they did. Yet, I will not cover other approaches using SVM and RNN. Since in the original paper, the author did not provide the specific hyper-parameters they used for their models, I will fine-tune it on my own.\nThis post covers the data processing step and the implementation of TD-LSTM. The second post will cover the implementation of TC-LSTM and comparision between three models: TC-LSTM, TD-LSTM, and LSTM.\nThe full notebook is available here."
  },
  {
    "objectID": "posts/2021-06-18-nlp_1_effective_lstms_for_target_dependent_sentiment_classification [part 1].html#install-required-packages",
    "href": "posts/2021-06-18-nlp_1_effective_lstms_for_target_dependent_sentiment_classification [part 1].html#install-required-packages",
    "title": "Effective LSTMs for Target Dependent Sentiment Classification [Part 1]",
    "section": "Install required packages",
    "text": "Install required packages\n\n%%capture\n!pip install pytorch-lightning\n!pip install torchmetrics\n# !pip install transformers"
  },
  {
    "objectID": "posts/2021-06-18-nlp_1_effective_lstms_for_target_dependent_sentiment_classification [part 1].html#download-dataset-and-pretrained-word-embedding",
    "href": "posts/2021-06-18-nlp_1_effective_lstms_for_target_dependent_sentiment_classification [part 1].html#download-dataset-and-pretrained-word-embedding",
    "title": "Effective LSTMs for Target Dependent Sentiment Classification [Part 1]",
    "section": "Download dataset and pretrained word-embedding",
    "text": "Download dataset and pretrained word-embedding\nFirst of all you should download the dataset. The dataset used in the paper is from the Twitter (Dong et al., 2014). You can download from here. After downloading, you should unzip the dataset file in the same folder with the notebook. They should be in the same folder to run properly.\n\n%%capture\n!unzip acl-14-short-data.zip\n\nIn the paper, the author used the 100-dimensional Glove vectors learned from Twitter. Download the word embedding file and unzip it in the same folder with the notebook.\n\n%%capture\n!wget https://nlp.stanford.edu/data/glove.twitter.27B.zip\n!unzip glove.twitter.27B.zip"
  },
  {
    "objectID": "posts/2021-06-18-nlp_1_effective_lstms_for_target_dependent_sentiment_classification [part 1].html#import-required-packages",
    "href": "posts/2021-06-18-nlp_1_effective_lstms_for_target_dependent_sentiment_classification [part 1].html#import-required-packages",
    "title": "Effective LSTMs for Target Dependent Sentiment Classification [Part 1]",
    "section": "Import required packages",
    "text": "Import required packages\n\nimport numpy as np\n\nimport pytorch_lightning as pl\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchmetrics\nfrom pytorch_lightning import loggers as pl_loggers\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom torch.utils.data import DataLoader, Dataset, random_split\nfrom torchtext.data import get_tokenizer"
  },
  {
    "objectID": "posts/2021-06-18-nlp_1_effective_lstms_for_target_dependent_sentiment_classification [part 1].html#load-dataset-from-file-and-create-dataloaders",
    "href": "posts/2021-06-18-nlp_1_effective_lstms_for_target_dependent_sentiment_classification [part 1].html#load-dataset-from-file-and-create-dataloaders",
    "title": "Effective LSTMs for Target Dependent Sentiment Classification [Part 1]",
    "section": "Load dataset from file and create dataloaders",
    "text": "Load dataset from file and create dataloaders\n=====Dataset File Format=====\nEach instance consists three lines: - sentence (the target is replaced with \\(T\\)) - target - polarity label (0: neutral, 1:positive, -1:negative)\nExample:\ni agree about arafat . i mean , shit , they even gave one to \\(T\\) ha . it should be called ’’ the worst president ’’ prize .\njimmy carter\n-1\nTarget-Dependent LSTM (TD-LSTM)\nThe LSTM model solves target-dependent sentiment classification in a target- independent way. That is to say, the feature representation used for sentiment classification remains the same without considering the target words. Let us again take “I bought a new camera. The picture quality is amazing but the battery life is too short” as an example. The representations of this sentence with regard to picture quality and battery life are identical. This is evidently problematic as the sentiment polarity labels towards these two targets are different.\nTo take into account of the target information, we make a slight modification on the aforementioned LSTM model and introduce a target-dependent LSTM (TD-LSTM) in this subsection. The basic idea is to model the preceding and following contexts surrounding the target string, so that contexts in both directions could be used as feature representations for sentiment classification. We believe that capturing such target-dependent context information could improve the accuracy of target-dependent sentiment classification.\nSpecifically, we use two LSTM neural networks, a left one LSTML and a right one LSTMR, to model the preceding and following contexts respectively. An illustration of the model is shown in Figure 1. The input of LSTML is the preceding contexts plus target string, and the input of LSTMR is the following contexts plus target string. We run LSTML from left to right, and run LSTMR from right to left. We favor this strategy as we believe that regarding target string as the last unit could better utilize the semantics of target string when using the composed representation for sentiment classification. Afterwards, we concatenate the last hidden vectors of LSTML and LSTMR , and feed them to a sof tmax layer to classify the sentiment polarity label. One could also try averaging or summing the last hidden vectors of LSTML and LSTMR as alternatives.\n\nfrom IPython.display import Image\nImage(filename='images/firgure_1_image.png')\n\n\n\n\n\n\n\n\n\nclass TwitterTDLSTMDataset(Dataset):\n    def __init__(self, l_sequences, r_sequences, l_lens, r_lens, sentiments):\n        self.l_sequences = l_sequences\n        self.r_sequences = r_sequences\n        self.l_lens = l_lens\n        self.r_lens = r_lens\n        self.sentiments = sentiments\n\n    def __len__(self):\n        return len(self.sentiments)   \n    \n    def __getitem__(self, idx):\n        return (self.l_sequences[idx], self.l_lens[idx]), (self.r_sequences[idx], self.r_lens[idx]), self.sentiments[idx]\n\n\n# Read file\ndef create_dataset_from(path: str):\n    \"\"\"\n    Create a dataset from a file path\n\n    Return: a TwitterDataset object\n    \"\"\"\n\n    sentences = []\n    targets = []\n    sentiments = []\n\n    with open(path) as f:\n        lines = f.readlines()\n        # Read the file line by line and \n        # check the relative index to parse the data according to the format.\n\n        for i, line in enumerate(lines):\n            index = i % 3 # compute the relative index \n            if index == 0: sentences.append(line[:-1])\n            elif index == 1: targets.append(line[:-1])\n            elif index == 2: sentiments.append(line.strip())\n\n    #Load tokenizer \n    tokenizer = get_tokenizer(\"basic_english\")\n\n    #Tokenize and Lower sentence and target text\n    tokenized_sentences = list(map(lambda x: tokenizer(x), sentences))\n    targets = list(map(lambda x: tokenizer(x), targets))\n\n    #Convert sentiment text to number\n    sentiments = list(map(lambda x: int(x), sentiments))\n\n    #Generate sequence_l, sequence_r\n    l_sequences = []\n    r_sequences = []\n    for i, sent in enumerate(tokenized_sentences):\n        seq_l, seq_r = [], []\n        flag = True\n        for token in sent:\n            if word_2_id.get(token) == len(word_2_id) - 1:\n                flag = False\n                continue\n\n            if flag:\n                # get the index of the token in the vocab\n                # if the token does not exists in the vocab, return index of &lt;UNK&gt; token \n                seq_l.append(word_2_id.get(token, 1)) \n            else:\n                seq_r.append(word_2_id.get(token, 1))\n            \n        target_seq = [word_2_id.get(token, 1) for token in targets[i]]\n        seq_l = torch.tensor(seq_l + target_seq) \n        seq_r = torch.tensor((target_seq + seq_r)[::-1]) # reverse the seq_r\n\n        l_sequences.append(seq_l)\n        r_sequences.append(seq_r)\n\n    l_lens = torch.tensor([len(seq) for seq in l_sequences])\n    r_lens = torch.tensor([len(seq) for seq in r_sequences])\n\n    sentiments = torch.tensor(sentiments) + 1\n\n    assert len(l_lens) == len(l_sequences)\n    assert len(r_lens) == len(r_sequences)\n    assert len(l_lens) == len(sentiments)\n    return TwitterTDLSTMDataset(l_sequences, r_sequences, l_lens, r_lens, sentiments)\n\n\ndef load_w2v(embedding_file_path: str): \n    \"\"\"\n    Load pretrained word-embeddings from a file path \n    Return a word_2_id dictionary and a embedding matrix\n    \"\"\"\n    word_2_id = {'&lt;PAD&gt;': 0, '&lt;UNK&gt;': 1}\n    embeddings = [torch.zeros(100), torch.zeros(100)]\n    with open(embedding_file_path) as f: \n        for i, line in enumerate(f.readlines()):\n            tokens = line.split()\n            word, vec = ' '.join(tokens[:-100]), tokens[-100:]\n            word_2_id[word] = i + 2\n            # convert list of str to float\n            float_tokens = np.array(vec, dtype=float)\n            embeddings.append(torch.tensor(float_tokens, dtype=torch.float))\n    embeddings = torch.stack(embeddings)\n    embeddings[word_2_id['&lt;UNK&gt;']] = torch.mean(embeddings[2:], dim=0)\n    word_2_id['$t$'] = len(word_2_id)\n    return word_2_id, embeddings\n\n\n# Create word_2_di dictionary and embeddings matrix\nword_2_id, embeddings = load_w2v(\"glove.twitter.27B.100d.txt\")\n\n\n# Create a collate_batch function to \nfrom torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n\ndef collate_batch(batch):\n    \"\"\"\n    Combine samples from dataset into a batch\n    \"\"\"\n    l_sequences = []\n    l_lens = []\n    r_sequences = []\n    r_lens = []\n    sentiments = []\n    for (l_sequence, l_len), (r_sequence, r_len), sentiment in batch:\n        l_sequences.append(l_sequence)\n        l_lens.append(l_len)\n        r_sequences.append(r_sequence)\n        r_lens.append(r_len)\n        sentiments.append(sentiment)\n\n    padded_l_seq = pad_sequence(l_sequences, batch_first=True, padding_value=0)\n    padded_r_seq = pad_sequence(r_sequences, batch_first=True, padding_value=0)\n\n    return (padded_l_seq, l_lens), (padded_r_seq, r_lens), torch.tensor(sentiments)\n\nIn the paper, the author trained the model on training set, and evaluated the performance on test set\n\ndataset = create_dataset_from(\"/content/acl-14-short-data/train.raw\")\ndataloaders = DataLoader(dataset, batch_size=128, collate_fn=collate_batch)\n\n\ntest_dataset = create_dataset_from(\"/content/acl-14-short-data/test.raw\")\ntest_dataloaders = DataLoader(test_dataset, batch_size=64, collate_fn=collate_batch)"
  },
  {
    "objectID": "posts/2021-06-18-nlp_1_effective_lstms_for_target_dependent_sentiment_classification [part 1].html#implement-model-architecture",
    "href": "posts/2021-06-18-nlp_1_effective_lstms_for_target_dependent_sentiment_classification [part 1].html#implement-model-architecture",
    "title": "Effective LSTMs for Target Dependent Sentiment Classification [Part 1]",
    "section": "Implement Model Architecture",
    "text": "Implement Model Architecture\nThe architecture has a embedding layer, 2 LSTM layers and 1 dense layer.\n\nEmbedding layer:\n\nConvert the sequences to word vectors using pre-trained Glove word embeddings\n\n2 LSTM layers:\n\nOne layer is used for the [left context + target] sequences, and one is used for the [target + right context] sequences.\n\nDense layer:\n\nWe concate the 2 hidden states from the LSTM layers and feed it into the Dense layer.\nNotes:\nWe use Adam as our optimizer and using accuracy and f1 as our evaluating metrics, just like in the original paper.\n\nclass TDLSTM(pl.LightningModule):\n    def __init__(self, embeddings, hidden_size, num_layers=1, num_classes=3, batch_first=True, lr=1e-3, dropout=0, l2reg=0.01):\n        super().__init__()\n        embedding_dim = embeddings.shape[1]\n        self.embedding = nn.Embedding.from_pretrained(embeddings) # load pre-trained word embeddings\n        self.l_lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first=batch_first, dropout=dropout)\n        self.r_lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first=batch_first, dropout=dropout)\n        self.linear = nn.Linear(hidden_size*2, num_classes)\n\n        self.lr = lr\n        self.l2reg = l2reg\n        # Define metrics \n        self.train_acc = torchmetrics.Accuracy() \n        self.val_acc = torchmetrics.Accuracy()\n        self.val_f1 = torchmetrics.F1(num_classes=3, average='macro')\n        self.test_acc = torchmetrics.Accuracy()\n        self.test_f1 = torchmetrics.F1(num_classes=3, average='macro')\n\n    def configure_optimizers(self):\n        optim = torch.optim.AdamW(self.parameters(), lr=self.lr, weight_decay=self.l2reg)\n        return optim\n\n    def forward(self, padded_l_seqs, l_lens, padded_r_seqs, r_lens):\n        # convert seq to word vector\n        padded_l_embeds = self.embedding(padded_l_seqs)\n        padded_r_embeds = self.embedding(padded_r_seqs)\n        # pack the embeds  \n        padded_l_seq_pack = pack_padded_sequence(padded_l_embeds, l_lens, batch_first=True, enforce_sorted=False)\n        padded_r_seq_pack = pack_padded_sequence(padded_r_embeds, r_lens, batch_first=True, enforce_sorted=False)\n\n        _, (h_l, _) = self.l_lstm(padded_l_seq_pack)  \n        _, (h_r, _) = self.r_lstm(padded_r_seq_pack)  \n        h = torch.cat((h_l[-1], h_r[-1]), -1) # B x 2H\n\n        out = self.linear(h)\n        return out\n\n    def training_step(self, batch, batch_idx): # pylint: disable=unused-argument\n        (padded_l_seqs, l_lens), (padded_r_seqs, r_lens), sentiments = batch\n        logits = self.forward(padded_l_seqs, l_lens, padded_r_seqs, r_lens)\n        loss = F.cross_entropy(logits, sentiments)\n        scores = F.softmax(logits, dim=-1)\n        self.train_acc(scores, sentiments)\n        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n        self.log('train_acc', self.train_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        return loss\n    \n    def validation_step(self, batch, batch_idx):  # pylint: disable=unused-argument\n        (padded_l_seqs, l_lens), (padded_r_seqs, r_lens), sentiments = batch\n        logits = self.forward(padded_l_seqs, l_lens, padded_r_seqs, r_lens)\n        loss = F.cross_entropy(logits, sentiments)\n        scores = F.softmax(logits, dim=-1)\n        self.val_acc(scores, sentiments)\n        self.val_f1(scores, sentiments)\n        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n        self.log('val_acc', self.val_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        self.log('val_f1', self.val_f1, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n\n    def test_step(self, batch, batch_idx):  # pylint: disable=unused-argument\n        (padded_l_seqs, l_lens), (padded_r_seqs, r_lens), sentiments = batch\n        logits = self.forward(padded_l_seqs, l_lens, padded_r_seqs, r_lens)\n        scores = F.softmax(logits, dim=-1)\n        self.test_acc(scores, sentiments)\n        self.test_f1(scores, sentiments)\n        self.log('test_acc', self.test_acc, on_step=False, on_epoch=True, logger=True)\n        self.log('test_f1', self.test_f1, on_step=False, on_epoch=True, logger=True)"
  },
  {
    "objectID": "posts/2021-06-18-nlp_1_effective_lstms_for_target_dependent_sentiment_classification [part 1].html#training",
    "href": "posts/2021-06-18-nlp_1_effective_lstms_for_target_dependent_sentiment_classification [part 1].html#training",
    "title": "Effective LSTMs for Target Dependent Sentiment Classification [Part 1]",
    "section": "Training",
    "text": "Training\n\ncheckpoint_callback = ModelCheckpoint(\n    monitor='val_acc', # save the model with the best validation accuracy\n    dirpath='checkpoints',\n    filename='best_model',\n    mode='max',\n)\n\ntb_logger = pl_loggers.TensorBoardLogger('logs/') # create logger for tensorboard\n\n# hyper-parameters\nlr = 1e-3 \nhidden_size = 500\nnum_epochs = 60\nl2reg = 0.5 \n\ntrainer = pl.Trainer(gpus=1, max_epochs=num_epochs, logger=tb_logger, callbacks=[checkpoint_callback])\nmodel = TDLSTM(embeddings, hidden_size, lr=lr, l2reg=l2reg)\ntrainer.fit(model, dataloaders, test_dataloaders)\n\nGPU available: True, used: True\nTPU available: False, using: 0 TPU cores\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\n  | Name      | Type      | Params\n----------------------------------------\n0 | embedding | Embedding | 119 M \n1 | l_lstm    | LSTM      | 1.2 M \n2 | r_lstm    | LSTM      | 1.2 M \n3 | linear    | Linear    | 3.0 K \n4 | train_acc | Accuracy  | 0     \n5 | val_acc   | Accuracy  | 0     \n6 | val_f1    | F1        | 0     \n7 | test_acc  | Accuracy  | 0     \n8 | test_f1   | F1        | 0     \n----------------------------------------\n2.4 M     Trainable params\n119 M     Non-trainable params\n121 M     Total params\n487.050   Total estimated model params size (MB)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# load the best model\nnew_model = TDLSTM.load_from_checkpoint(checkpoint_callback.best_model_path,  embeddings=embeddings, hidden_size=500)\ntrainer.test(new_model, test_dataloaders)\n\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\n\n\n\n\n\n--------------------------------------------------------------------------------\nDATALOADER:0 TEST RESULTS\n{'test_acc': 0.7037572264671326, 'test_f1': 0.6847572326660156}\n--------------------------------------------------------------------------------\n\n\n[{'test_acc': 0.7037572264671326, 'test_f1': 0.6847572326660156}]\n\n\n\nfrom IPython.display import Image\nImage(filename='images/results.png')\n\n\n\n\n\n\n\n\nCompare to the result from the paper, our implementation gets very close results. You can try to tune the model to get better result."
  },
  {
    "objectID": "posts/2021-07-27-nlp_7_text_preprocessing_and_labelling_[part_1].html",
    "href": "posts/2021-07-27-nlp_7_text_preprocessing_and_labelling_[part_1].html",
    "title": "Text Processing & Labelling [Part1]",
    "section": "",
    "text": "The full notebook is availabel here.\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\nDrive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n%%capture\n!pip install transformers\n!pip install emoji\n!pip install Unidecode\n!pip install contractions\n!pip install word2number\n!python -m spacy download en_core_web_md\n!pip install spacy-langdetect"
  },
  {
    "objectID": "posts/2021-07-27-nlp_7_text_preprocessing_and_labelling_[part_1].html#step-1-remove-html-tags",
    "href": "posts/2021-07-27-nlp_7_text_preprocessing_and_labelling_[part_1].html#step-1-remove-html-tags",
    "title": "Text Processing & Labelling [Part1]",
    "section": "Step 1: Remove HTML Tags",
    "text": "Step 1: Remove HTML Tags\nHTLM tags does not add any useful information for understanding and analyzing text, so we remove it.\n\ndef remove_html_tags(text):\n    soup = BeautifulSoup(text, \"html.parser\")\n    stripped_text = soup.get_text()\n    return stripped_text\n\n\ndf[\"no_html\"] = df[\"review\"].apply(remove_html_tags)\n\n\ndf[df[\"no_html\"] != df[\"review\"]][100:120]\n\n\n\n\n\n\n\n\ncomment_id\nreview\nstar_rating\nno_html\n\n\n\n\n8897\n255542\nThe colors are super vibrant &amp; unique. I was unable to find colors like this in multiple stores I visited, let alone find both a left &amp; right controller together so this was definitely a win-win.\n5\nThe colors are super vibrant & unique. I was unable to find colors like this in multiple stores I visited, let alone find both a left & right controller together so this was definitely a win-win.\n\n\n8955\n255550\nI received my Neon Pink &amp; Neon Green Joy Cons yesterday and I'm amazed at how vibrant and colorful this particular set is! These 2 colors compliment each other perfectly, too! 5/5 Stars! Good packaging, prompt next-day delivery as a Prime Member.\n5\nI received my Neon Pink & Neon Green Joy Cons yesterday and I'm amazed at how vibrant and colorful this particular set is! These 2 colors compliment each other perfectly, too! 5/5 Stars! Good packaging, prompt next-day delivery as a Prime Member.\n\n\n9216\n255962\nLove my Switch &amp; these are fun colors\n5\nLove my Switch & these are fun colors\n\n\n9293\n256306\n&lt;3\n5\n&lt;3\n\n\n9466\n255331\nPerfect pair of new joycons I'm using for a shell &amp; button mod swap.\n5\nPerfect pair of new joycons I'm using for a shell & button mod swap.\n\n\n10566\n257919\nWorks &amp; bright colors!\n5\nWorks & bright colors!\n\n\n10717\n258185\nAlthough we do enjoy the new features that Switch have over Wii:* Does not require sensor bar* Portable - able to play on-the-go with build-in console batteryThere are few limitations that we were not aware prior to purchase:* Joy Con battery not removable. (Since rechargeable batteries have limited life, customers will need to purchase new controllers every 1-2 years depending on amount of use)* Joy Con controller size are small for adults including the joystick &amp; buttons* Gel-Con Guards need to be removed when switching to Wheel adopter* Hand Strap need to removed in order to place on charger\n3\nAlthough we do enjoy the new features that Switch have over Wii:* Does not require sensor bar* Portable - able to play on-the-go with build-in console batteryThere are few limitations that we were not aware prior to purchase:* Joy Con battery not removable. (Since rechargeable batteries have limited life, customers will need to purchase new controllers every 1-2 years depending on amount of use)* Joy Con controller size are small for adults including the joystick & buttons* Gel-Con Guards need to be removed when switching to Wheel adopter* Hand Strap need to removed in order to place on charger\n\n\n10737\n258240\nAfter a few months of use, without dropping them, nothing smeared on them, and just playing Smash Bros Ultimate, one of the sticks on a Joy-con is starting to wear down. I can't make it respond to sudden movements or flicking. My left stick, in particular, is now drifting. I tried calibrating the controls, and it's fine, but it did nothing to fix the issue.I looked up on means to fix this, and it requires the risk of ruining your controller further by taking it apart to replace the stick with a new one (or at least adjust the current one). Even then, it does not take long for the drifting to come back.It's entirely possible I got unlucky and received a bad pair with my Switch, but it doesn't change the fact that something like this occurred so soon for something so expensive. I really want to enjoy my games on-the-go more often than at home, but it's not going to happen the way the design is flawed.Even the Pro-Controller is having the same issue... so now I'm hesitant to buy any Nintendo-licensed controller... and it doesn't help that the warranty for these controllers are so short. Terrific. Thanks for nothing, Nintendo.&gt;.&gt;\n2\nAfter a few months of use, without dropping them, nothing smeared on them, and just playing Smash Bros Ultimate, one of the sticks on a Joy-con is starting to wear down. I can't make it respond to sudden movements or flicking. My left stick, in particular, is now drifting. I tried calibrating the controls, and it's fine, but it did nothing to fix the issue.I looked up on means to fix this, and it requires the risk of ruining your controller further by taking it apart to replace the stick with a new one (or at least adjust the current one). Even then, it does not take long for the drifting to come back.It's entirely possible I got unlucky and received a bad pair with my Switch, but it doesn't change the fact that something like this occurred so soon for something so expensive. I really want to enjoy my games on-the-go more often than at home, but it's not going to happen the way the design is flawed.Even the Pro-Controller is having the same issue... so now I'm hesitant to buy any Nintendo-licensed controller... and it doesn't help that the warranty for these controllers are so short. Terrific. Thanks for nothing, Nintendo.&gt;.&gt;\n\n\n10748\n258269\nI for one actually really like Joy Cons, they’re a very unique controller &amp; can work together as one or just use a single joy con as one controller, these purple &amp; neon orange combo is extraordinary! The Purple would sometimes look more like a Hot pink (depending when light hits it) and the neon orange would look more like a summer yellow (same reason; lighting) but they actually are a great combo and if you have other types of color joy cons, you can mixed them up &amp; create your own colorful creation!\n5\nI for one actually really like Joy Cons, they’re a very unique controller & can work together as one or just use a single joy con as one controller, these purple & neon orange combo is extraordinary! The Purple would sometimes look more like a Hot pink (depending when light hits it) and the neon orange would look more like a summer yellow (same reason; lighting) but they actually are a great combo and if you have other types of color joy cons, you can mixed them up & create your own colorful creation!\n\n\n10866\n258366\nI bought this for my daughter for Christmas. She had several people over &amp; they all enjoyed using the new controllers.\n5\nI bought this for my daughter for Christmas. She had several people over & they all enjoyed using the new controllers.\n\n\n10892\n258431\nColors are vibrant &amp; they work great (as expected lol)! Very fun purchase! We accidentally yeeted one of them across the living room playing a Mario party mini game and it actually still works LOL The stick is a little wonky but overall impressed that it even survived! 10/10 will buy more colors!\n5\nColors are vibrant & they work great (as expected lol)! Very fun purchase! We accidentally yeeted one of them across the living room playing a Mario party mini game and it actually still works LOL The stick is a little wonky but overall impressed that it even survived! 10/10 will buy more colors!\n\n\n11561\n257944\nThey hold a super long charge and the pink &amp; green fill me with nostalgia for the fairly odd parents (my SHOW as a kid).\n5\nThey hold a super long charge and the pink & green fill me with nostalgia for the fairly odd parents (my SHOW as a kid).\n\n\n11667\n258509\nThey are cute &amp; i love the colors 💜\n5\nThey are cute & i love the colors 💜\n\n\n11720\n258580\nMy child is soooo happy to have new working controllers! The shipping was quick &amp; on time for his birthday last month.\n5\nMy child is soooo happy to have new working controllers! The shipping was quick & on time for his birthday last month.\n\n\n11825\n258629\nPerfect finial addition to me now owning every single pair of joycons (- grey colour as to bland for me) from the UK, Japan &amp; Also the US 😀 very speedy international delivery &amp; arrived perfect so thank you 5*\n0\nPerfect finial addition to me now owning every single pair of joycons (- grey colour as to bland for me) from the UK, Japan & Also the US 😀 very speedy international delivery & arrived perfect so thank you 5*\n\n\n11842\n258645\nEstoy en mi trabajo, y resulta que ya me entregaron el paquete y para colmo tienen el descaro de poner que la persona que recogió el paquete fui yo. TIENEN MI NUMERO DE TELÉFONO, MI DIRECCIÓN &amp; SE ATREVEN A ENTREGARLE EL PRODUCTO A ALGUIEN QUE EN PRIMER LUGAR SE ENCUENTRA FUERA DE LA PROPIEDAD, YA QUE EN LA MISMA HAY REJAS A LO CUAL NADIE PUEDE ENTRAR, QUE ASCO CON EL SERVICIO DE PAQUETERIA. Sigo a la espera de llamada.....\n0\nEstoy en mi trabajo, y resulta que ya me entregaron el paquete y para colmo tienen el descaro de poner que la persona que recogió el paquete fui yo. TIENEN MI NUMERO DE TELÉFONO, MI DIRECCIÓN & SE ATREVEN A ENTREGARLE EL PRODUCTO A ALGUIEN QUE EN PRIMER LUGAR SE ENCUENTRA FUERA DE LA PROPIEDAD, YA QUE EN LA MISMA HAY REJAS A LO CUAL NADIE PUEDE ENTRAR, QUE ASCO CON EL SERVICIO DE PAQUETERIA. Sigo a la espera de llamada.....\n\n\n11879\n253884\nI bought these used for a custom mod, so I only needed the internals. Before taking them apart they seemed to work normally. Post mod they still work normally. It is worth noting however that the shells had scuffs &amp; a few distinct scratches. I recommend just buying new ones if you are using them as is. If you are looking to save a few bucks on a custom controller mod &amp; only need the internal parts then these work. It is worth noting that the sticks did not seem to have any drifting issues either.\n4\nI bought these used for a custom mod, so I only needed the internals. Before taking them apart they seemed to work normally. Post mod they still work normally. It is worth noting however that the shells had scuffs & a few distinct scratches. I recommend just buying new ones if you are using them as is. If you are looking to save a few bucks on a custom controller mod & only need the internal parts then these work. It is worth noting that the sticks did not seem to have any drifting issues either.\n\n\n11961\n254562\nWhen I bought this product used, all of the buttons worked on both joycons minus the L &amp; R button. I opened them up and saw that the button on the motherboard was not attached but next to where it should have been. Also, the left joycon joystick looks like a toddler chewed on it. I guess that’s what I get for trying to buy used joycons?\n3\nWhen I bought this product used, all of the buttons worked on both joycons minus the L & R button. I opened them up and saw that the button on the motherboard was not attached but next to where it should have been. Also, the left joycon joystick looks like a toddler chewed on it. I guess that’s what I get for trying to buy used joycons?\n\n\n11968\n254892\nThis is our 4th set of Nintendo Switch Joy-Cons. They’re great fun &amp; just as expected, BUT the left one wears out so quickly. And we don’t play video games all the time like some people. For such a high price, Nintendo really should do better.\n3\nThis is our 4th set of Nintendo Switch Joy-Cons. They’re great fun & just as expected, BUT the left one wears out so quickly. And we don’t play video games all the time like some people. For such a high price, Nintendo really should do better.\n\n\n12031\n256532\nThe left one gets stuck &amp; drifts! Just bought a few months ago this shouldn’t happen!! So disappointed\n1\nThe left one gets stuck & drifts! Just bought a few months ago this shouldn’t happen!! So disappointed\n\n\n\n\n\n\n\nOne notice from the example above is that the BeautifulSoup function convert &amp; to $. In general, the function tries to convert decode the HTML Character Entities."
  },
  {
    "objectID": "posts/2021-07-27-nlp_7_text_preprocessing_and_labelling_[part_1].html#step-2-remove-redundant-elements",
    "href": "posts/2021-07-27-nlp_7_text_preprocessing_and_labelling_[part_1].html#step-2-remove-redundant-elements",
    "title": "Text Processing & Labelling [Part1]",
    "section": "Step 2: Remove redundant elements",
    "text": "Step 2: Remove redundant elements\n\n# Remove and replace by empty space\ndef remove_redundant_elements(text):\n    # remove urls\n    text = re.sub(r\"http\\S+\", \" \", text)\n    # remove phone\n    text = re.sub(r\"[\\+]?[(]?[0-9]{3}[)]?[-\\s\\.]?[0-9]{3}[-\\s\\.]?[0-9]{4,6}\", \" \", text)\n    # remove email\n    text = re.sub(r\"[\\w.+-]+@[\\w-]+\\.[\\w.-]+\", \" \", text)\n    # remove newline\n    table = str.maketrans(\"\\n\\t\\r\", \"   \")\n    text = text.translate(table)\n    # remove redundant whitespaces\n    text = \" \".join(text.split())\n#     # remove punctuations\n#     table_ = str.maketrans(string.punctuation, \" \" * len(string.punctuation))\n#     comment = \" \".join(comment.translate(table_).split())\n    return text\n\n\ndf[\"no_redundant\"] = df[\"no_html\"].apply(remove_redundant_elements)\n\n\ndf[df[\"no_redundant\"] != df[\"no_html\"]][[\"no_html\", \"no_redundant\"]]\n\n\n\n\n\n\n\n\nno_html\nno_redundant\n\n\n\n\n1950\nI am overall satisfied with the laptop. It's fast, works great, and didn't have any trouble setting up. I've got to admit, it was hard switching from Windows to IOS, but that was on my part. I was loving it until I really started seeing some changes...It was only, what? Two days in? I unplugged my laptop because I left my room to do assignments in my sister's room, and less than an hour later my laptop went from 100 to 89. I wasn't even using any \"THIS NEEDS POWER\" apps. I had all the energy saver settings on, and my brightness was low as well. Also, (please read the whole thing because I'm not sure if it's me or the laptop) I had problems with the temperature. It was overheating. I would always hear the fan on at times that were so unnecessary.I'll admit, high-graphic games were played, but after I stopped playing those games, the fan was still moving like someone trying to find a bathroom in Taco Bell. And, it was LOUD, like enough to wake up a 'tarantula' loud (of course not THAT loud, but it sounded like I was using a 2010 desktop Windows 7 Vista CPU). I have a laptop stand, but it has holes. Could that still factor in my circulation issues? I mean, there aren't any ventilation holes on the bottom, right? RIGHT?That's the laptop stand. It says it has heat vents, and in the picture, it shows a Macbook:https://www.amazon.com/Adjustable-Aluminum-Multi-Angle-Heat-Vent-Compatible/dp/B088DB45HG/ref=pd_ybh_a_219?_encoding=UTF8&psc=1&refRID=R8VBZ111SHQCQCPPHJSX\nI am overall satisfied with the laptop. It's fast, works great, and didn't have any trouble setting up. I've got to admit, it was hard switching from Windows to IOS, but that was on my part. I was loving it until I really started seeing some changes...It was only, what? Two days in? I unplugged my laptop because I left my room to do assignments in my sister's room, and less than an hour later my laptop went from 100 to 89. I wasn't even using any \"THIS NEEDS POWER\" apps. I had all the energy saver settings on, and my brightness was low as well. Also, (please read the whole thing because I'm not sure if it's me or the laptop) I had problems with the temperature. It was overheating. I would always hear the fan on at times that were so unnecessary.I'll admit, high-graphic games were played, but after I stopped playing those games, the fan was still moving like someone trying to find a bathroom in Taco Bell. And, it was LOUD, like enough to wake up a 'tarantula' loud (of course not THAT loud, but it sounded like I was using a 2010 desktop Windows 7 Vista CPU). I have a laptop stand, but it has holes. Could that still factor in my circulation issues? I mean, there aren't any ventilation holes on the bottom, right? RIGHT?That's the laptop stand. It says it has heat vents, and in the picture, it shows a Macbook:\n\n\n4248\nEssa review do Switch Lite está fragmentada em duas partes, software e hardware.Começando pelo aspecto de hardware, é seguro dizer que a Nvidia fez um trabalho muito melhor do que a Nintendo: O SoC Tegra é capaz de entregar jogos antigos de PC (2013 em diante) para o handheld sem screen tearing, sem frame drops, e com uma boa duração de bateria (no máximo 3 horas, dependendo do jogo).Porém, a Nintendo me desapontou: embora os face buttons (X, Y, A B) sejam macios de apertar, a pressa da empresa em lançar logo o Switch Lite afim de aproveitar o hype que o tradicional Switch gerou culminou em sticks com qualidade duvidosa sendo implementados na versão final do produto. Uma vez que o seu stick esteja \"funcionando sozinho\", isso vai sempre te perseguir até que você resolva o problema: ou envie para um representante da Nintendo no exterior para consertar, o que pode levar até semanas, ou você resolve o problema sozinho - e é aí que você se depara com uma outra limitação imposta pela Nintendo, as tri-wing screws (parafusos de três pontas) que a empresa implementou propositalmente para evitar que seus clientes sejam capazes de fazer a manutenção do Switch Lite. Lamentável.Em termos de software: até a geração passada da Nintendo (WiiU) o senso comum ditava que a audiência da empresa sempre foram os pequenos até os adolescentes. Com o Switch, a Nintendo quer mudar essa idéia e abraçar todos os públicos. Mas os desenvolvedores ainda não engoliram essa, principalmente porque lançaram seus jogos nas plataformas anteriores da Nintendo e se arrependeram amargamente, devido às míseras vendas de seus jogos. É por isso que desenvolvedores como Rockstar, Activision, EA, dentre outros não lançam jogos considerados 'Mature' na plataforma. Depois de quase três anos de mercado, o Switch ainda vive o momento em que essas desenvolvedoras ficam esperando ver quem dá o primeiro passo. Se for feito com sucesso e a lucratividade compensar, as outras seguem. Nesse período de indecisão, a comunidade Switch ainda debate \"onde está GTA V para o Switch?\", \"Cadê o port de Red Dead Redemption?\", \"por quê ainda não temos Tomb Raider ou Deus EX no Switch?\", entre outras reivindicações. Os jogos \"first-party\" nada mais são do que ports do WiiU cujos preços são absurdamente caros. Para se ter uma idéia, Donkey Kong Tropical Freeze, um jogo do WiiU com mais de cinco anos de existência, é cobrado por 60 Dólares. Tudo bem, o jogo é bonito, porém velho demais e caro demais. E essa tem sido a filosofia da empresa, se for first-party, cobre o máximo. Diferente da competidora Sony, onde até mesmo jogos first-party como God of War é descontado mais da metade em promoções na PS Store, a Nintendo quer sempre cobrar o máximo, descontando seus jogos em 33% de vez em nunca na Nintendo eShop. Esse desconto é seletivo (não valem para todos os jogos da empresa). Além disso, falando na eShop, você sempre compra um jogo 'no escuro': sem uma demo, sem review para você ter uma idéia se o jogo é bom ou não antes de comprar. Então supomos que você compre o jogo mesmo assim. Se arrependeu? Azar o seu, a Nintendo não permite refunds (retorno do software e o seu dinheiro de volta). Um absurdo. E como as leis vigentes brasileiras são mais feitas pra te ferrar do que pra te ajudar, é melhor você procurar um vídeo de um gameplay no Youtube antes de efetuar a sua compra. Você foi avisado.Por fim, eu tenho mais de 340 horas com o meu Switch Lite. Me arrependo de ter comprado o handheld com um preço tão salgado, confesso que deveria ter esperado mais um ano, quem sabe até lá o Switch Lite teria um preço menos abusivo e jogos mais atrativos. Não sou fã de Mario e toda aquela corja \"fofinha demais e caro demais\" da Nintendo. Admitidamente, se o projeto Smach Z (Kickstarter) tivesse entregado um produto digno da espera, não teria sequer passado perto do Nintendo Switch. E tem mais: se você curte apenas jogos em 2D ou então no estilo dos da Gameloft, teu celular vai ter dar uma experiência melhor do que o Nintendo Switch Lite, supondo que você tenha um controle Bluetooth e um celular com uma configuração respeitável e com mais de 2000mAh de bateria. O único quesito que o Switch Lite ganha é que é apenas uma única configuração de hardware, portanto os desenvolvedores oferecem o suporte aos seus jogos de maneira que rodem de forma suave e compatível, coisa que não se vê muito em jogos Android em 2020.Adicionalmente, se o seu Switch Lite for teu hardware principal para jogos, ele vai ficar bastante judiado.Você vai precisar de um case, uma skin e um grip. Eu recomendo essa solução três-em-um da Skull & Co:https://www.amazon.com/gp/product/B082B56D2H/ref=ppx_yo_dt_b_asin_title_o00_s00?ie=UTF8&psc=1Um screen protector para evitar arranhões na tela:https://www.amazon.com/gp/product/B07QNRB34L/ref=ppx_yo_dt_b_asin_title_o03_s01?ie=UTF8&psc=1E por fim, um cartão de memória. Dependendo se você for um colecionador, a memória interna talvez seja o suficiente. Caso contrário, um cartão de 200GB da SanDisk deve bastar para o seu primeiro ano com o Switch Lite:https://www.amazon.com/gp/product/B073JY5T7T/ref=ppx_yo_dt_b_asin_title_o03_s00?ie=UTF8&psc=1\nEssa review do Switch Lite está fragmentada em duas partes, software e hardware.Começando pelo aspecto de hardware, é seguro dizer que a Nvidia fez um trabalho muito melhor do que a Nintendo: O SoC Tegra é capaz de entregar jogos antigos de PC (2013 em diante) para o handheld sem screen tearing, sem frame drops, e com uma boa duração de bateria (no máximo 3 horas, dependendo do jogo).Porém, a Nintendo me desapontou: embora os face buttons (X, Y, A B) sejam macios de apertar, a pressa da empresa em lançar logo o Switch Lite afim de aproveitar o hype que o tradicional Switch gerou culminou em sticks com qualidade duvidosa sendo implementados na versão final do produto. Uma vez que o seu stick esteja \"funcionando sozinho\", isso vai sempre te perseguir até que você resolva o problema: ou envie para um representante da Nintendo no exterior para consertar, o que pode levar até semanas, ou você resolve o problema sozinho - e é aí que você se depara com uma outra limitação imposta pela Nintendo, as tri-wing screws (parafusos de três pontas) que a empresa implementou propositalmente para evitar que seus clientes sejam capazes de fazer a manutenção do Switch Lite. Lamentável.Em termos de software: até a geração passada da Nintendo (WiiU) o senso comum ditava que a audiência da empresa sempre foram os pequenos até os adolescentes. Com o Switch, a Nintendo quer mudar essa idéia e abraçar todos os públicos. Mas os desenvolvedores ainda não engoliram essa, principalmente porque lançaram seus jogos nas plataformas anteriores da Nintendo e se arrependeram amargamente, devido às míseras vendas de seus jogos. É por isso que desenvolvedores como Rockstar, Activision, EA, dentre outros não lançam jogos considerados 'Mature' na plataforma. Depois de quase três anos de mercado, o Switch ainda vive o momento em que essas desenvolvedoras ficam esperando ver quem dá o primeiro passo. Se for feito com sucesso e a lucratividade compensar, as outras seguem. Nesse período de indecisão, a comunidade Switch ainda debate \"onde está GTA V para o Switch?\", \"Cadê o port de Red Dead Redemption?\", \"por quê ainda não temos Tomb Raider ou Deus EX no Switch?\", entre outras reivindicações. Os jogos \"first-party\" nada mais são do que ports do WiiU cujos preços são absurdamente caros. Para se ter uma idéia, Donkey Kong Tropical Freeze, um jogo do WiiU com mais de cinco anos de existência, é cobrado por 60 Dólares. Tudo bem, o jogo é bonito, porém velho demais e caro demais. E essa tem sido a filosofia da empresa, se for first-party, cobre o máximo. Diferente da competidora Sony, onde até mesmo jogos first-party como God of War é descontado mais da metade em promoções na PS Store, a Nintendo quer sempre cobrar o máximo, descontando seus jogos em 33% de vez em nunca na Nintendo eShop. Esse desconto é seletivo (não valem para todos os jogos da empresa). Além disso, falando na eShop, você sempre compra um jogo 'no escuro': sem uma demo, sem review para você ter uma idéia se o jogo é bom ou não antes de comprar. Então supomos que você compre o jogo mesmo assim. Se arrependeu? Azar o seu, a Nintendo não permite refunds (retorno do software e o seu dinheiro de volta). Um absurdo. E como as leis vigentes brasileiras são mais feitas pra te ferrar do que pra te ajudar, é melhor você procurar um vídeo de um gameplay no Youtube antes de efetuar a sua compra. Você foi avisado.Por fim, eu tenho mais de 340 horas com o meu Switch Lite. Me arrependo de ter comprado o handheld com um preço tão salgado, confesso que deveria ter esperado mais um ano, quem sabe até lá o Switch Lite teria um preço menos abusivo e jogos mais atrativos. Não sou fã de Mario e toda aquela corja \"fofinha demais e caro demais\" da Nintendo. Admitidamente, se o projeto Smach Z (Kickstarter) tivesse entregado um produto digno da espera, não teria sequer passado perto do Nintendo Switch. E tem mais: se você curte apenas jogos em 2D ou então no estilo dos da Gameloft, teu celular vai ter dar uma experiência melhor do que o Nintendo Switch Lite, supondo que você tenha um controle Bluetooth e um celular com uma configuração respeitável e com mais de 2000mAh de bateria. O único quesito que o Switch Lite ganha é que é apenas uma única configuração de hardware, portanto os desenvolvedores oferecem o suporte aos seus jogos de maneira que rodem de forma suave e compatível, coisa que não se vê muito em jogos Android em 2020.Adicionalmente, se o seu Switch Lite for teu hardware principal para jogos, ele vai ficar bastante judiado.Você vai precisar de um case, uma skin e um grip. Eu recomendo essa solução três-em-um da Skull & Co: screen protector para evitar arranhões na tela: por fim, um cartão de memória. Dependendo se você for um colecionador, a memória interna talvez seja o suficiente. Caso contrário, um cartão de 200GB da SanDisk deve bastar para o seu primeiro ano com o Switch Lite:\n\n\n5503\nButton on left as in picture broke too easily please send new one to my niece. Jennifer Canady We spent $200 for this in June.... and we will send old one back (include return shipping label) please call Deborah 512-809-5934 or Sandra niece (512) 944-2592thank you\nButton on left as in picture broke too easily please send new one to my niece. Jennifer Canady We spent $200 for this in June.... and we will send old one back (include return shipping label) please call Deborah or Sandra niece thank you\n\n\n12295\nPlease warranty my joy-con Left-side doesn’t charge! New email is huitang2009@hotmail.com. I bought it 2/12 2018!! Only use couple times! Sent me warranty one so I can sent you back the broken one!!!!!\nPlease warranty my joy-con Left-side doesn’t charge! New email is I bought it 2/12 2018!! Only use couple times! Sent me warranty one so I can sent you back the broken one!!!!!"
  },
  {
    "objectID": "posts/2021-07-27-nlp_7_text_preprocessing_and_labelling_[part_1].html#step-3-remove-emoji",
    "href": "posts/2021-07-27-nlp_7_text_preprocessing_and_labelling_[part_1].html#step-3-remove-emoji",
    "title": "Text Processing & Labelling [Part1]",
    "section": "Step 3: Remove emoji",
    "text": "Step 3: Remove emoji\n\ndef remove_emoji(text):\n    return emoji.get_emoji_regexp().sub(r\" \", text)\n\n\ndf[\"no_emoji\"] = df[\"no_redundant\"].apply(remove_emoji)\n\n\ndf[df[\"no_redundant\"] != df[\"no_emoji\"]][[\"no_redundant\", \"no_emoji\"]]\n\n\n\n\n\n\n\n\nno_redundant\nno_emoji\n\n\n\n\n19\nI have been using my renewed computer 👩🏾‍💻 for about 2 weeks now and I am so glad I bought it from “All-out-Apple” the best computer seller on Amazon! I received the 2018 MacBook Air i5 quad core 256gb and the actual specs matched the description! I use it for college for my Zoom classes and the virtual background works!! I upgraded from my 2013 MacBook Air and this one is a lot faster and a much better battery life. It also came with a brand new usb-c original Apple charger for this Mac. This computer is like-new with no scratches at all and I was able to transfer all my old data to this new computer. I would recommend this computer for students and teachers too.\nI have been using my renewed computer for about 2 weeks now and I am so glad I bought it from “All-out-Apple” the best computer seller on Amazon! I received the 2018 MacBook Air i5 quad core 256gb and the actual specs matched the description! I use it for college for my Zoom classes and the virtual background works!! I upgraded from my 2013 MacBook Air and this one is a lot faster and a much better battery life. It also came with a brand new usb-c original Apple charger for this Mac. This computer is like-new with no scratches at all and I was able to transfer all my old data to this new computer. I would recommend this computer for students and teachers too.\n\n\n239\nGreat purchase! Worth every penny. And the color is gorgeous 😍\nGreat purchase! Worth every penny. And the color is gorgeous\n\n\n363\nI spent a lot of time debating on purchasing brand new or renewed off amazon. I ended up going the cheaper route and went with the amazon renewed one. The product came in a plain brown box, but was wrapped like it was brand new. There are no marks or dents on mine, and it acts like a brand new computer!! I am obsessed with it!!! Best purchase I’ve made all year. Seriously, great bang for your buck! 😁\nI spent a lot of time debating on purchasing brand new or renewed off amazon. I ended up going the cheaper route and went with the amazon renewed one. The product came in a plain brown box, but was wrapped like it was brand new. There are no marks or dents on mine, and it acts like a brand new computer!! I am obsessed with it!!! Best purchase I’ve made all year. Seriously, great bang for your buck!\n\n\n475\nI'm happy with product. Is apple 🍎 there's not much to say. there product are great. I'm a prime member. I received it 2 days later. My daughter needed for school on line\nI'm happy with product. Is apple there's not much to say. there product are great. I'm a prime member. I received it 2 days later. My daughter needed for school on line\n\n\n527\nI’m in love with my new Mac book very easy to use and set up. I Definitely recommend it great purchase that I did 👌😁\nI’m in love with my new Mac book very easy to use and set up. I Definitely recommend it great purchase that I did\n\n\n...\n...\n...\n\n\n11874\nArrived broken, you can see in the one pic how it came, when my husband took it out of the plastic he said this isn’t right. The black part was completely unattached to the red main part. Upon inspection, because my husband can fix anything...it looks like someone just ripped it off the main part of the controller. It’s missing one screw and the other was ripped out with the red con plastic still on it. It’s beyond repair 😒. How did it pass inspection?!\nArrived broken, you can see in the one pic how it came, when my husband took it out of the plastic he said this isn’t right. The black part was completely unattached to the red main part. Upon inspection, because my husband can fix anything...it looks like someone just ripped it off the main part of the controller. It’s missing one screw and the other was ripped out with the red con plastic still on it. It’s beyond repair . How did it pass inspection?!\n\n\n11894\nHad original gray Joy-Cons when I got my Switch and had the dreaded analog drift. It was time I purchased official Nintendo (pricey) Joy-Cons...and always thought this Neon Purple/Orange was eye-catching and lemme tell you...once you see them in person, they're beautiful.All the buttons feel a notch up more stable and comfortable to the input. Drift is no longer an issue and I was super satisfied with these Joy-Cons. My Switch never looked better. 😉\nHad original gray Joy-Cons when I got my Switch and had the dreaded analog drift. It was time I purchased official Nintendo (pricey) Joy-Cons...and always thought this Neon Purple/Orange was eye-catching and lemme tell you...once you see them in person, they're beautiful.All the buttons feel a notch up more stable and comfortable to the input. Drift is no longer an issue and I was super satisfied with these Joy-Cons. My Switch never looked better.\n\n\n11934\nOnly giving it one star because they worked great for about 2 days then the right controller started doing exactly the same thing our left controller did. We bought these to replace our original ones but they’re the same 😒\nOnly giving it one star because they worked great for about 2 days then the right controller started doing exactly the same thing our left controller did. We bought these to replace our original ones but they’re the same\n\n\n11942\nI surprised my nephew for 10th birthday andHe loves it!🙂\nI surprised my nephew for 10th birthday andHe loves it!\n\n\n12134\nI love these Joy Cons I purchased for the purpose of replacing my red and blue neon pair because the left joy con's analog stick was broken. My biggest problem/complaint is that the left Joy Con battery dies way too quickly. It's almost been a month since I had these joy cons and I've never had to charge the left one, only the right one. I don't understand it 🤷🤷\nI love these Joy Cons I purchased for the purpose of replacing my red and blue neon pair because the left joy con's analog stick was broken. My biggest problem/complaint is that the left Joy Con battery dies way too quickly. It's almost been a month since I had these joy cons and I've never had to charge the left one, only the right one. I don't understand it\n\n\n\n\n217 rows × 2 columns\n\n\n\nAll the emojies detected are removed"
  },
  {
    "objectID": "posts/2021-07-27-nlp_7_text_preprocessing_and_labelling_[part_1].html#step-4-expand-contractions",
    "href": "posts/2021-07-27-nlp_7_text_preprocessing_and_labelling_[part_1].html#step-4-expand-contractions",
    "title": "Text Processing & Labelling [Part1]",
    "section": "Step 4: Expand Contractions",
    "text": "Step 4: Expand Contractions\n\ndef expand_contractions(text):\n    \"\"\"expand shortened words, e.g. don't to do not\"\"\"\n    text = contractions.fix(text)\n    return text\n\n\ndf[\"expand_contractions\"] = df[\"no_emoji\"].apply(expand_contractions)\n\n\ndf[df[\"expand_contractions\"] != df[\"no_emoji\"]][[\"no_emoji\", \"expand_contractions\"]]\n\n\n\n\n\n\n\n\nno_emoji\nexpand_contractions\n\n\n\n\n1\nBest computer I’ve ever own!! This computer forces me to be productive. I used to wait around for this spinning wheel to stop, and now I can do everything so quickly that I think I almost miss the waiting part. Ha ha. I don’t have time to get coffee anymore. All my apps run smoothly, including adobe illustrator and Photoshop, and they work perfectly. Almost too perfect. I really love this computer. I hope it last me for many years to come.\nBest computer I have ever own!! This computer forces me to be productive. I used to wait around for this spinning wheel to stop, and now I can do everything so quickly that I think I almost miss the waiting part. Ha ha. I do not have time to get coffee anymore. All my apps run smoothly, including adobe illustrator and Photoshop, and they work perfectly. Almost too perfect. I really love this computer. I hope it last me for many years to come.\n\n\n4\nI left my brand new Macbook pro in my car for an hour and now the screen looks like a Picasso painting. Neither Amazon nor Macintosh will pay for repairs, even though I bought it only two months ago, so I'm out $700 to repair my brand new computer. I would heavily advise against buying one of these, because if 80 degree heat is enough to damage the screen, then they're essentially useless if your air conditioner goes out and you will be left with a repair bill that is half the value of the computer.\nI left my brand new Macbook pro in my car for an hour and now the screen looks like a Picasso painting. Neither Amazon nor Macintosh will pay for repairs, even though I bought it only two months ago, so I am out $700 to repair my brand new computer. I would heavily advise against buying one of these, because if 80 degree heat is enough to damage the screen, then they are essentially useless if your air conditioner goes out and you will be left with a repair bill that is half the value of the computer.\n\n\n8\nProduct came in excellent condition. Battery life isn’t as long as I would like it to be. Product overall works excellent.\nProduct came in excellent condition. Battery life is not as long as I would like it to be. Product overall works excellent.\n\n\n9\nI don’t what to think I bought 2017 16gb 256 ssd but I received a refurbished 2019 8g 256 perfectly packaged, I can’t put apple care I already call for that but im not sure to keep it because I want a computer of 16of ram but this one is 2019, im gonna give the chance to see how it works, And it cost me the same price of a refurbished 2019 Of apple but those ones you can put apple care\nI do not what to think I bought 2017 16gb 256 ssd but I received a refurbished 2019 8g 256 perfectly packaged, I cannot put apple care I already call for that but I am not sure to keep it because I want a computer of 16of ram but this one is 2019, I am going to give the chance to see how it works, And it cost me the same price of a refurbished 2019 Of apple but those ones you can put apple care\n\n\n15\nKEYBOARD FAILED! I ordered this in November and started using it in January as my main “home” laptop (minimal use). The keyboard stopped working properly in June. Some letters don’t regularly work. Sometimes - but not always- the space bar leaves two spaces instead of one. I wish I spent the money to get a NEW laptop and not refurbished. This was my first refurbished purchase, which I now see is a mistake. I live in a remote area, so fixing a keyboard may outweigh the cost savings. The battery works fine. Regrets here.\nKEYBOARD FAILED! I ordered this in November and started using it in January as my main “home” laptop (minimal use). The keyboard stopped working properly in June. Some letters do not regularly work. Sometimes - but not always- the space bar leaves two spaces instead of one. I wish I spent the money to get a NEW laptop and not refurbished. This was my first refurbished purchase, which I now see is a mistake. I live in a remote area, so fixing a keyboard may outweigh the cost savings. The battery works fine. Regrets here.\n\n\n...\n...\n...\n\n\n12413\nWe must all understand the expectations of purchasing used products. I bought these joy-cons used directly by Amazon as \"very good condition\", so I figured I would take the chance. With how great amazon is delivering quality for a great price, their reputation made me feel at ease for buying used directly from them.Instant regret when I opened the box. The right joy-con has severe drifting issue with the joystick. And there are many bite marks on both joy-cons. No doubt adding to the drifting. I did what I could to clean the base of the joystick without opening either device. But even then, major involuntary movements when using it. I have to be sure I recenter the stick after every movement to reduce drift.Might not be clear enough, but in the pictures I attached you might be able to make out the various bite marks and the damaged joystick base. Nintendo is very aware that their older joy-con controllers are prone to this drifting problem, and thus offer free repairs or replacements well past their warranty. However, that whole repair process with Nintendo takes around 3 weeks. I don't have that time, so instead I returned these to Amazon. I am hopeful that Amazon won't put these back up for sale as someone else will be disappointed :(Save yourselves the headache and invest an extra $10 for new joy-cons.\nWe must all understand the expectations of purchasing used products. I bought these joy-cons used directly by Amazon as \"very good condition\", so I figured I would take the chance. With how great amazon is delivering quality for a great price, their reputation made me feel at ease for buying used directly from them.Instant regret when I opened the box. The right joy-con has severe drifting issue with the joystick. And there are many bite marks on both joy-cons. No doubt adding to the drifting. I did what I could to clean the base of the joystick without opening either device. But even then, major involuntary movements when using it. I have to be sure I recenter the stick after every movement to reduce drift.Might not be clear enough, but in the pictures I attached you might be able to make out the various bite marks and the damaged joystick base. Nintendo is very aware that their older joy-con controllers are prone to this drifting problem, and thus offer free repairs or replacements well past their warranty. However, that whole repair process with Nintendo takes around 3 weeks. I do not have that time, so instead I returned these to Amazon. I am hopeful that Amazon will not put these back up for sale as someone else will be disappointed :(Save yourselves the headache and invest an extra $10 for new joy-cons.\n\n\n12415\nThis is not so much a product review as a compliment, so here goes...Just wanted to give the Amazon delivery service a “Thank you”. I’ve had my Switch for almost 2 yrs and have logged many happy, sometimes frustrating hours on it. So last week when the Joy-Cons started gradually sticking I knew they needed replacing. The R stick wasn’t actually “physically” sticking to the right, but was sending the message to the game to move right when I wanted to stand my ground. Don’t know if any of you have ever tried fighting Ice Lizalfos on a mountain top while Link keeps trying to creep off the cliff, but I would not recommend it. I’d already searched to replace them, but due to the COVID pandemic Switch Joy-Cons are near impossible to get in regular grey here in Sacramento. EVERY store was wiped out. Even GameStop, Walmart, Best Buy and Fry’s couldn’t provide via store OR online. Amazon said they could deliver, but not until August 1st... it was the best offer I could get. So when that beautiful little brown box showed up yesterday afternoon, July 28th, while I was actually playing Zelda BOTW no less, the feelings of relief that swept over me can only be understated. And just in time too. Yesterday, only an hour or so before delivery, the L stick was starting to stick to the right also. Whew!.... Thanks again, Amazon for that little extra “sumthin’” you always seem to provide.P.S. Oh, and the controllers were delivered, packaged, and function perfectly. The actual Nintendo Joy-Con box was untampered and had safety seals in tact - something I always look for, especially with electronics (and food, of course).\nThis is not so much a product review as a compliment, so here goes...Just wanted to give the Amazon delivery service a “Thank you”. I have had my Switch for almost 2 yrs and have logged many happy, sometimes frustrating hours on it. So last week when the Joy-Cons started gradually sticking I knew they needed replacing. The R stick was not actually “physically” sticking to the right, but was sending the message to the game to move right when I wanted to stand my ground. do not know if any of you have ever tried fighting Ice Lizalfos on a mountain top while Link keeps trying to creep off the cliff, but I would not recommend it. I would already searched to replace them, but due to the COVID pandemic Switch Joy-Cons are near impossible to get in regular grey here in Sacramento. EVERY store was wiped out. Even GameStop, Walmart, Best Buy and Fry’s could not provide via store OR online. Amazon said they could deliver, but not until August 1st... it was the best offer I could get. So when that beautiful little brown box showed up yesterday afternoon, July 28th, while I was actually playing Zelda BOTW no less, the feelings of relief that swept over me can only be understated. And just in time too. Yesterday, only an hour or so before delivery, the L stick was starting to stick to the right also. Whew!.... Thanks again, Amazon for that little extra “sumthin’” you always seem to provide.P.S. Oh, and the controllers were delivered, packaged, and function perfectly. The actual Nintendo Joy-Con box was untampered and had safety seals in tact - something I always look for, especially with electronics (and food, of course).\n\n\n12416\nI desperately wanted to love this product. I'm a huge Nintendo fan & Switch advocate. I love that they have HD rumble, an NFC reader, & pretty responsive gyro controls. I even love that they can be used as individual controllers for many games. What I don't love is the horrible drift all 6 pairs I've purchased has eventually gotten (4 different pairs purchased, a blue pair, 2 yellow pair, & the green/pink pair, plus 2 more pairs from purchasing systems). Before anyone wants to jump down my throat saying I should've gone to Nintendo, I actually have done that more than once. Nintendo did not charge me anything to send them for repairs because each time they claimed nothing was wrong with them & the very same Joy-Cons would be returned to me. Lo & behold, these Joy-Cons that were returned to me still drifted. Other than that, I've heard people say the size of these controllers aren't bothersome or small. I've also heard people say they're much too small, & I certainly fall somewhere in the latter category. Holding & playing my Switch in handheld is always a struggle, even for a short amount of time. I don't know if having sorta big hands was a factor but after a few months, most of my Joy-Cons also began having issues remaining securely on the side rails. This is especially true for my original Cons, they would frequently have to be clicked back into place for handheld mode. Overall I don't mind how the Joy-Cons work at all. But either I'm an incredibly unlucky sob or there is something wrong with how the control sticks are designed or manufactured.\nI desperately wanted to love this product. I am a huge Nintendo fan & Switch advocate. I love that they have HD rumble, an NFC reader, & pretty responsive gyro controls. I even love that they can be used as individual controllers for many games. What I do not love is the horrible drift all 6 pairs I have purchased has eventually gotten (4 different pairs purchased, a blue pair, 2 yellow pair, & the green/pink pair, plus 2 more pairs from purchasing systems). Before anyone wants to jump down my throat saying I should have gone to Nintendo, I actually have done that more than once. Nintendo did not charge me anything to send them for repairs because each time they claimed nothing was wrong with them & the very same Joy-Cons would be returned to me. Lo & behold, these Joy-Cons that were returned to me still drifted. Other than that, I have heard people say the size of these controllers are not bothersome or small. I have also heard people say they are much too small, & I certainly fall somewhere in the latter category. Holding & playing my Switch in handheld is always a struggle, even for a short amount of time. I do not know if having sorta big hands was a factor but after a few months, most of my Joy-Cons also began having issues remaining securely on the side rails. This is especially true for my original Cons, they would frequently have to be clicked back into place for handheld mode. Overall I do not mind how the Joy-Cons work at all. But either I am an incredibly unlucky sob or there is something wrong with how the control sticks are designed or manufactured.\n\n\n12417\nBought these controllers because after a year the ones that came with the switch started to malfunction. One of the analog controllers would drift making gameplay extremely hard. It would make scrolling through menus damn near impossible. I did buy the replacement parts and fixed the remote first (because that is the much cheaper option) but within two months it started happening again so I decided to bite the bullet and replace them. Wouldn’t you know the replacements came and didn’t even last two weeks with very light use! The analog broke and the controller started drifting again. I looked it up and it turns out that this is a common problem with these remotes. I’m disappointed with nintendo. You pay a lot for these systems and the accessories I expect them to last at least a few years. I will say that Amazon was fantastic and replaced them right away. The replacement should be here today. I’m curious to see how long this one lasts.\nBought these controllers because after a year the ones that came with the switch started to malfunction. One of the analog controllers would drift making gameplay extremely hard. It would make scrolling through menus damn near impossible. I did buy the replacement parts and fixed the remote first (because that is the much cheaper option) but within two months it started happening again so I decided to bite the bullet and replace them. would not you know the replacements came and did not even last two weeks with very light use! The analog broke and the controller started drifting again. I looked it up and it turns out that this is a common problem with these remotes. I am disappointed with nintendo. You pay a lot for these systems and the accessories I expect them to last at least a few years. I will say that Amazon was fantastic and replaced them right away. The replacement should be here today. I am curious to see how long this one lasts.\n\n\n12418\nEdit: 2yrs later. Today is april 24th 2021 and let me say i am still disappointed. These worked but were the first to start drifting after about i dunno 1 month not bad but still upsetting for full price \"new\" joycons... both drift and still do till this day simply bc i have not sent them out to be fixed.1. Not new joy cons2. colors were swaped (didn’t even match what the actual box stated; (L) red (R) Blue)3. They are USEDso to start off the box of the controllers itself seemed to be slightly bent as if something heavier was placed on top. The first thing that i noticed was the colors were switched than advertised on the box (i dont mind that at all).Then i decided to check the controllers individually; both have black scratch marks as if being constantly put on and taken off of the console. With that said it already tells me they were used; now i did not pay ‘full’ price for something to be used, i initially didn’t buy them used. I could see small chips on the paint where they slide on and off of the console.Now they work, yes they seemed to work when i put them on the console; however, i haven’t actually played using them yet.I gave this 3 stars mainly for the fact that technically i didn’t get what i paid for. All in all i dont mind, as long as they work but it is upsetting to not get a good presentation.\nEdit: 2yrs later. Today is april 24th 2021 and let me say i am still disappointed. These worked but were the first to start drifting after about i dunno 1 month not bad but still upsetting for full price \"new\" joycons... both drift and still do till this day simply bc i have not sent them out to be fixed.1. Not new joy cons2. colors were swaped (did not even match what the actual box stated; (L) red (R) Blue)3. They are USEDso to start off the box of the controllers itself seemed to be slightly bent as if something heavier was placed on top. The first thing that i noticed was the colors were switched than advertised on the box (i do not mind that at all).Then i decided to check the controllers individually; both have black scratch marks as if being constantly put on and taken off of the console. With that said it already tells me they were used; now i did not pay ‘full’ price for something to be used, i initially did not buy them used. I could see small chips on the paint where they slide on and off of the console.Now they work, yes they seemed to work when i put them on the console; however, i have not actually played using them yet.I gave this 3 stars mainly for the fact that technically i did not get what i paid for. All in all i do not mind, as long as they work but it is upsetting to not get a good presentation.\n\n\n\n\n3400 rows × 2 columns"
  },
  {
    "objectID": "posts/2021-07-27-nlp_7_text_preprocessing_and_labelling_[part_1].html#step-5-removing-accented-characters",
    "href": "posts/2021-07-27-nlp_7_text_preprocessing_and_labelling_[part_1].html#step-5-removing-accented-characters",
    "title": "Text Processing & Labelling [Part1]",
    "section": "Step 5: Removing accented characters",
    "text": "Step 5: Removing accented characters\n\nimport unidecode\ndef remove_accented_chars(text):\n    text = unidecode.unidecode(text)\n    return text\n\n\ndf[\"no_accented\"] = df[\"expand_contractions\"].apply(remove_accented_chars)\n\n\ndf[df[\"expand_contractions\"] != df[\"no_accented\"]][[\"expand_contractions\", \"no_accented\"]]\n\n\n\n\n\n\n\n\nexpand_contractions\nno_accented\n\n\n\n\n15\nKEYBOARD FAILED! I ordered this in November and started using it in January as my main “home” laptop (minimal use). The keyboard stopped working properly in June. Some letters do not regularly work. Sometimes - but not always- the space bar leaves two spaces instead of one. I wish I spent the money to get a NEW laptop and not refurbished. This was my first refurbished purchase, which I now see is a mistake. I live in a remote area, so fixing a keyboard may outweigh the cost savings. The battery works fine. Regrets here.\nKEYBOARD FAILED! I ordered this in November and started using it in January as my main \"home\" laptop (minimal use). The keyboard stopped working properly in June. Some letters do not regularly work. Sometimes - but not always- the space bar leaves two spaces instead of one. I wish I spent the money to get a NEW laptop and not refurbished. This was my first refurbished purchase, which I now see is a mistake. I live in a remote area, so fixing a keyboard may outweigh the cost savings. The battery works fine. Regrets here.\n\n\n19\nI have been using my renewed computer for about 2 weeks now and I am so glad I bought it from “All-out-Apple” the best computer seller on Amazon! I received the 2018 MacBook Air i5 quad core 256gb and the actual specs matched the description! I use it for college for my Zoom classes and the virtual background works!! I upgraded from my 2013 MacBook Air and this one is a lot faster and a much better battery life. It also came with a brand new usb-c original Apple charger for this Mac. This computer is like-new with no scratches at all and I was able to transfer all my old data to this new computer. I would recommend this computer for students and teachers too.\nI have been using my renewed computer for about 2 weeks now and I am so glad I bought it from \"All-out-Apple\" the best computer seller on Amazon! I received the 2018 MacBook Air i5 quad core 256gb and the actual specs matched the description! I use it for college for my Zoom classes and the virtual background works!! I upgraded from my 2013 MacBook Air and this one is a lot faster and a much better battery life. It also came with a brand new usb-c original Apple charger for this Mac. This computer is like-new with no scratches at all and I was able to transfer all my old data to this new computer. I would recommend this computer for students and teachers too.\n\n\n24\nExcelente producto!! Sin palabras!, Lo mejor para el trabajo, gaming, día a día, el mejor producto de apple hasta la fecha!!!\nExcelente producto!! Sin palabras!, Lo mejor para el trabajo, gaming, dia a dia, el mejor producto de apple hasta la fecha!!!\n\n\n36\nWow, absolutely perfect! I bought this for my daughter’s birthday and for her to use at college. She loves it!! It arrived super fast and in perfect condition!! We are extremely pleased with this MacBook. Thanks for a great purchase!\nWow, absolutely perfect! I bought this for my daughter's birthday and for her to use at college. She loves it!! It arrived super fast and in perfect condition!! We are extremely pleased with this MacBook. Thanks for a great purchase!\n\n\n48\nI am kindof dissatisfied. So I just opened it and cannot tell you everything, however I can tell you what I do not like that I already found. The apple emblem is cracked and the power cord that it came with has MANY scratches, bumps, and scrapes all over it so I question if the cable even charges properly. I know this is referbished, but can we please follow the policy \"external finishes like new” legit? Aside from those so far I am satisfied. Scrolling on the mouse pad is Kindof meh but maybe it is because I am not use to it yet? The keys are in fine condition and the finger print scanner works. I was worried with some of the reviews saying that they got a grey instead of a space grey but mine is space grey so I am very happy. My fave color. I can leave another review with more information after a week or so of use.\nI am kindof dissatisfied. So I just opened it and cannot tell you everything, however I can tell you what I do not like that I already found. The apple emblem is cracked and the power cord that it came with has MANY scratches, bumps, and scrapes all over it so I question if the cable even charges properly. I know this is referbished, but can we please follow the policy \"external finishes like new\" legit? Aside from those so far I am satisfied. Scrolling on the mouse pad is Kindof meh but maybe it is because I am not use to it yet? The keys are in fine condition and the finger print scanner works. I was worried with some of the reviews saying that they got a grey instead of a space grey but mine is space grey so I am very happy. My fave color. I can leave another review with more information after a week or so of use.\n\n\n...\n...\n...\n\n\n12362\nCompré este par de Joy-Con para reemplazar los grises que venían originalmente con mi consola, pues esos tenían input lag, muy notorio especialmente en el control derecho.Estos Joy-Con color neon venían \"sellados\", pero pareciera que retiraron el sello original, abrieron la caja, usaron los controles y luego los volvieron a colocar. Digo lo de los sellos porque en la caja hay partes donde falta pintura y se nota que un sello la retiró.Además menciono que usaron los controles, debido a que recién sacados de la caja, tienen marcas de haber sido introducidos en una consola (los rieles dejaron marca). Lo cual realmente no da entera confianza de que el producto sea nuevo.El producto funciona, pero cuesta mucho creer que sea 100% nuevo. Además afuera de la caja menciona que debe incluirse una guía de inicio rápido y una póliza de garantía, cosa que no venía incluída.\nCompre este par de Joy-Con para reemplazar los grises que venian originalmente con mi consola, pues esos tenian input lag, muy notorio especialmente en el control derecho.Estos Joy-Con color neon venian \"sellados\", pero pareciera que retiraron el sello original, abrieron la caja, usaron los controles y luego los volvieron a colocar. Digo lo de los sellos porque en la caja hay partes donde falta pintura y se nota que un sello la retiro.Ademas menciono que usaron los controles, debido a que recien sacados de la caja, tienen marcas de haber sido introducidos en una consola (los rieles dejaron marca). Lo cual realmente no da entera confianza de que el producto sea nuevo.El producto funciona, pero cuesta mucho creer que sea 100% nuevo. Ademas afuera de la caja menciona que debe incluirse una guia de inicio rapido y una poliza de garantia, cosa que no venia incluida.\n\n\n12363\nA ciencia cierta no sé que pasó, los dos primeros cinco días de uso con mi nintendo switch en modo de sobremesa, al jugar mario odyssey me dieron muchos problemas estoy joy con nuevos. Inicia el juego, inicia la partida y parece que todo normal, pero después de los primeros cinco minutos de juego, dejaban de funcionar, se apagaban/desconectaban había que oprimir los botones para que la consola los reconociera nuevamente. No funcionó, los acoplé a la consola y los reconoció de inmediato, volví a sobremesa y oprimí los botones y volvieron a funcionar. Así los 4 días restantes, pensé en hacer la devolución pero finalmente terminó por dejar de pasar ese error y amarga experiencia. Los utilizo diariamente y no ha vuelto a suceder. Ahora que sú estética es excelente son realmente bonitos en color naranja y morado neón, no creo que vuelva a suceder dicho error menos con nintendo en la mira de todos pero quién sabe. Los joy con de mi consola nunca me hicieron eso de dejar de funcionar sin embargo el control izquierdo tiene problema con la palanquilla izquierda que hace que el personaje se mueva solo, lo que me hizo optar por estos atractivos joy con nuevos y chulos de bonitos, pero parece que todos los productos de nintendo switch acaban teniendo algún detallito. Después de esos días frustrantes ahora estoy muy contento con su uso.\nA ciencia cierta no se que paso, los dos primeros cinco dias de uso con mi nintendo switch en modo de sobremesa, al jugar mario odyssey me dieron muchos problemas estoy joy con nuevos. Inicia el juego, inicia la partida y parece que todo normal, pero despues de los primeros cinco minutos de juego, dejaban de funcionar, se apagaban/desconectaban habia que oprimir los botones para que la consola los reconociera nuevamente. No funciono, los acople a la consola y los reconocio de inmediato, volvi a sobremesa y oprimi los botones y volvieron a funcionar. Asi los 4 dias restantes, pense en hacer la devolucion pero finalmente termino por dejar de pasar ese error y amarga experiencia. Los utilizo diariamente y no ha vuelto a suceder. Ahora que su estetica es excelente son realmente bonitos en color naranja y morado neon, no creo que vuelva a suceder dicho error menos con nintendo en la mira de todos pero quien sabe. Los joy con de mi consola nunca me hicieron eso de dejar de funcionar sin embargo el control izquierdo tiene problema con la palanquilla izquierda que hace que el personaje se mueva solo, lo que me hizo optar por estos atractivos joy con nuevos y chulos de bonitos, pero parece que todos los productos de nintendo switch acaban teniendo algun detallito. Despues de esos dias frustrantes ahora estoy muy contento con su uso.\n\n\n12377\nSúper bien\nSuper bien\n\n\n12415\nThis is not so much a product review as a compliment, so here goes...Just wanted to give the Amazon delivery service a “Thank you”. I have had my Switch for almost 2 yrs and have logged many happy, sometimes frustrating hours on it. So last week when the Joy-Cons started gradually sticking I knew they needed replacing. The R stick was not actually “physically” sticking to the right, but was sending the message to the game to move right when I wanted to stand my ground. do not know if any of you have ever tried fighting Ice Lizalfos on a mountain top while Link keeps trying to creep off the cliff, but I would not recommend it. I would already searched to replace them, but due to the COVID pandemic Switch Joy-Cons are near impossible to get in regular grey here in Sacramento. EVERY store was wiped out. Even GameStop, Walmart, Best Buy and Fry’s could not provide via store OR online. Amazon said they could deliver, but not until August 1st... it was the best offer I could get. So when that beautiful little brown box showed up yesterday afternoon, July 28th, while I was actually playing Zelda BOTW no less, the feelings of relief that swept over me can only be understated. And just in time too. Yesterday, only an hour or so before delivery, the L stick was starting to stick to the right also. Whew!.... Thanks again, Amazon for that little extra “sumthin’” you always seem to provide.P.S. Oh, and the controllers were delivered, packaged, and function perfectly. The actual Nintendo Joy-Con box was untampered and had safety seals in tact - something I always look for, especially with electronics (and food, of course).\nThis is not so much a product review as a compliment, so here goes...Just wanted to give the Amazon delivery service a \"Thank you\". I have had my Switch for almost 2 yrs and have logged many happy, sometimes frustrating hours on it. So last week when the Joy-Cons started gradually sticking I knew they needed replacing. The R stick was not actually \"physically\" sticking to the right, but was sending the message to the game to move right when I wanted to stand my ground. do not know if any of you have ever tried fighting Ice Lizalfos on a mountain top while Link keeps trying to creep off the cliff, but I would not recommend it. I would already searched to replace them, but due to the COVID pandemic Switch Joy-Cons are near impossible to get in regular grey here in Sacramento. EVERY store was wiped out. Even GameStop, Walmart, Best Buy and Fry's could not provide via store OR online. Amazon said they could deliver, but not until August 1st... it was the best offer I could get. So when that beautiful little brown box showed up yesterday afternoon, July 28th, while I was actually playing Zelda BOTW no less, the feelings of relief that swept over me can only be understated. And just in time too. Yesterday, only an hour or so before delivery, the L stick was starting to stick to the right also. Whew!.... Thanks again, Amazon for that little extra \"sumthin'\" you always seem to provide.P.S. Oh, and the controllers were delivered, packaged, and function perfectly. The actual Nintendo Joy-Con box was untampered and had safety seals in tact - something I always look for, especially with electronics (and food, of course).\n\n\n12418\nEdit: 2yrs later. Today is april 24th 2021 and let me say i am still disappointed. These worked but were the first to start drifting after about i dunno 1 month not bad but still upsetting for full price \"new\" joycons... both drift and still do till this day simply bc i have not sent them out to be fixed.1. Not new joy cons2. colors were swaped (did not even match what the actual box stated; (L) red (R) Blue)3. They are USEDso to start off the box of the controllers itself seemed to be slightly bent as if something heavier was placed on top. The first thing that i noticed was the colors were switched than advertised on the box (i do not mind that at all).Then i decided to check the controllers individually; both have black scratch marks as if being constantly put on and taken off of the console. With that said it already tells me they were used; now i did not pay ‘full’ price for something to be used, i initially did not buy them used. I could see small chips on the paint where they slide on and off of the console.Now they work, yes they seemed to work when i put them on the console; however, i have not actually played using them yet.I gave this 3 stars mainly for the fact that technically i did not get what i paid for. All in all i do not mind, as long as they work but it is upsetting to not get a good presentation.\nEdit: 2yrs later. Today is april 24th 2021 and let me say i am still disappointed. These worked but were the first to start drifting after about i dunno 1 month not bad but still upsetting for full price \"new\" joycons... both drift and still do till this day simply bc i have not sent them out to be fixed.1. Not new joy cons2. colors were swaped (did not even match what the actual box stated; (L) red (R) Blue)3. They are USEDso to start off the box of the controllers itself seemed to be slightly bent as if something heavier was placed on top. The first thing that i noticed was the colors were switched than advertised on the box (i do not mind that at all).Then i decided to check the controllers individually; both have black scratch marks as if being constantly put on and taken off of the console. With that said it already tells me they were used; now i did not pay 'full' price for something to be used, i initially did not buy them used. I could see small chips on the paint where they slide on and off of the console.Now they work, yes they seemed to work when i put them on the console; however, i have not actually played using them yet.I gave this 3 stars mainly for the fact that technically i did not get what i paid for. All in all i do not mind, as long as they work but it is upsetting to not get a good presentation.\n\n\n\n\n1466 rows × 2 columns"
  },
  {
    "objectID": "posts/2021-07-27-nlp_7_text_preprocessing_and_labelling_[part_1].html#step-6-collapse-duplicated-punctuation",
    "href": "posts/2021-07-27-nlp_7_text_preprocessing_and_labelling_[part_1].html#step-6-collapse-duplicated-punctuation",
    "title": "Text Processing & Labelling [Part1]",
    "section": "Step 6: Collapse duplicated punctuation",
    "text": "Step 6: Collapse duplicated punctuation\n\npunc = string.punctuation\n\ndef remove_consecutive_punctuation(text):\n    newtext = []\n    for k, g in groupby(text):\n        if k in punc:\n            newtext.append(k + \" \")\n        else:\n            newtext.extend(g)\n\n    return ''.join(newtext) \n\n\nremove_consecutive_punctuation(\"Hello World..Now I can see you\")\n\n\ndf[\"no_consecutive_punc\"] = df[\"expand_contractions\"].apply(remove_consecutive_punctuation)\n\n\ndf[df[\"expand_contractions\"] != df[\"no_consecutive_punc\"]][[\"expand_contractions\", \"no_consecutive_punc\"]]\n\n\n\n\n\n\n\n\nexpand_contractions\nno_consecutive_punc\n\n\n\n\n1\nBest computer I have ever own!! This computer forces me to be productive. I used to wait around for this spinning wheel to stop, and now I can do everything so quickly that I think I almost miss the waiting part. Ha ha. I do not have time to get coffee anymore. All my apps run smoothly, including adobe illustrator and Photoshop, and they work perfectly. Almost too perfect. I really love this computer. I hope it last me for many years to come.\nBest computer I have ever own! This computer forces me to be productive. I used to wait around for this spinning wheel to stop, and now I can do everything so quickly that I think I almost miss the waiting part. Ha ha. I do not have time to get coffee anymore. All my apps run smoothly, including adobe illustrator and Photoshop, and they work perfectly. Almost too perfect. I really love this computer. I hope it last me for many years to come.\n\n\n11\nPositivo, EXCELENTE EQUIPO!!!\nPositivo, EXCELENTE EQUIPO!\n\n\n19\nI have been using my renewed computer for about 2 weeks now and I am so glad I bought it from “All-out-Apple” the best computer seller on Amazon! I received the 2018 MacBook Air i5 quad core 256gb and the actual specs matched the description! I use it for college for my Zoom classes and the virtual background works!! I upgraded from my 2013 MacBook Air and this one is a lot faster and a much better battery life. It also came with a brand new usb-c original Apple charger for this Mac. This computer is like-new with no scratches at all and I was able to transfer all my old data to this new computer. I would recommend this computer for students and teachers too.\nI have been using my renewed computer for about 2 weeks now and I am so glad I bought it from “All-out-Apple” the best computer seller on Amazon! I received the 2018 MacBook Air i5 quad core 256gb and the actual specs matched the description! I use it for college for my Zoom classes and the virtual background works! I upgraded from my 2013 MacBook Air and this one is a lot faster and a much better battery life. It also came with a brand new usb-c original Apple charger for this Mac. This computer is like-new with no scratches at all and I was able to transfer all my old data to this new computer. I would recommend this computer for students and teachers too.\n\n\n24\nExcelente producto!! Sin palabras!, Lo mejor para el trabajo, gaming, día a día, el mejor producto de apple hasta la fecha!!!\nExcelente producto! Sin palabras!, Lo mejor para el trabajo, gaming, día a día, el mejor producto de apple hasta la fecha!\n\n\n26\nI am extremely pleased with this early 2015, 13\" Macbook Pro! There is not one mark on the case, screen, keyboard - it is exactly like the brand-new one I purchased from Apple, 5 years ago!! The battery cycle count is only 21 - truly remarkable! It also came with a genuine MagSafe 2 Apple charger (I did check, and it is new and authentic). I am very happy with the purchase so far - thank you for selling such a quality item!\nI am extremely pleased with this early 2015, 13\" Macbook Pro! There is not one mark on the case, screen, keyboard - it is exactly like the brand-new one I purchased from Apple, 5 years ago! The battery cycle count is only 21 - truly remarkable! It also came with a genuine MagSafe 2 Apple charger (I did check, and it is new and authentic). I am very happy with the purchase so far - thank you for selling such a quality item!\n\n\n...\n...\n...\n\n\n12405\nThese were an early Christmas gift for my son who has everything he wants, he literally does not want or need anything, so I am always far stretched when trying to figure out what to give him for birthdays and Christmas.I was relieved as heck when he said he wanted a set of these controllers. I could not wait for Christmas because he had the new Super Mario Party game and we were having a few people come to the house to play it.The controllers arrived just in time for our Mario Party , but my son and I played to practice the new game the day ahead. I usually am triple-thumbed when it comes to controlling the controllers but these were surprisingly easy for me to use.Note:I discovered that using a certain color controller gives that user certain controls over the game that the other users do not have. For instance, when using a particular color controller, I had the ability to click the game back to the previous screen, thus making everyone groan loudly and wait for me to click us back to the game at hand. :)~~~~\nThese were an early Christmas gift for my son who has everything he wants, he literally does not want or need anything, so I am always far stretched when trying to figure out what to give him for birthdays and Christmas.I was relieved as heck when he said he wanted a set of these controllers. I could not wait for Christmas because he had the new Super Mario Party game and we were having a few people come to the house to play it.The controllers arrived just in time for our Mario Party , but my son and I played to practice the new game the day ahead. I usually am triple-thumbed when it comes to controlling the controllers but these were surprisingly easy for me to use.Note:I discovered that using a certain color controller gives that user certain controls over the game that the other users do not have. For instance, when using a particular color controller, I had the ability to click the game back to the previous screen, thus making everyone groan loudly and wait for me to click us back to the game at hand. :)~\n\n\n12408\nDid not purchase from Amazon as third party sellers were of course raising prices due to low stock and high demand. Managed to find these MSRP.I had purchased the Neon Blue/Red Switch and wanted these because I read they were opposite the set that came with the Neon Switch. This is true. Purchasing these will give you a complete set of Blue and Red. So if you want to throw them on your Switch and have matching colors, you can now!They are a little on the expensive side compared to a typical controller from other console makers, but I get it. They are individual controllers for Multiplayer games and are pretty sophisticated. The motion sending is great, the rumble feels nice, the colors really pop! And the batteries last a very long time. You will not have to charge these often!Speaking of charging you have two options: purchase a charging dock to charge them, or have them connected to your Switch. I never found keeping the extra pairs charged because you will probably just have them attached to the console anyway. I rotate them out so they are always charged. The fact that the battery life is ~20 hrs, you will have a hard time and rarely be low on battery. Plus having more joycons means more Multiplayer fun!!\nDid not purchase from Amazon as third party sellers were of course raising prices due to low stock and high demand. Managed to find these MSRP.I had purchased the Neon Blue/Red Switch and wanted these because I read they were opposite the set that came with the Neon Switch. This is true. Purchasing these will give you a complete set of Blue and Red. So if you want to throw them on your Switch and have matching colors, you can now!They are a little on the expensive side compared to a typical controller from other console makers, but I get it. They are individual controllers for Multiplayer games and are pretty sophisticated. The motion sending is great, the rumble feels nice, the colors really pop! And the batteries last a very long time. You will not have to charge these often!Speaking of charging you have two options: purchase a charging dock to charge them, or have them connected to your Switch. I never found keeping the extra pairs charged because you will probably just have them attached to the console anyway. I rotate them out so they are always charged. The fact that the battery life is ~20 hrs, you will have a hard time and rarely be low on battery. Plus having more joycons means more Multiplayer fun!\n\n\n12410\nI have been a Nintendo fan since the late 80's. I love their products for the most part. The Switch seems like a high water mark for innovation and functionality, with one caveat. The joy-con SUCKS!We have the blue and red joy-cons which came with the Switch. I bought the Pink & Green joy-cons so we could play Mario Party (which we LOVE). Initially, we had no problems with the controllers. I was not impressed with the range, but whatever. Also, the delay while playing wirelessly is pitiable. If you are playing any game which requires timed button presses (Mario Party, Smash Bro's, Hollow Knight...) you cannot depend on accuracy, which is downright silly. Latency is not an issue for any other system's controllers.Now, I have got a blue controller which will not hold a charge, a pink controller who is \"L\" button does not register and my green controller's \"X\" button sticks. Perhaps these issues are from maltreatment. I do have three kids. But I was their age when I got my NES and I abused the heck out of those controllers and they STILL work today!I want to love the Joy-cons. they are adorable. The ability to switch between two and one controller play is a great feat in system engineering. The Switch system itself is a GREAT system. To ask $70!!! for garbage controllers which have lower range and higher latency than any other controller is a poor business practice. You are better than this Nintendo.\nI have been a Nintendo fan since the late 80's. I love their products for the most part. The Switch seems like a high water mark for innovation and functionality, with one caveat. The joy-con SUCKS!We have the blue and red joy-cons which came with the Switch. I bought the Pink & Green joy-cons so we could play Mario Party (which we LOVE). Initially, we had no problems with the controllers. I was not impressed with the range, but whatever. Also, the delay while playing wirelessly is pitiable. If you are playing any game which requires timed button presses (Mario Party, Smash Bro's, Hollow Knight.) you cannot depend on accuracy, which is downright silly. Latency is not an issue for any other system's controllers.Now, I have got a blue controller which will not hold a charge, a pink controller who is \"L\" button does not register and my green controller's \"X\" button sticks. Perhaps these issues are from maltreatment. I do have three kids. But I was their age when I got my NES and I abused the heck out of those controllers and they STILL work today!I want to love the Joy-cons. they are adorable. The ability to switch between two and one controller play is a great feat in system engineering. The Switch system itself is a GREAT system. To ask $70! for garbage controllers which have lower range and higher latency than any other controller is a poor business practice. You are better than this Nintendo.\n\n\n12415\nThis is not so much a product review as a compliment, so here goes...Just wanted to give the Amazon delivery service a “Thank you”. I have had my Switch for almost 2 yrs and have logged many happy, sometimes frustrating hours on it. So last week when the Joy-Cons started gradually sticking I knew they needed replacing. The R stick was not actually “physically” sticking to the right, but was sending the message to the game to move right when I wanted to stand my ground. do not know if any of you have ever tried fighting Ice Lizalfos on a mountain top while Link keeps trying to creep off the cliff, but I would not recommend it. I would already searched to replace them, but due to the COVID pandemic Switch Joy-Cons are near impossible to get in regular grey here in Sacramento. EVERY store was wiped out. Even GameStop, Walmart, Best Buy and Fry’s could not provide via store OR online. Amazon said they could deliver, but not until August 1st... it was the best offer I could get. So when that beautiful little brown box showed up yesterday afternoon, July 28th, while I was actually playing Zelda BOTW no less, the feelings of relief that swept over me can only be understated. And just in time too. Yesterday, only an hour or so before delivery, the L stick was starting to stick to the right also. Whew!.... Thanks again, Amazon for that little extra “sumthin’” you always seem to provide.P.S. Oh, and the controllers were delivered, packaged, and function perfectly. The actual Nintendo Joy-Con box was untampered and had safety seals in tact - something I always look for, especially with electronics (and food, of course).\nThis is not so much a product review as a compliment, so here goes.Just wanted to give the Amazon delivery service a “Thank you”. I have had my Switch for almost 2 yrs and have logged many happy, sometimes frustrating hours on it. So last week when the Joy-Cons started gradually sticking I knew they needed replacing. The R stick was not actually “physically” sticking to the right, but was sending the message to the game to move right when I wanted to stand my ground. do not know if any of you have ever tried fighting Ice Lizalfos on a mountain top while Link keeps trying to creep off the cliff, but I would not recommend it. I would already searched to replace them, but due to the COVID pandemic Switch Joy-Cons are near impossible to get in regular grey here in Sacramento. EVERY store was wiped out. Even GameStop, Walmart, Best Buy and Fry’s could not provide via store OR online. Amazon said they could deliver, but not until August 1st. it was the best offer I could get. So when that beautiful little brown box showed up yesterday afternoon, July 28th, while I was actually playing Zelda BOTW no less, the feelings of relief that swept over me can only be understated. And just in time too. Yesterday, only an hour or so before delivery, the L stick was starting to stick to the right also. Whew!. Thanks again, Amazon for that little extra “sumthin’” you always seem to provide.P.S. Oh, and the controllers were delivered, packaged, and function perfectly. The actual Nintendo Joy-Con box was untampered and had safety seals in tact - something I always look for, especially with electronics (and food, of course).\n\n\n12418\nEdit: 2yrs later. Today is april 24th 2021 and let me say i am still disappointed. These worked but were the first to start drifting after about i dunno 1 month not bad but still upsetting for full price \"new\" joycons... both drift and still do till this day simply bc i have not sent them out to be fixed.1. Not new joy cons2. colors were swaped (did not even match what the actual box stated; (L) red (R) Blue)3. They are USEDso to start off the box of the controllers itself seemed to be slightly bent as if something heavier was placed on top. The first thing that i noticed was the colors were switched than advertised on the box (i do not mind that at all).Then i decided to check the controllers individually; both have black scratch marks as if being constantly put on and taken off of the console. With that said it already tells me they were used; now i did not pay ‘full’ price for something to be used, i initially did not buy them used. I could see small chips on the paint where they slide on and off of the console.Now they work, yes they seemed to work when i put them on the console; however, i have not actually played using them yet.I gave this 3 stars mainly for the fact that technically i did not get what i paid for. All in all i do not mind, as long as they work but it is upsetting to not get a good presentation.\nEdit: 2yrs later. Today is april 24th 2021 and let me say i am still disappointed. These worked but were the first to start drifting after about i dunno 1 month not bad but still upsetting for full price \"new\" joycons. both drift and still do till this day simply bc i have not sent them out to be fixed.1. Not new joy cons2. colors were swaped (did not even match what the actual box stated; (L) red (R) Blue)3. They are USEDso to start off the box of the controllers itself seemed to be slightly bent as if something heavier was placed on top. The first thing that i noticed was the colors were switched than advertised on the box (i do not mind that at all).Then i decided to check the controllers individually; both have black scratch marks as if being constantly put on and taken off of the console. With that said it already tells me they were used; now i did not pay ‘full’ price for something to be used, i initially did not buy them used. I could see small chips on the paint where they slide on and off of the console.Now they work, yes they seemed to work when i put them on the console; however, i have not actually played using them yet.I gave this 3 stars mainly for the fact that technically i did not get what i paid for. All in all i do not mind, as long as they work but it is upsetting to not get a good presentation.\n\n\n\n\n1113 rows × 2 columns"
  },
  {
    "objectID": "posts/2021-07-27-nlp_7_text_preprocessing_and_labelling_[part_1].html#step-7-filter-languages-english-only",
    "href": "posts/2021-07-27-nlp_7_text_preprocessing_and_labelling_[part_1].html#step-7-filter-languages-english-only",
    "title": "Text Processing & Labelling [Part1]",
    "section": "Step 7: Filter Languages (English only)",
    "text": "Step 7: Filter Languages (English only)\n\nnlp.add_pipe(LanguageDetector(), name='language_detector', last=True)\n\n\ndef detect_lang(text):\n    doc = nlp(text)\n    lang = doc._.language['language']\n    return lang\n\n\ndf[\"lang\"] = df[\"no_consecutive_punc\"].apply(detect_lang)\n\n\nnon_english_df = df[df.lang != \"en\"][[\"no_consecutive_punc\", \"lang\"]]\nprint(\"number of non english comments\", non_english_df.shape)\n\nnumber of non english comments (2559, 2)\n\n\n\ndf.to_csv(\"preprocessed.csv\")\n\n\nfiltered_df = df[df.lang == \"en\"]\n\n\nprint(\"Number of data before filter:\", len(df))\nprint(\"Number of data after filter:\", len(filtered_df))\n\nNumber of data before filter: 12416\nNumber of data after filter: 9857"
  },
  {
    "objectID": "posts/2021-07-27-nlp_7_text_preprocessing_and_labelling_[part_1].html#step-8-lower-case",
    "href": "posts/2021-07-27-nlp_7_text_preprocessing_and_labelling_[part_1].html#step-8-lower-case",
    "title": "Text Processing & Labelling [Part1]",
    "section": "Step 8: Lower case",
    "text": "Step 8: Lower case\n\ndf['lower_case'] = df[\"no_consecutive_punc\"].str.lower()\n\n\ndf.to_csv(\"preprocessed.csv\", index=False)"
  },
  {
    "objectID": "posts/2021-07-04-nlp_5_interactive_attention_networks_for_aspect_level_sentiment_classififcation.html",
    "href": "posts/2021-07-04-nlp_5_interactive_attention_networks_for_aspect_level_sentiment_classififcation.html",
    "title": "Interactive Attention Networks for Aspect-Level Sentiment Classification",
    "section": "",
    "text": "The full notebook is available here.\n\nIntroduction\nPrevious stuides have realized the importance of targets in aspect-based sentiment analysis. However, they all ignore the separate modeling for targets. In other word, they don’t have a separate model to learn the target text. In this paper, the author proposed an architecture which has 2 sub-networks used to model the both the contexts and the targets. They argued that targets and contexts can be modelled separately, but learned from their interaction.\n\nWhen “short” is collocated with “battery life”, the sentiment tends to be negative. But when “short” is used with “spoon” in the context “Short fat noodle spoon, relatively deep some curva”, the sentiment can be neu- tral. Then, the next problem is how to simultaneously model targets and contexts precisely. First, target and context can determine representations of each other. For example, when we see the target “picture quality”, context word “clear-cut” is naturally associated with the target. And it is vice versa - “picture quality” is first connected with “clear-cut”\n\nAlso, contexts and targets both includes many words. Different words may have different contributions to the final representation. Therefore, in this paper, the author created 2 attention mechanisms to capture the important information for both contexts and targets.\n\nfrom IPython.display import Image\nImage(filename='architecture.png')\n\n\n\n\n\n\n\n\nThe model is called interactive attention network (IAN). It is based on LSTM and attention mechanism.\nThe text input will be firstly converted to embeddings. Then they are feeded into LSTMs. After that, the authors averaged the hidden states of the context LSTM to get the inital representation of context (pool vector in the figure). They do the same for the target LSTM. Then they used the target pool vector in the context attention computation and vice versa. They argued that with this design, the target and context can influence the generation of their representations interactively. Lastly, they concatenate the target and context vector and feed it into the softmax layer to do the classification.\nExplain using Query, Key, Value: Regarding the target LSTM, in the figure 1 the pool vector is computed by averaging hidden states of the LSTM. That vector will play as the query vector. Each hidden state vectors represents both the key and value vectors. Then just calculate the attention score as the step below: - Step 1: Calculate the similarity score between the query vector and all the key vectors. - Step 2: Normalize the score using softmax. - Step 3: Calculate the final representation vector by weighted average the value vectors using the normalized scores.\n\n\nInstall and Import required packages\n\n%%capture\n!pip install pytorch-lightning\n!pip install torchmetrics\n\n\nimport os\nimport pickle\nfrom collections import Counter, OrderedDict\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Optional, Tuple, Union\nfrom urllib.request import urlretrieve\n\nimport numpy as np\nfrom tqdm import tqdm\n\nimport pytorch_lightning as pl\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchmetrics\nimport torchtext\nfrom pytorch_lightning import loggers as pl_loggers\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom torch.nn.utils.rnn import (pack_padded_sequence, pad_packed_sequence,\n                                pad_sequence)\nfrom torch.utils.data import DataLoader, Dataset, random_split\nfrom torchtext.data import get_tokenizer\nfrom torchtext.vocab import Vectors, Vocab\n\n# For repoducibility\npl.utilities.seed.seed_everything(seed=2401, workers=True)\n\nGlobal seed set to 2401\n\n\n2401\n\n\n\n\nDefine dataset, dataloader class and utility functions\n\nclass TqdmUpTo(tqdm):\n    \"\"\"From https://github.com/tqdm/tqdm/blob/master/examples/tqdm_wget.py\"\"\"\n\n    def update_to(self, blocks=1, bsize=1, tsize=None):\n        \"\"\"\n        Parameters\n        ----------\n        blocks: int, optional\n            Number of blocks transferred so far [default: 1].\n        bsize: int, optional\n            Size of each block (in tqdm units) [default: 1].\n        tsize: int, optional\n            Total size (in tqdm units). If [default: None] remains unchanged.\n        \"\"\"\n        if tsize is not None:\n            self.total = tsize  \n        self.update(blocks * bsize - self.n)  \n\nclass Tokenizer():\n    def __init__(self, tokenizer: Any, is_lower=True):\n        self.counter = Counter(['&lt;pad&gt;', '&lt;unk&gt;'])\n        self.tokenizer = tokenizer\n        self.vocab = self.update_vocab()\n        self.is_lower = is_lower\n\n    def update_vocab(self):\n        sorted_by_freq_tuples = sorted(self.counter.items(), key=lambda x: x[1], reverse=True)\n        ordered_dict = OrderedDict(sorted_by_freq_tuples)\n        self.vocab = torchtext.vocab.vocab(ordered_dict, min_freq=1)\n\n    def fit_on_texts(self, texts: List[str]):\n        \"\"\"\n        Updates internal vocabulary based on a list of texts.\n        \"\"\"\n        # lower and tokenize texts to sequences\n        for text in texts:\n            self.counter.update(self.tokenizer(text))\n        self.update_vocab()\n\n    def texts_to_sequences(self, texts: List[str], reverse: bool=False, tensor: bool=True) -&gt; List[List[int]]:\n        word2idx = self.vocab.get_stoi()\n        sequences = []\n        for text in texts:\n            if self.is_lower:\n                text = text.lower()\n            seq = [word2idx.get(word, word2idx['&lt;unk&gt;']) for word in self.tokenizer(text)]\n            if reverse:\n                seq = seq[::-1] \n            if tensor:\n                seq = torch.tensor(seq)\n            sequences.append(seq)\n        return sequences\n    \n    def text_to_sequence(self, text: str, reverse: bool=False, tensor: bool=True) -&gt; List[int]:\n        if self.is_lower:\n            text = text.lower()\n        word2idx = self.vocab.get_stoi()\n        seq = [word2idx.get(word, word2idx['&lt;unk&gt;']) for word in self.tokenizer(text)]\n        if reverse:\n            seq = seq[::-1]\n        if tensor:\n            seq = torch.tensor(seq)\n        return seq  \n\ndef download_url(url, filename, directory='.'):\n    \"\"\"Download a file from url to filename, with a progress bar.\"\"\"\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n    path = os.path.join(directory, filename)\n\n    with TqdmUpTo(unit=\"B\", unit_scale=True, unit_divisor=1024, miniters=1) as t:\n        urlretrieve(url, path, reporthook=t.update_to, data=None)  # nosec\n    return  path\n\ndef load_data_from(path: Union[str, Path]):\n    sentences = []\n    targets = []\n    sentiments = []\n    with open(path, 'r') as f:\n        lines = f.readlines()\n        for index in range(0, len(lines), 3):\n            text = lines[index].lower().strip()\n            target = lines[index+1].lower().strip()\n            text = text.replace('$t$', target)\n            sentences.append(text)\n            targets.append(target)\n            sentiments.append(int(lines[index+2].strip()))\n    return sentences, targets, sentiments\n\ndef _preprocess_data(data, tokenizer):\n    sentences, targets, sentiments = data\n    \n    # Create sentence sequences and aspects sequences\n    sequences = tokenizer.texts_to_sequences(sentences)\n    target_seqs = tokenizer.texts_to_sequences(targets)\n    sentiments = torch.tensor(sentiments) + 1\n\n    # pad sequences\n    seq_lens = torch.tensor([len(seq) for seq in sequences])\n    target_lens = torch.tensor([len(target_seq) for target_seq in target_seqs])\n\n    sequences = pad_sequence(sequences, batch_first=True)\n    target_seqs = pad_sequence(target_seqs, batch_first=True)\n\n    assert len(sequences) == len(sentiments)\n    assert len(sequences) == len(target_seqs)\n\n    all_data = []\n    for i in range(len(sentiments)):\n        sample = {\n            'context_seq': sequences[i],\n            'context_len': seq_lens[i],\n            'target_seq': target_seqs[i],\n            'target_len': target_lens[i],\n            'sentiment': sentiments[i]\n        }\n        all_data.append(sample)\n    return all_data\n\ndef build_vocab(tokenizer, data):\n    sentences = data[0]\n    tokenizer.fit_on_texts(sentences)\n\ndef load_pretrained_word_embeddings(options: Dict[str, Any]):\n    return torchtext.vocab.GloVe(options['name'], options['dim'])\n\ndef create_embedding_matrix(word_embeddings: Vectors, vocab: Vocab, path: Union[str, Path]):\n    if os.path.exists(path):\n        print(f'loading embedding matrix from {path}')\n        embedding_matrix = pickle.load(open(path, 'rb'))\n    else:\n        embedding_matrix = torch.zeros((len(vocab), word_embeddings.dim), \n                                       dtype=torch.float)\n\n        # words that are not availabel in the pretrained word embeddings will be zeros\n        for word, index in vocab.get_stoi().items():\n            embedding_matrix[index] = word_embeddings.get_vecs_by_tokens(word)\n\n        # save embedding matrix\n        pickle.dump(embedding_matrix, open(path, 'wb'))\n    return embedding_matrix\n\n\nclass SemEvalDataset(Dataset):\n    def __init__(self, data):\n        self.data = data\n\n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        return self.data[idx]\n\n\n# Restaurant\nRES_TRAIN_DS_URL = 'https://raw.githubusercontent.com/songyouwei/ABSA-PyTorch/master/datasets/semeval14/Restaurants_Train.xml.seg'\nRES_TEST_DS_URL = 'https://raw.githubusercontent.com/songyouwei/ABSA-PyTorch/master/datasets/semeval14/Restaurants_Test_Gold.xml.seg'\n\n# Laptop\nLAP_TRAIN_DS_URL = 'https://raw.githubusercontent.com/songyouwei/ABSA-PyTorch/master/datasets/semeval14/Laptops_Train.xml.seg'\nLAP_TEST_DS_URL = 'https://raw.githubusercontent.com/songyouwei/ABSA-PyTorch/master/datasets/semeval14/Laptops_Test_Gold.xml.seg'\n\nclass SemEval2014(pl.LightningDataModule):\n    def __init__(self, tokenizer, opts):\n        super().__init__()\n        self.tokenizer = tokenizer\n        self.batch_size = opts['batch_size']\n        self.num_workers = opts['num_workers']\n        self.on_gpu = opts['on_gpu']\n\n        self.mapping = {\"negative\": 0, \"neutral\": 1, \"positive\": 2} \n        self.inverse_mapping = {v: k for k, v in enumerate(self.mapping)} \n\n    def prepare_data(self) -&gt; None:\n        self.train_path = 'download/SemEval2014/train.xml'\n        self.test_path = 'download/SemEval2014/test.xml'\n        \n        if not os.path.exists(train_path):\n            print(\"Downloading train dataset\")\n            self.train_path = download_url(RES_TRAIN_DS_URL, 'train.xml', 'download/SemEval2014')\n\n        if not os.path.exists(test_path):\n            print(\"Downloading test dataset\")\n            self.test_path = download_url(RES_TEST_DS_URL, 'test.xml', 'download/SemEval2014')\n        \n    def setup(self, stage: str = None) -&gt; None:\n        if stage == 'fit' or stage is None:\n            # Load data from files\n            train_data = load_data_from(self.train_path)\n            valid_data = load_data_from(self.test_path)\n            self.train_data = _preprocess_data(train_data, self.tokenizer)\n            self.val_data = _preprocess_data(valid_data, self.tokenizer)\n\n        elif stage == 'test' or stage is None:\n            test_data = load_data_from(self.test_path)\n            self.test_data = _preprocess_data(test_data, self.tokenizer)\n            \n    def train_dataloader(self):\n        # Create Dataset object\n        train_ds = SemEvalDataset(self.train_data)\n        # Create Dataloader\n        return DataLoader(\n            train_ds,\n            shuffle=True,\n            batch_size=self.batch_size,\n            num_workers=self.num_workers,\n            pin_memory=self.on_gpu,\n        ) \n\n    def val_dataloader(self):\n        val_ds = SemEvalDataset(self.val_data)\n        return DataLoader(\n            val_ds,\n            shuffle=False,\n            batch_size=self.batch_size,\n            num_workers=self.num_workers,\n            pin_memory=self.on_gpu,\n        ) \n\n    def test_dataloader(self):\n        test_ds = SemEvalDataset(self.test_data)\n        return DataLoader(\n            test_ds,\n            shuffle=False,\n            batch_size=self.batch_size,\n            num_workers=self.num_workers,\n            pin_memory=self.on_gpu,\n        ) \n\n    def __repr__(self):\n        basic = f\"SemEval2014 Dataset\\nNum classes: {len(self.mapping)}\\nMapping: {self.mapping}\\n\"\n        if self.train_data is None and self.val_data is None and self.test_data is None:\n            return basic\n        batch = next(iter(self.train_dataloader()))\n        cols = ['context_seq', 'context_len', 'target_seq', 'target_len', 'sentiment']\n        context_seqs, context_lens, target_seqs, target_lens, sentiments = [batch[col] for col in cols]\n        data = (\n            f\"Train/val/test sizes: {len(self.train_data)}, {len(self.val_data)}, {len(self.test_data)}\\n\"\n            f\"Batch context_seqs stats: {(context_seqs.shape, context_seqs.dtype)}\\n\"\n            f\"Batch context_lens stats: {(context_lens.shape, context_lens.dtype)}\\n\"\n            f\"Batch target_seqs stats: {(target_seqs.shape, target_seqs.dtype)}\\n\"\n            f\"Batch target_lens stats: {(target_lens.shape, target_lens.dtype)}\\n\"\n            f\"Batch sentiments stats: {(sentiments.shape, sentiments.dtype)}\\n\"\n        )\n        return basic + data\n\n\n\nImplementation\n\nclass Attention(nn.Module):\n    def __init__(self, hidden_size):\n        super(Attention, self).__init__()\n        self.linear = nn.Linear(hidden_size, hidden_size)\n\n    def forward(self, query, key, value, max_seq_len, seq_lens, device):\n        # Calculate similarity between query and key vectors\n        score = torch.tanh(torch.matmul(\n            self.linear(key), query.transpose(-2,-1))).squeeze(-1) # BxL\n\n        # Mask out padding score\n        att_mask = torch.arange(max_seq_len, device=device)[None,:] &lt; seq_lens[:, None]\n        score = score.masked_fill(att_mask == False, float('-inf'))\n        softmax_score = F.softmax(score, dim=-1).unsqueeze(2) #BxLx1\n        out = torch.matmul(value.transpose(-2,-1), softmax_score).squeeze() #BxH\n        return out\n\n\nclass IAN(pl.LightningModule):\n    def __init__(self, embedding_matrix, hidden_size, num_layers=1, \n                 num_classes=3, batch_first=True, lr=1e-3, dropout=0, l2reg=0.0):\n        super().__init__()\n        embedding_dim = embedding_matrix.shape[1]\n        self.batch_first = batch_first\n        self.lr = lr\n        self.l2reg = l2reg\n        # Define architecture components\n        self.embedding = nn.Embedding.from_pretrained(embedding_matrix)\n        self.target_lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first=batch_first, dropout=dropout)\n        self.context_lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first=batch_first, dropout=dropout)\n        self.context_attn = Attention(hidden_size)\n        self.target_attn = Attention(hidden_size)\n        self.linear = nn.Linear(hidden_size*2, num_classes)\n\n        # Define metrics\n        self.train_acc = torchmetrics.Accuracy() \n        self.val_acc = torchmetrics.Accuracy()\n        self.test_acc = torchmetrics.Accuracy()\n\n        # Initialize layer parameters\n        # for layer in [self.context_lstm, self.target_lstm, \n        #               self.context_attention, self.target_attention, self.linear]:\n        #     nn.init.uniform_(layer.weight, a=-0.1, b=0.1)\n\n    def configure_optimizers(self):\n        optim = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.l2reg)\n        return optim\n\n    def forward(self, input):\n        cols = [\"context_seq\", \"context_len\", \"target_seq\", \"target_len\"]\n        padded_context_seqs, context_lens, padded_target_seqs, target_lens = [input[col] for col in cols]\n        padded_context_embeddings = self.embedding(padded_context_seqs)\n        padded_target_embeddings = self.embedding(padded_target_seqs)\n        \n        context_seqs_pack = pack_padded_sequence(padded_context_embeddings, context_lens.cpu(), \n                                                 batch_first=self.batch_first, enforce_sorted=False)\n        target_seqs_pack = pack_padded_sequence(padded_target_embeddings, target_lens.cpu(),\n                                                 batch_first=self.batch_first, enforce_sorted=False)\n\n        H_context, _ = self.context_lstm(context_seqs_pack)\n        H_target, _ = self.target_lstm(target_seqs_pack)\n\n        # Unpack to get the full hidden states\n        padded_H_context, _ = pad_packed_sequence(H_context, batch_first=self.batch_first) # BxLxH\n        padded_H_target, _ = pad_packed_sequence(H_target, batch_first=self.batch_first) # BxLxH\n\n        # Compute the initial representation for target and context\n        c_avg = torch.mean(padded_H_context, dim=1, keepdim=True) #Bx1xH\n        t_avg = torch.mean(padded_H_target, dim=1, keepdim=True) #Bx1xH\n\n        c_max_seq_len = torch.max(context_lens)\n        final_c = self.context_attn(t_avg, padded_H_context, padded_H_context, \n                                         c_max_seq_len, context_lens, self.device)\n        \n        t_max_seq_len = torch.max(target_lens)\n        inal_t = self.target_attn(c_avg, padded_H_target, padded_H_target, \n                                        t_max_seq_len, target_lens, self.device)\n        \n        final_vector = torch.cat([final_t, final_c], dim=-1) # Bx2H\n        out = self.linear(final_vector)\n        logits = torch.tanh(out)\n        return logits\n\n    def training_step(self, batch, batch_idx):\n        sentiments = batch['sentiment']\n        logits = self.forward(batch)\n        loss = F.cross_entropy(logits, sentiments)\n        scores = F.softmax(logits, dim=-1)\n        self.train_acc(scores, sentiments)\n        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n        self.log('train_acc', self.train_acc, on_step=False, on_epoch=True, \n                 prog_bar=True, logger=True)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        sentiments = batch['sentiment']\n        logits = self.forward(batch)\n        loss = F.cross_entropy(logits, sentiments)\n        scores = F.softmax(logits, dim=-1)\n        self.val_acc(scores, sentiments)\n        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n        self.log('val_acc', self.val_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n\n    def test_step(self, batch, batch_idx):\n        sentiments = batch['sentiment']\n        logits = self.forward(batch)\n        scores = F.softmax(logits, dim=-1)\n        self.test_acc(scores, sentiments)\n        self.log('test_acc', self.test_acc, on_step=False, on_epoch=True, logger=True)\n        \n\n#Training\n\nprocessed_train_data = _preprocess_data(train_data, tokenizer)\n\n\ntrain_path = download_url(RES_TRAIN_DS_URL, 'train.xml', 'download/SemEval2014')\ntest_path = download_url(RES_TEST_DS_URL, 'test.xml', 'download/SemEval2014')\n\ntrain_data = load_data_from(train_path)\ntest_data = load_data_from(test_path)\n\nall_sentences = train_data[0] + test_data[0] \ntokenizer = Tokenizer(get_tokenizer(\"basic_english\"))\nbuild_vocab(tokenizer, [all_sentences])\n\n384kB [00:00, 1.71MB/s]                            \n120kB [00:00, 626kB/s]                             \n\n\n\nword_embeddings = load_pretrained_word_embeddings({\"name\": \"42B\", \"dim\": 300})\n\n.vector_cache/glove.42B.300d.zip: 1.88GB [05:53, 5.31MB/s]                            \n100%|█████████▉| 1916797/1917494 [04:10&lt;00:00, 8178.84it/s]\n\n\n\ntrain_path = download_url(RES_TRAIN_DS_URL, 'train.xml', 'download/SemEval2014')\ntest_path = download_url(RES_TEST_DS_URL, 'test.xml', 'download/SemEval2014')\n\ntrain_data = load_data_from(train_path)\ntest_data = load_data_from(test_path)\n\nall_sentences = train_data[0] + test_data[0] \ntokenizer = Tokenizer(get_tokenizer(\"basic_english\"))\nbuild_vocab(tokenizer, [all_sentences])\n\noptions = {\n    \"on_gpu\": True,\n    \"batch_size\": 16,\n    \"num_workers\": 2\n}\ndatamodule = SemEval2014(tokenizer, options)\nembedding_matrix = create_embedding_matrix(word_embeddings, tokenizer.vocab, \"embedding_matrix.dat\")\n\n384kB [00:00, 7.09MB/s]\n120kB [00:00, 2.81MB/s]\n\n\nloading embedding matrix from embedding_matrix.dat\n\n\n\ntorch.autograd.set_detect_anomaly(True)\ncheckpoint_callback = ModelCheckpoint(\n    monitor='val_acc', # save the model with the best validation accuracy\n    dirpath='checkpoints',\n    mode='max',\n)\n\ntb_logger = pl_loggers.TensorBoardLogger('logs/') # create logger for tensorboard\n\n# Set hyper-parameters\nlr = 1e-3 \nhidden_size = 300\naspect_embedding_dim = 300\nnum_epochs = 30\nl2reg = 1e-5\ndropout = 0.0\n\ntrainer = pl.Trainer(gpus=1, max_epochs=num_epochs, logger=tb_logger, callbacks=[checkpoint_callback], deterministic=True)\n# trainer = pl.Trainer(fast_dev_run=True, gpus=1) #Debug \n# trainer = pl.Trainer(overfit_batches=0.025, max_epochs=num_epochs, gpus=1) #Debug\nmodel = IAN(embedding_matrix=embedding_matrix, hidden_size=hidden_size, lr=lr, l2reg=l2reg, dropout=dropout)\ntrainer.fit(model, datamodule)\n\nGPU available: True, used: True\nTPU available: False, using: 0 TPU cores\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\n  | Name         | Type      | Params\n-------------------------------------------\n0 | embedding    | Embedding | 1.4 M \n1 | target_lstm  | LSTM      | 722 K \n2 | context_lstm | LSTM      | 722 K \n3 | context_attn | Attention | 90.3 K\n4 | target_attn  | Attention | 90.3 K\n5 | linear       | Linear    | 1.8 K \n6 | train_acc    | Accuracy  | 0     \n7 | val_acc      | Accuracy  | 0     \n8 | test_acc     | Accuracy  | 0     \n-------------------------------------------\n1.6 M     Trainable params\n1.4 M     Non-trainable params\n3.0 M     Total params\n11.921    Total estimated model params size (MB)\n\n\n\n\n\nGlobal seed set to 2401\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntrainer.test(ckpt_path=checkpoint_callback.best_model_path, test_dataloaders=datamodule.test_dataloader())\n\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\n\n\n\n\n\n--------------------------------------------------------------------------------\nDATALOADER:0 TEST RESULTS\n{'test_acc': 0.7866071462631226}\n--------------------------------------------------------------------------------\n\n\n[{'test_acc': 0.7866071462631226}]\n\n\n\n\nDiscussion\nOur result:\n\n\n\nDataset\nRestaurants\n\n\n\n\nIAN\n0.786\n\n\n\nPaper result:\n\n\n\nDataset\nRestaurants\nLaptops\n\n\n\n\nNo-target\n0.772\n0.708\n\n\nNo-interaction\n0.769\n0.706\n\n\nTarget2Content\n0.775\n0.712\n\n\nIAN\n0.786\n0.721\n\n\n\nFrom the two table above, we can see that our training get the same accuracy value with the paper.\nAnalysis:\nThe author analyzed the IAN model effectiveness by comparing it with 3 other types of models. All the models are based on LSTM and attention mechanism. The No-target model does not model the representation of the target. The second model, No-interaction, used 2 LSTM networks to model the representations of target and context via their own local atttentions, but without interaction. Next, the Target2Content model also employs 2 LSTM networks to learn target and context representation, but only uses the pool target vector for the context attention computation. The difference between this model and the IAN is the IAN also use the pool context vector in target attetion computation.\n\nThe results verify that target should be separately modeled and target representations can make contribution to judging the sentiment polarity of a target.\n\nThe improvements on Restaurant category is much less than those on Laptop category. The author explained that by pointing out that the Restaurant dataset has 9% 1-word target more than the Laptop one. In other words, the Laptop dataset has more multi-words targets. In IAN, the targets are modeled by LSTM networks and interactive attentions. LSTM networks and interactive attention are more effective on modelling long targets than short ones.\nYou can read more about the case study in which the author analyzes the attention score when doing inference here.\n\n\nLesson\n\nPass device in forward function instead of __init__\nWhen masking, create a mask matrix and times with the matrix we want to mask. By doing that, we can avoid modifying the tensor in-place error. We can also use the function mask_fill with ‘underscore’.\nWhen the training model is slow, check the number of model parameters!\nWhen using functions that requires the dim, we should set it explicitly to avoid bugs in our code. For example, in this implementation, using squeeze() function after calculating the similariry score between query and key vectors has error when the sequence length of key is 1.\n\n\n\nSuggestion for Readers:\n\nYou can try a larger word embeddings to see whether we can improve the metrics.\nTraining on the Laptop data\nHave fun :)"
  },
  {
    "objectID": "posts/2025-01-14_XV6.html",
    "href": "posts/2025-01-14_XV6.html",
    "title": "XV6 Series: MIT Lab4 2024",
    "section": "",
    "text": "Which registers contain arguments to functions? For example, which register holds 13 in main’s call to printf?\n\n\nIn RISC, a0-a7 are used to store function’s arguments. Specifically, for the printf, register a2 holds the value 13.\nvoid main(void) {\n1c: 1141                    add sp,sp,-16\n1e: e406                    sd  ra,8(sp)\n20: e022                    sd  s0,0(sp)\n22: 0800                    add s0,sp,16\nprintf(\"%d %d\\n\", f(8)+1, 13);\n24: 4635                    li  a2,13\n26: 45b1                    li  a1,12\n28: 00001517            auipc   a0,0x1\n2c: 84850513            add a0,a0,-1976 # 870 &lt;malloc+0x100&gt;\n30: 68c000ef            jal 6bc &lt;printf&gt;\nexit(0);\n34: 4501                    li  a0,0\n36: 26e000ef            jal 2a4 &lt;exit&gt;\n\nint f(int x) {\n   e:   1141                    add sp,sp,-16\n  10:   e422                    sd  s0,8(sp)\n  12:   0800                    add s0,sp,16\n  return g(x);\n}\n\n\nWhere is the call to function f in the assembly code for main? Where is the call to g? (Hint: the compiler may inline functions.)\n\n\nFrom the code above, we can see that the calls to function f and g are optimized in main. That means the output of the function calls are computed in compiled time. You can see that the register a1 holds the result of the f(8) + 1.\n\n\nAt what address is the function printf located?\n\n\nFrom the code above, we can see that the printf function is located at 0x6bc.\n\n\nWhat value is in the register ra just after the jalr to printf in main?\n\n\nNotes: jal(jump and link): jump to the address and save the address of the next instruction in the ra register.\nBy this definition, then the register ra will store the address of the next instruction, which is 0x34 in this case.\n\n\nRun the following code.\n\n\nunsigned int i = 0x00646c72;\nprintf(\"H%x Wo%s\", 57616, (char *) &i);\n\nWhat is the output? Here’s an ASCII table that maps bytes to characters.\n\n\nThe output depends on that fact that the RISC-V is little-endian. If the RISC-V were instead big-endian what would you set i to in order to yield the same output? Would you need to change 57616 to a different value?\n\nIn little-endian system, the least significant byte is stored at the lowest address. That means the value i = 0x00646c72 is stored as 72 6c 64 00 in memory. In which,\n\n0x72 is r\n0x6c is l\n0x64 is d\n0x00 is \\0\n\nAlso, in printf, %x is used to print the hexadecimal format.\nTherefore, the output is: He110 World\nIf RISC-V is big-endian, then the value of i should be 0x726c6400 and the value of 57616.\n\nIn the following code, what is going to be printed after ‘y=’? (note: the answer is not a specific value.) Why does this happen?\n\nprintf(\"x=%d y=%d\", 3);\nSince the printf function requires two arguments for 2 format specifiers, but only one argument is provided, the output will be undefined or the program will be crashed."
  },
  {
    "objectID": "posts/2025-01-14_XV6.html#risc-v-assembly",
    "href": "posts/2025-01-14_XV6.html#risc-v-assembly",
    "title": "XV6 Series: MIT Lab4 2024",
    "section": "",
    "text": "Which registers contain arguments to functions? For example, which register holds 13 in main’s call to printf?\n\n\nIn RISC, a0-a7 are used to store function’s arguments. Specifically, for the printf, register a2 holds the value 13.\nvoid main(void) {\n1c: 1141                    add sp,sp,-16\n1e: e406                    sd  ra,8(sp)\n20: e022                    sd  s0,0(sp)\n22: 0800                    add s0,sp,16\nprintf(\"%d %d\\n\", f(8)+1, 13);\n24: 4635                    li  a2,13\n26: 45b1                    li  a1,12\n28: 00001517            auipc   a0,0x1\n2c: 84850513            add a0,a0,-1976 # 870 &lt;malloc+0x100&gt;\n30: 68c000ef            jal 6bc &lt;printf&gt;\nexit(0);\n34: 4501                    li  a0,0\n36: 26e000ef            jal 2a4 &lt;exit&gt;\n\nint f(int x) {\n   e:   1141                    add sp,sp,-16\n  10:   e422                    sd  s0,8(sp)\n  12:   0800                    add s0,sp,16\n  return g(x);\n}\n\n\nWhere is the call to function f in the assembly code for main? Where is the call to g? (Hint: the compiler may inline functions.)\n\n\nFrom the code above, we can see that the calls to function f and g are optimized in main. That means the output of the function calls are computed in compiled time. You can see that the register a1 holds the result of the f(8) + 1.\n\n\nAt what address is the function printf located?\n\n\nFrom the code above, we can see that the printf function is located at 0x6bc.\n\n\nWhat value is in the register ra just after the jalr to printf in main?\n\n\nNotes: jal(jump and link): jump to the address and save the address of the next instruction in the ra register.\nBy this definition, then the register ra will store the address of the next instruction, which is 0x34 in this case.\n\n\nRun the following code.\n\n\nunsigned int i = 0x00646c72;\nprintf(\"H%x Wo%s\", 57616, (char *) &i);\n\nWhat is the output? Here’s an ASCII table that maps bytes to characters.\n\n\nThe output depends on that fact that the RISC-V is little-endian. If the RISC-V were instead big-endian what would you set i to in order to yield the same output? Would you need to change 57616 to a different value?\n\nIn little-endian system, the least significant byte is stored at the lowest address. That means the value i = 0x00646c72 is stored as 72 6c 64 00 in memory. In which,\n\n0x72 is r\n0x6c is l\n0x64 is d\n0x00 is \\0\n\nAlso, in printf, %x is used to print the hexadecimal format.\nTherefore, the output is: He110 World\nIf RISC-V is big-endian, then the value of i should be 0x726c6400 and the value of 57616.\n\nIn the following code, what is going to be printed after ‘y=’? (note: the answer is not a specific value.) Why does this happen?\n\nprintf(\"x=%d y=%d\", 3);\nSince the printf function requires two arguments for 2 format specifiers, but only one argument is provided, the output will be undefined or the program will be crashed."
  },
  {
    "objectID": "posts/2021-06-20-nlp_2_effective_lstms_for_target_dependent_sentiment_classification [part 2].html",
    "href": "posts/2021-06-20-nlp_2_effective_lstms_for_target_dependent_sentiment_classification [part 2].html",
    "title": "Effective LSTMs for Target Dependent Sentiment Classification [Part 2]",
    "section": "",
    "text": "The full notebook is available here."
  },
  {
    "objectID": "posts/2021-06-20-nlp_2_effective_lstms_for_target_dependent_sentiment_classification [part 2].html#td-lstm",
    "href": "posts/2021-06-20-nlp_2_effective_lstms_for_target_dependent_sentiment_classification [part 2].html#td-lstm",
    "title": "Effective LSTMs for Target Dependent Sentiment Classification [Part 2]",
    "section": "TD-LSTM",
    "text": "TD-LSTM\nThe architecture has a embedding layer, 2 LSTM layers and 1 dense layer.\n\nEmbedding layer:\n\nConvert the sequences to word vectors using pre-trained Glove word embeddings\n\n2 LSTM layers:\n\nOne layer is used for the [left context + target] sequences, and one is used for the [target + right context] sequences.\n\nDense layer:\n\nWe concate the 2 hidden states from the LSTM layers and feed it into the Dense layer.\n\nTo take into account of the target information, we make a slight modification on the \\(LSTM\\) model. The basic idea is to model the preceding and following contexts surrounding the target string, so that contexts in both directions could be used as feature representations for sentiment classification. We believe that capturing such target-dependent context information could improve the accuracy of target-dependent sentiment classification.\nSpecifically, we use two \\(LSTM\\) neural networks, a left one \\(LSTM_L\\) and a right one \\(LSTM_R\\), to model the preceding and following contexts respectively. An illustration of the model is shown in Figure 1. The input of \\(LSTM_L\\) is the preceding contexts plus target string, and the input of \\(LSTM_R\\) is the following contexts plus target string. We run \\(LSTM_L\\) from left to right, and run \\(LSTM_R\\) from right to left. We favor this strategy as we believe that regarding target string as the last unit could better utilize the semantics of target string when using the composed representation for sentiment classification. Afterwards, we concatenate the last hidden vectors of \\(LSTM_L\\) and \\(LSTM_R\\) , and feed them to a sof tmax layer to classify the sentiment polarity label. One could also try averaging or summing the last hidden vectors of \\(LSTM_L\\) and \\(LSTM_R\\) as alternatives.\n\n\nfrom IPython.display import Image\nImage(filename='images/figure_1_image.png')\n\n\n\n\n\n\n\n\n\nclass TDLSTM(pl.LightningModule):\n    def __init__(self, embeddings, hidden_size, num_layers=1, num_classes=3, batch_first=True, lr=1e-3, dropout=0, l2reg=0.01):\n        super().__init__()\n        embedding_dim = embeddings.shape[1]\n        self.embedding = nn.Embedding.from_pretrained(embeddings) # load pre-trained word embeddings\n        self.l_lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first=batch_first, dropout=dropout)\n        self.r_lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first=batch_first, dropout=dropout)\n        self.linear = nn.Linear(hidden_size*2, num_classes)\n\n        self.lr = lr\n        self.l2reg = l2reg\n        # Define metrics \n        self.train_acc = torchmetrics.Accuracy() \n        self.val_acc = torchmetrics.Accuracy()\n        self.val_f1 = torchmetrics.F1(num_classes=3, average='macro')\n        self.test_acc = torchmetrics.Accuracy()\n        self.test_f1 = torchmetrics.F1(num_classes=3, average='macro')\n\n    def configure_optimizers(self):\n        optim = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.l2reg)\n        return optim\n\n    def forward(self, data):\n        cols = ['padded_l_sequence', 'padded_r_sequence', 'l_len', 'r_len']\n        padded_l_seqs, padded_r_seqs, l_lens, r_lens = [data[col] for col in cols]\n        # convert seq to word vector\n        padded_l_embeds = self.embedding(padded_l_seqs)\n        padded_r_embeds = self.embedding(padded_r_seqs)\n        # pack the embeds  \n        padded_l_seq_pack = pack_padded_sequence(padded_l_embeds, l_lens.cpu(), batch_first=True, enforce_sorted=False)\n        padded_r_seq_pack = pack_padded_sequence(padded_r_embeds, r_lens.cpu(), batch_first=True, enforce_sorted=False)\n        _, (h_l, _) = self.l_lstm(padded_l_seq_pack)  \n        _, (h_r, _) = self.r_lstm(padded_r_seq_pack)  \n        h = torch.cat((h_l[-1], h_r[-1]), -1) # B x 2H\n        out = self.linear(h)\n        return out\n\n    def training_step(self, batch, batch_idx): # pylint: disable=unused-argument\n        sentiments = batch['sentiment']\n        logits = self.forward(batch)\n        loss = F.cross_entropy(logits, sentiments)\n        scores = F.softmax(logits, dim=-1)\n        self.train_acc(scores, sentiments)\n        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n        self.log('train_acc', self.train_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        return loss\n    \n    def validation_step(self, batch, batch_idx):  # pylint: disable=unused-argument\n        sentiments = batch['sentiment']\n        logits = self.forward(batch)\n        loss = F.cross_entropy(logits, sentiments)\n        scores = F.softmax(logits, dim=-1)\n        self.val_acc(scores, sentiments)\n        self.val_f1(scores, sentiments)\n        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n        self.log('val_acc', self.val_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        self.log('val_f1', self.val_f1, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n\n    def test_step(self, batch, batch_idx):  # pylint: disable=unused-argument\n        sentiments = batch['sentiment']\n        logits = self.forward(batch)\n        scores = F.softmax(logits, dim=-1)\n        self.test_acc(scores, sentiments)\n        self.test_f1(scores, sentiments)\n        self.log('test_acc', self.test_acc, on_step=False, on_epoch=True, logger=True)\n        self.log('test_f1', self.test_f1, on_step=False, on_epoch=True, logger=True)"
  },
  {
    "objectID": "posts/2021-06-20-nlp_2_effective_lstms_for_target_dependent_sentiment_classification [part 2].html#tc-lstm",
    "href": "posts/2021-06-20-nlp_2_effective_lstms_for_target_dependent_sentiment_classification [part 2].html#tc-lstm",
    "title": "Effective LSTMs for Target Dependent Sentiment Classification [Part 2]",
    "section": "TC-LSTM",
    "text": "TC-LSTM\nThe architecture has a embedding layer, 2 LSTM layers and 1 dense layer.\n\nEmbedding layer:\n\nConvert the sequences to word vectors using pre-trained Glove word embeddings\n\n2 LSTM layers:\n\nOne layer is used for the [left context + target] sequences, and one is used for the [target + right context] sequences.\n\nDense layer:\n\nWe concate the 2 hidden states from the LSTM layers and feed it into the Dense layer.\nThe only difference compared to the TD-LSTM is its input. The input of TC-LSTM is a concatenation of the input word vector and the \\(v_{target}\\) vector. We calculate the \\(v_{target}\\) vector by averaging the all the target word vector(s) of the sample. For example, if the target in the sentence is jimmy carter, we tokenizer the target to jimmy and carter then convert them to word vector. After that, we average those vector to get the \\(v_{target}\\) vector.\n\nAn overview of TC-LSTM is illustrated in Figure 2. The model extends TD-LSTM by incorporating an target con- nection component, which explicitly utilizes the connections between target word and each context word when composing the representation of a sentence.\nThe input of TC-LSTM is a sentence consist- ing of n words { \\(w_1,w_2,...w_n\\) } and a target string t occurs in the sentence. We represent target t as { \\(w_{l+1}, w_{l+2}...w_{r−1}\\) } because a target could be a word sequence of variable length, such as “google” or “harry potter”. When processing a sentence, we split it into three components: target words, preceding context words and following context words. We obtain target vector \\(v_{target}\\) by averaging the vectors of words it contains, which has been proven to be simple and effective in representing named entities (Socher et al., 2013a; Sun et al., 2015). When compute the hidden vectors of preceding and following context words, we use two separate long short-term memory models, which are similar with the strategy used in TD-LSTM. The difference is that in TC-LSTM the input at each position is the concatenation of word embedding and target vector vtarget, while in TD-LSTM the input at each position only includes only the embedding of current word.\n\n\nThe input data has an additional element which is the \\(v_{target}\\) vector. Let create a new Dataset class for TC-LSTM.\n\n\nfrom IPython.display import Image\nImage(filename='images/figure_2_image.png')\n\n\n\n\n\n\n\n\n\nclass TCLSTM(pl.LightningModule):\n    def __init__(self, embeddings, hidden_size, num_layers=1, num_classes=3, batch_first=True, lr=1e-3, dropout=0, l2reg=0.01):\n        super().__init__()\n        embedding_dim = embeddings.shape[1]\n        self.embedding = nn.Embedding.from_pretrained(embeddings) # load pre-trained word embeddings\n        \n        self.l_lstm = nn.LSTM(embedding_dim*2, hidden_size, num_layers, batch_first=batch_first, dropout=dropout)\n        self.r_lstm = nn.LSTM(embedding_dim*2, hidden_size, num_layers, batch_first=batch_first, dropout=dropout)\n        self.linear = nn.Linear(hidden_size*2, num_classes)\n\n        self.lr = lr\n        self.l2reg = l2reg\n        \n        # log hyperparameters\n        # self.save_hyperparameters()\n\n        # Define metrics \n        self.train_acc = torchmetrics.Accuracy() \n        self.val_acc = torchmetrics.Accuracy()\n        self.val_f1 = torchmetrics.F1(num_classes=3, average='macro')\n        self.test_acc = torchmetrics.Accuracy()\n        self.test_f1 = torchmetrics.F1(num_classes=3, average='macro')\n\n    def configure_optimizers(self):\n        optim = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.l2reg)\n        return optim\n\n    def forward(self, data):\n        cols = ['padded_l_sequence', 'padded_r_sequence', 'l_len', 'r_len', 'padded_target_sequence']\n        padded_l_seqs, padded_r_seqs, l_lens, r_lens, padded_target_seqs = [data[col] for col in cols]\n        # convert seq to word vector\n        padded_l_embeds = self.embedding(padded_l_seqs)\n        padded_r_embeds = self.embedding(padded_r_seqs)\n        padded_target_embeds = self.embedding(padded_target_seqs) # BxLxH\n\n        # create v_target vector and concat it to both l_embeds and r_embeds \n        v_targets = torch.mean(padded_target_embeds, dim=1, keepdims=True)\n        padded_l_embeds = torch.cat((padded_l_embeds, v_targets.expand((-1, padded_l_embeds.shape[1], -1))), dim=2) \n        padded_r_embeds = torch.cat((padded_r_embeds, v_targets.expand((-1, padded_r_embeds.shape[1], -1))), dim=2) \n\n        # pack the embeds  \n        padded_l_seq_pack = pack_padded_sequence(padded_l_embeds, l_lens.cpu(), batch_first=True, enforce_sorted=False)\n        padded_r_seq_pack = pack_padded_sequence(padded_r_embeds, r_lens.cpu(), batch_first=True, enforce_sorted=False)\n\n        _, (h_l, _) = self.l_lstm(padded_l_seq_pack)  \n        _, (h_r, _) = self.r_lstm(padded_r_seq_pack)  \n        h = torch.cat((h_l[-1], h_r[-1]), -1) # B x 2H\n\n        out = self.linear(h)\n        return out\n\n    def training_step(self, batch, batch_idx): # pylint: disable=unused-argument\n        sentiments = batch['sentiment']\n        logits = self.forward(batch)\n        loss = F.cross_entropy(logits, sentiments)\n        scores = F.softmax(logits, dim=-1)\n        self.train_acc(scores, sentiments)\n        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n        self.log('train_acc', self.train_acc, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n        return loss\n    \n    def validation_step(self, batch, batch_idx):  # pylint: disable=unused-argument\n        sentiments = batch['sentiment']\n        logits = self.forward(batch)\n        loss = F.cross_entropy(logits, sentiments)\n        scores = F.softmax(logits, dim=-1)\n        self.val_acc(scores, sentiments)\n        self.val_f1(scores, sentiments)\n        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n        self.log('val_acc', self.val_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        self.log('val_f1', self.val_f1, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n\n    def test_step(self, batch, batch_idx):  # pylint: disable=unused-argument\n        sentiments = batch['sentiment']\n        logits = self.forward(batch)\n        scores = F.softmax(logits, dim=-1)\n        self.test_acc(scores, sentiments)\n        self.test_f1(scores, sentiments)\n        self.log('test_acc', self.test_acc, on_step=False, on_epoch=True, logger=True)\n        self.log('test_f1', self.test_f1, on_step=False, on_epoch=True, logger=True)"
  },
  {
    "objectID": "posts/2021-06-20-nlp_2_effective_lstms_for_target_dependent_sentiment_classification [part 2].html#lstm",
    "href": "posts/2021-06-20-nlp_2_effective_lstms_for_target_dependent_sentiment_classification [part 2].html#lstm",
    "title": "Effective LSTMs for Target Dependent Sentiment Classification [Part 2]",
    "section": "LSTM",
    "text": "LSTM\nThis is just a simple LSTM model with a embedding layer, 1 LSTM layers and 1 dense layer.\nFor the input data, we simply feed all the input word vector to the LSTM without informing the model any information of the target words.\n\nThe LSTM model solves target-dependent sentiment classification in a target- independent way. That is to say, the feature representation used for sentiment classification remains the same without considering the target words. Let us again take “I bought a new camera. The picture quality is amazing but the battery life is too short” as an example. The representations of this sentence with regard to picture quality and battery life are identical. This is evidently problematic as the sentiment polarity labels towards these two targets are different.\n\n\nfrom IPython.display import Image\nImage(filename='images/figure_3_image.png')\n\n\n\n\n\n\n\n\n\nclass LSTM(pl.LightningModule):\n    def __init__(self, embeddings, hidden_size, num_layers=1, num_classes=3, batch_first=True, lr=1e-3, dropout=0, l2reg=0.01):\n        super().__init__()\n        embedding_dim = embeddings.shape[1]\n        self.embedding = nn.Embedding.from_pretrained(embeddings) # load pre-trained word embeddings\n        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first=batch_first, dropout=dropout)\n        self.linear = nn.Linear(hidden_size, num_classes)\n\n        self.lr = lr\n        self.l2reg = l2reg\n        # Define metrics \n        self.train_acc = torchmetrics.Accuracy() \n        self.val_acc = torchmetrics.Accuracy()\n        self.val_f1 = torchmetrics.F1(num_classes=3, average='macro')\n        self.test_acc = torchmetrics.Accuracy()\n        self.test_f1 = torchmetrics.F1(num_classes=3, average='macro')\n\n    def configure_optimizers(self):\n        optim = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.l2reg)\n        return optim\n\n    def forward(self, data):\n        cols = ['padded_sequence', 'len']\n        padded_seqs, lens = [data[col] for col in cols]\n        # convert seq to word vector\n        padded_embeds = self.embedding(padded_seqs)\n        # pack the embeds  \n        padded_seq_pack = pack_padded_sequence(padded_embeds, lens.cpu(), batch_first=True, enforce_sorted=False)\n        _, (h, _) = self.lstm(padded_seq_pack)  \n        out = self.linear(h[-1])\n        return out\n\n    def training_step(self, batch, batch_idx): # pylint: disable=unused-argument\n        sentiments = batch['sentiment']\n        logits = self.forward(batch)\n        loss = F.cross_entropy(logits, sentiments)\n        scores = F.softmax(logits, dim=-1)\n        self.train_acc(scores, sentiments)\n        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n        self.log('train_acc', self.train_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        return loss\n    \n    def validation_step(self, batch, batch_idx):  # pylint: disable=unused-argument\n        sentiments = batch['sentiment']\n        logits = self.forward(batch)\n        loss = F.cross_entropy(logits, sentiments)\n        scores = F.softmax(logits, dim=-1)\n        self.val_acc(scores, sentiments)\n        self.val_f1(scores, sentiments)\n        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n        self.log('val_acc', self.val_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        self.log('val_f1', self.val_f1, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n\n    def test_step(self, batch, batch_idx):  # pylint: disable=unused-argument\n        sentiments = batch['sentiment']\n        logits = self.forward(batch)\n        scores = F.softmax(logits, dim=-1)\n        self.test_acc(scores, sentiments)\n        self.test_f1(scores, sentiments)\n        self.log('test_acc', self.test_acc, on_step=False, on_epoch=True, logger=True)\n        self.log('test_f1', self.test_f1, on_step=False, on_epoch=True, logger=True)"
  },
  {
    "objectID": "posts/2021-06-20-nlp_2_effective_lstms_for_target_dependent_sentiment_classification [part 2].html#td-lstm-1",
    "href": "posts/2021-06-20-nlp_2_effective_lstms_for_target_dependent_sentiment_classification [part 2].html#td-lstm-1",
    "title": "Effective LSTMs for Target Dependent Sentiment Classification [Part 2]",
    "section": "TD-LSTM",
    "text": "TD-LSTM\n\n# Define callback\ncheckpoint_callback = ModelCheckpoint(\n    monitor='val_acc', # save the model with the best validation accuracy\n    dirpath='checkpoints',\n    mode='max',\n)\n\ntb_logger = pl_loggers.TensorBoardLogger('logs/') # create logger for tensorboard\n\n# Set hyper-parameters\nlr = 1e-3 \nhidden_size = 300\nnum_epochs = 30\nl2reg = 0.0 \n\ntrainer = pl.Trainer(gpus=1, max_epochs=num_epochs, logger=tb_logger, callbacks=[checkpoint_callback], deterministic=True)\n# trainer = pl.Trainer(fast_dev_run=True) #Debug \n# trainer = pl.Trainer(overfit_batches=0.1, max_epochs=30) #Debug\nmodel = TDLSTM(embedding_matrix, hidden_size, lr=lr, l2reg=l2reg)\ntrainer.fit(model, datamodule)\n\nGPU available: True, used: True\nTPU available: False, using: 0 TPU cores\n\n\nloading embedding matrix from embedding_matrix.dat\n\n\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\n  | Name      | Type      | Params\n----------------------------------------\n0 | embedding | Embedding | 1.3 M \n1 | l_lstm    | LSTM      | 482 K \n2 | r_lstm    | LSTM      | 482 K \n3 | linear    | Linear    | 1.8 K \n4 | train_acc | Accuracy  | 0     \n5 | val_acc   | Accuracy  | 0     \n6 | val_f1    | F1        | 0     \n7 | test_acc  | Accuracy  | 0     \n8 | test_f1   | F1        | 0     \n----------------------------------------\n966 K     Trainable params\n1.3 M     Non-trainable params\n2.3 M     Total params\n9.235     Total estimated model params size (MB)\n\n\n\n\n\nGlobal seed set to 2401\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# load the best model and evaluate on the testset\nnew_model = TDLSTM.load_from_checkpoint(checkpoint_callback.best_model_path, embeddings=embedding_matrix, hidden_size=300)\ntrainer.test(new_model, datamodule.test_dataloader())\n\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\n\n\n\n\n\n--------------------------------------------------------------------------------\nDATALOADER:0 TEST RESULTS\n{'test_acc': 0.6979768872261047, 'test_f1': 0.6850955486297607}\n--------------------------------------------------------------------------------\n\n\n[{'test_acc': 0.6979768872261047, 'test_f1': 0.6850955486297607}]"
  },
  {
    "objectID": "posts/2021-06-20-nlp_2_effective_lstms_for_target_dependent_sentiment_classification [part 2].html#tc-lstm-1",
    "href": "posts/2021-06-20-nlp_2_effective_lstms_for_target_dependent_sentiment_classification [part 2].html#tc-lstm-1",
    "title": "Effective LSTMs for Target Dependent Sentiment Classification [Part 2]",
    "section": "TC-LSTM",
    "text": "TC-LSTM\n\ncheckpoint_callback_2 = ModelCheckpoint(\n    monitor='val_acc', # save the model with the best validation accuracy\n    dirpath='checkpoints',\n    mode='max',\n)\n\ntb_logger = pl_loggers.TensorBoardLogger('logs/') # create logger for tensorboard\n\n# Set hyper-parameters\nlr = 1e-3 \nhidden_size = 300\nnum_epochs = 30\nl2reg = 0.0\n\ntrainer = pl.Trainer(gpus=1, max_epochs=num_epochs, logger=tb_logger, callbacks=[checkpoint_callback_2])\n# trainer = pl.Trainer(fast_dev_run=True) #Debug \n# trainer = pl.Trainer(overfit_batches=0.1, max_epochs=30) #Debug\nmodel = TCLSTM(embedding_matrix, hidden_size, lr=lr, l2reg=l2reg)\ntrainer.fit(model, datamodule)\n\nGPU available: True, used: True\nTPU available: False, using: 0 TPU cores\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\n  | Name      | Type      | Params\n----------------------------------------\n0 | embedding | Embedding | 1.3 M \n1 | l_lstm    | LSTM      | 602 K \n2 | r_lstm    | LSTM      | 602 K \n3 | linear    | Linear    | 1.8 K \n4 | train_acc | Accuracy  | 0     \n5 | val_acc   | Accuracy  | 0     \n6 | val_f1    | F1        | 0     \n7 | test_acc  | Accuracy  | 0     \n8 | test_f1   | F1        | 0     \n----------------------------------------\n1.2 M     Trainable params\n1.3 M     Non-trainable params\n2.5 M     Total params\n10.195    Total estimated model params size (MB)\n\n\n\n\n\nGlobal seed set to 2401\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# load the best model and evaluate on the testset\nnew_model = TCLSTM.load_from_checkpoint(checkpoint_callback_2.best_model_path, embeddings=embedding_matrix, hidden_size=300)\ntrainer.test(new_model, datamodule.test_dataloader())\n\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\n\n\n\n\n\n--------------------------------------------------------------------------------\nDATALOADER:0 TEST RESULTS\n{'test_acc': 0.7008670568466187, 'test_f1': 0.6788402199745178}\n--------------------------------------------------------------------------------\n\n\n[{'test_acc': 0.7008670568466187, 'test_f1': 0.6788402199745178}]"
  },
  {
    "objectID": "posts/2021-06-20-nlp_2_effective_lstms_for_target_dependent_sentiment_classification [part 2].html#lstm-1",
    "href": "posts/2021-06-20-nlp_2_effective_lstms_for_target_dependent_sentiment_classification [part 2].html#lstm-1",
    "title": "Effective LSTMs for Target Dependent Sentiment Classification [Part 2]",
    "section": "LSTM",
    "text": "LSTM\n\ncheckpoint_callback_3 = ModelCheckpoint(\n    monitor='val_acc', # save the model with the best validation accuracy\n    dirpath='checkpoints',\n    mode='max',\n)\n\ntb_logger = pl_loggers.TensorBoardLogger('logs/') # create logger for tensorboard\n\n# Set hyper-parameters\nlr = 1e-3 \nhidden_size = 300\nnum_epochs = 30\nl2reg = 0.0\n\ntrainer = pl.Trainer(gpus=1, max_epochs=num_epochs, logger=tb_logger, callbacks=[checkpoint_callback_3])\n# trainer = pl.Trainer(fast_dev_run=True) #Debug \n# trainer = pl.Trainer(overfit_batches=0.1, max_epochs=30) #Debug\nmodel = LSTM(embedding_matrix, hidden_size, lr=lr, l2reg=l2reg)\ntrainer.fit(model, datamodule)\n\nGPU available: True, used: True\nTPU available: False, using: 0 TPU cores\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\n  | Name      | Type      | Params\n----------------------------------------\n0 | embedding | Embedding | 1.3 M \n1 | lstm      | LSTM      | 482 K \n2 | linear    | Linear    | 903   \n3 | train_acc | Accuracy  | 0     \n4 | val_acc   | Accuracy  | 0     \n5 | val_f1    | F1        | 0     \n6 | test_acc  | Accuracy  | 0     \n7 | test_f1   | F1        | 0     \n----------------------------------------\n483 K     Trainable params\n1.3 M     Non-trainable params\n1.8 M     Total params\n7.302     Total estimated model params size (MB)\n\n\n\n\n\nGlobal seed set to 2401\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# load the best model and evaluate on the testset\nnew_model = LSTM.load_from_checkpoint(checkpoint_callback_3.best_model_path, embeddings=embedding_matrix, hidden_size=300)\ntrainer.test(new_model, datamodule.test_dataloader())\n\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\n\n\n\n\n\n--------------------------------------------------------------------------------\nDATALOADER:0 TEST RESULTS\n{'test_acc': 0.6878612637519836, 'test_f1': 0.6633064150810242}\n--------------------------------------------------------------------------------\n\n\n[{'test_acc': 0.6878612637519836, 'test_f1': 0.6633064150810242}]"
  },
  {
    "objectID": "posts/2021-07-28-nlp_8_text_preprocessing_and_labelling_[part_2].html",
    "href": "posts/2021-07-28-nlp_8_text_preprocessing_and_labelling_[part_2].html",
    "title": "Text Processing & Labelling [Part2]",
    "section": "",
    "text": "The full notebook is available here.\nimport pandas as pd\npd.set_option('display.max_colwidth', None) # Set to display full-width dataframe"
  },
  {
    "objectID": "posts/2021-07-28-nlp_8_text_preprocessing_and_labelling_[part_2].html#step-1-segment-document-into-sentences",
    "href": "posts/2021-07-28-nlp_8_text_preprocessing_and_labelling_[part_2].html#step-1-segment-document-into-sentences",
    "title": "Text Processing & Labelling [Part2]",
    "section": "Step 1: Segment Document into Sentences",
    "text": "Step 1: Segment Document into Sentences\nWe want to decrease the complexity when there are multiple sentences with different polarities in a doc. Therefore, instead of making prediction on a doc, we do for a sentence.\nNote: This way also does not guarantee that we will not have a sentence with 2 conflict polarities. Yet, it reduces the proability of that situation.\n\ndef segment_review(df):\n    reviews = list(df[\"review\"])\n    ratings = list(df[\"star_rating\"]) \n    new_reviews = []\n    new_ratings = []\n    for i in range(len(reviews)):\n        doc = nlp(reviews[i])\n        rating = ratings[i]\n        for sent in doc.sents:\n            new_reviews.append(str(sent))\n            new_ratings.append(rating)\n    return new_reviews, new_ratings\n\n\ndoc_df = pd.DataFrame({\"review\": filtered_df[\"lower_case\"], \"star_rating\": filtered_df[\"star_rating\"]})\n\n\n# Check NaN \ndf[\"star_rating\"].isnull().sum()\n\n0\n\n\n\nnew_texts, new_ratings = segment_review(doc_df)\n\n\nsegmented_df = pd.DataFrame({\"review\": new_texts, \"star_rating\": new_ratings})\n\n\nprint(\"Number of data after segmenting:\", len(segmented_df))\n\nNumber of data after segmenting: 35448\n\n\n\nsegmented_df.to_csv(\"segmented_df.csv\", index=False)"
  },
  {
    "objectID": "posts/2021-07-28-nlp_8_text_preprocessing_and_labelling_[part_2].html#step-2-add-labels-using-rating-and-pretrained-models-predictions",
    "href": "posts/2021-07-28-nlp_8_text_preprocessing_and_labelling_[part_2].html#step-2-add-labels-using-rating-and-pretrained-models-predictions",
    "title": "Text Processing & Labelling [Part2]",
    "section": "Step 2: Add labels using rating and pretrained-models’ predictions",
    "text": "Step 2: Add labels using rating and pretrained-models’ predictions\n\nlabel_df = segmented_df.copy(deep=True)\n\n\nRating Label\n\ndef rating2label(rating):\n    if rating == 3:\n        return \"Neutral\"\n    elif rating &lt; 3:\n        return \"Negative\"\n    else:\n        return \"Positive\"\n\n\ndef score2label(score):\n    if score == 1:\n        return \"Positive\"\n    else:\n        return \"Negative\"\n\n\n# Add rating labels\nlabel_df[\"rating_label\"] = label_df[\"star_rating\"].apply(rating2label)\n\n\n\nBERT Label\n\n%%capture\n!pip install transformers\n\n\nfrom transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\ndef get_classifier(model_name, **kwargs):\n    id2label = kwargs.get(\"id2label\")\n    if id2label:\n        model = AutoModelForSequenceClassification.from_pretrained(model_name, id2label=id2label)\n    else:\n        model = AutoModelForSequenceClassification.from_pretrained(model_name)\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n    return classifier\n\n\nModel 1: nlptown/bert-base-multilingual-uncased-sentimen\n\n# Load pretrained model\nmodel_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\nclassifier = get_classifer(model_name)\n\n\n# Function to convert the model output to label\ndef get_prediction(text):\n    rating = int(classifier(text)[0]['label'].split()[0])\n    return rating2label(rating)\n\n\nlabel_df[\"nlptown_bert_label\"] = label_df['review'].apply(get_prediction)\n\n\nlabel_df.head()\n\n\nlabel_df.to_csv(\"label_df.csv\", index=False)\n\n\nget_prediction(label_df['review'][0])\n\n\n# Check number of neutral\nlabel_df[label_df[\"nlptown_bert_label\"] == \"Neutral\"][[\"review\"]]\n\n\n\nModel 2: cardiffnlp/twitter-roberta-base-sentiment\n\nfrom transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\nmodel_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\nid2label = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\nclassifier = get_classifier(model_name, id2label=id2label)\n\n{'id2label': {0: 'Negative', 1: 'Neutral', 2: 'Positive'}}\n\n\n\ndef get_prediction(text):\n    return classifier(text)[0]['label']\n\n\nlabel_df[\"twitter-robert_label\"] = label_df['review'].apply(get_prediction)\n\n\nlabel_df.head()\n\n\n\n\n\n\n\n\nreview\nstar_rating\nrating_label\nnlptown_bert_label\ntwitter-robert_label\n\n\n\n\n0\ni love my new laptop!\n5\nPositive\nPositive\nPositive\n\n\n1\nbest computer i have ever own!\n5\nPositive\nPositive\nPositive\n\n\n2\nthis computer forces me to be productive.\n5\nPositive\nPositive\nPositive\n\n\n3\ni used to wait around for this spinning wheel to stop,\n5\nPositive\nNegative\nNeutral\n\n\n4\nand now i can do everything so quickly\n5\nPositive\nPositive\nPositive\n\n\n\n\n\n\n\n\nlabel_df[\"review\"] = label_df[\"review\"].str.strip()\n\n\nlabel_df.to_csv(\"label_df_full.csv\", index=False)\n\n\n\nModel 3: LSTM (Optional)\n\n# Label by LSTM model\nfrom allennlp.predictors.predictor import Predictor\npredictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/basic_stanford_sentiment_treebank-2020.06.09.tar.gz\")\n\nlstm_label = list()\nfor i, review in enumerate(new_df['review']):\n    label = score2label(int(predictor.predict(review)['label']))\n    lstm_label.append(label)\n\nPlugin allennlp_models could not be loaded: No module named 'nltk.translate.meteor_score'\n\n\n\nlabel_df[\"LSTM_label\"] = lstm_label"
  },
  {
    "objectID": "posts/2021-06-21-nlp_3_phobert_sentiment_analysis.html",
    "href": "posts/2021-06-21-nlp_3_phobert_sentiment_analysis.html",
    "title": "PhoBERT Vietnamese Sentiment Analysis on UIT-VSFC dataset with transformers and Pytorch Lightning",
    "section": "",
    "text": "The full notebook is available here."
  },
  {
    "objectID": "posts/2021-06-21-nlp_3_phobert_sentiment_analysis.html#phobert-pre-trained-language-models-for-vietnamese",
    "href": "posts/2021-06-21-nlp_3_phobert_sentiment_analysis.html#phobert-pre-trained-language-models-for-vietnamese",
    "title": "PhoBERT Vietnamese Sentiment Analysis on UIT-VSFC dataset with transformers and Pytorch Lightning",
    "section": "PhoBERT: Pre-trained language models for Vietnamese",
    "text": "PhoBERT: Pre-trained language models for Vietnamese\nPhoBERT models are the SOTA language models for Vietnamese. There are two versions of PhoBERT, which are PhoBERT base and PhoBERT large. Their pretraining approach is based on RoBERTa which optimizes the BERT pre-training procedure for more robust performance. PhoBERT has achieved SOTA in many downstream task such as POS, Dependency parsing, NER and NLI. You can read more about the PhoBERT here."
  },
  {
    "objectID": "posts/2021-06-21-nlp_3_phobert_sentiment_analysis.html#uit-vsfc-vietnamese-students-feedback-corpus",
    "href": "posts/2021-06-21-nlp_3_phobert_sentiment_analysis.html#uit-vsfc-vietnamese-students-feedback-corpus",
    "title": "PhoBERT Vietnamese Sentiment Analysis on UIT-VSFC dataset with transformers and Pytorch Lightning",
    "section": "UIT-VSFC: Vietnamese Students’ Feedback Corpus",
    "text": "UIT-VSFC: Vietnamese Students’ Feedback Corpus\nVietnamese Students’ Feedback Corpus (UIT-VSFC) is the resource consists of over 16,000 sentences which are human-annotated with two different tasks: sentiment-based and topic-based classifications.\n\nIn this project, we will apply PhoBERT to do the sentiment classification task on UIT-VSFC dataset. We will use pytorch-lightning and transformers for this project."
  },
  {
    "objectID": "posts/rubik.html",
    "href": "posts/rubik.html",
    "title": "Rubik Solving",
    "section": "",
    "text": "3x3:\n\n\nPLL attack\n\nCLB Rubik Nha Trang"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blogs",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\n1/14/25\n\n\nXV6 Series: MIT Lab4 2024\n\n\nAnswer for lab4 2024\n\n\n\n\n1/5/25\n\n\nXV6 Series: MIT Lab3 2024\n\n\nAnswer for lab3 2024\n\n\n\n\n8/30/21\n\n\nJob recommendation system for CS/IT program.\n\n\nImplement job recommendation system for CS/IT program\n\n\n\n\n8/18/21\n\n\nExtract aspects from sentence using denpendency parsing and POS tags\n\n\nExtract aspects in the sentences for aspect sentiment analysis uisng dependency parsing and pos tags.\n\n\n\n\n8/17/21\n\n\nAIVIVN Product Review Sentiment Analysis [Pytorch Lightning Sample]\n\n\nTraining the sentiment classifier (TextCNN) for AIVIVN product review dataset using Pytorch Lightning.\n\n\n\n\n8/15/21\n\n\nContent based recommendation system for movies [Baby Version]\n\n\nDevelop a content-based recommendation system for movies.\n\n\n\n\n7/28/21\n\n\nText Processing & Labelling [Part2]\n\n\nSample of labelling data for Sentiment Analysis task\n\n\n\n\n7/27/21\n\n\nText Processing & Labelling [Part1]\n\n\nSample of text preprocessing.\n\n\n\n\n7/4/21\n\n\nInteractive Attention Networks for Aspect-Level Sentiment Classification\n\n\nInteractive Attention Networks for Aspect-Level Sentiment Classification\n\n\n\n\n6/26/21\n\n\nAttention based LSTM for Aspect level Sentiment Classification\n\n\nAttention-based LSTM for Aspect-level Sentiment Classification\n\n\n\n\n6/21/21\n\n\nPhoBERT Vietnamese Sentiment Analysis on UIT-VSFC dataset with transformers and Pytorch Lightning\n\n\nApply PhoBERT on UIT-VSFC dataset.\n\n\n\n\n6/20/21\n\n\nEffective LSTMs for Target Dependent Sentiment Classification [Part 2]\n\n\nReproduce the ‘Effective LSTMs for Target Dependent Sentiment Classification’ paper.\n\n\n\n\n6/18/21\n\n\nEffective LSTMs for Target Dependent Sentiment Classification [Part 1]\n\n\nReproduce the ‘Effective LSTMs for Target Dependent Sentiment Classification’ paper.\n\n\n\n\n5/9/12\n\n\nRubik Solving\n\n\nMy recording of solving rubik and related videos\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "list_100.html",
    "href": "list_100.html",
    "title": "List 100",
    "section": "",
    "text": "Things I want to do before I die. Please let me know if you have any recommendation. Progress as of Oct 28, 2024: 1/100.\n\n✗ Participate in UTMB.\n✗ Live and work in another country (WIP).\n✗ Marathon sub 3:00.\n✗ Build a home.\n✗ Work for Google.\n✗ Become a parent.\n✓ Fall in love.\n✗ Body transformation (WIP).\n✗ Participate in Iron Man World Championship.\n✗ Meet David Goggins.\n✗ Publish a book.\n✗ Learn to play guitar again.\n✗ Get the Guardian badge (Leetcode) (WIP, currently got a Knight Badge).\n✗ Travel with my big family to Europe.\n✗ Learning a 3rd language.\n\n✗ for not complete  ✓ for complete"
  },
  {
    "objectID": "mindmap/OS/os.html",
    "href": "mindmap/OS/os.html",
    "title": "Operating system",
    "section": "",
    "text": "A software that lies between the application and hardware. It allows the application to access hardware resources."
  },
  {
    "objectID": "mindmap/OS/os.html#definition",
    "href": "mindmap/OS/os.html#definition",
    "title": "Operating system",
    "section": "",
    "text": "A software that lies between the application and hardware. It allows the application to access hardware resources."
  },
  {
    "objectID": "mindmap/OS/os.html#features",
    "href": "mindmap/OS/os.html#features",
    "title": "Operating system",
    "section": "Features",
    "text": "Features\n\nVirtualize the CPU\n\nGoal: Give each “process” impression it alone is actively using CPU\nResources can be shared in time and/or space. ### Virtualize the memory"
  }
]